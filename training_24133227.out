✅ Conda env active at: /n/fs/similarity/open-r1/openr1/bin/python
Python 3.11.12
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: write).
The token `ionic` has been saved to /n/fs/similarity/open-r1/.hf_cache/stored_tokens
Your token has been saved to /n/fs/similarity/open-r1/.hf_cache/token
Login successful.
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
✅ Logged into Hugging Face
Requirement already satisfied: yq in ./openr1/lib/python3.11/site-packages (3.4.3)
Requirement already satisfied: huggingface_hub in ./openr1/lib/python3.11/site-packages (0.32.4)
Requirement already satisfied: PyYAML>=5.3.1 in ./openr1/lib/python3.11/site-packages (from yq) (6.0.2)
Requirement already satisfied: xmltodict>=0.11.0 in ./openr1/lib/python3.11/site-packages (from yq) (0.14.2)
Requirement already satisfied: tomlkit>=0.11.6 in ./openr1/lib/python3.11/site-packages (from yq) (0.13.2)
Requirement already satisfied: argcomplete>=1.8.1 in ./openr1/lib/python3.11/site-packages (from yq) (3.6.2)
Requirement already satisfied: filelock in ./openr1/lib/python3.11/site-packages (from huggingface_hub) (3.18.0)
Requirement already satisfied: fsspec>=2023.5.0 in ./openr1/lib/python3.11/site-packages (from huggingface_hub) (2024.6.1)
Requirement already satisfied: packaging>=20.9 in ./openr1/lib/python3.11/site-packages (from huggingface_hub) (25.0)
Requirement already satisfied: requests in ./openr1/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)
Requirement already satisfied: tqdm>=4.42.1 in ./openr1/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)
Requirement already satisfied: typing-extensions>=3.7.4.3 in ./openr1/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./openr1/lib/python3.11/site-packages (from huggingface_hub) (1.1.2)
Requirement already satisfied: charset-normalizer<4,>=2 in ./openr1/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.2)
Requirement already satisfied: idna<4,>=2.5 in ./openr1/lib/python3.11/site-packages (from requests->huggingface_hub) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./openr1/lib/python3.11/site-packages (from requests->huggingface_hub) (2.4.0)
Requirement already satisfied: certifi>=2017.4.17 in ./openr1/lib/python3.11/site-packages (from requests->huggingface_hub) (2025.4.26)
🟢 Setup complete. Ready to run SFT.
Env:        /n/fs/similarity/open-r1/openr1
Config:     recipes/Qwen2.5-1.5B-Instruct/sft/config_demo_liv.yaml
Log Files:  logs/liv_train_Qwen1.5B-SFT-Finetune-v2_20250606_000856.log
CUDA_VISIBLE_DEVICES: 0,1
/n/fs/similarity/open-r1/openr1/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2025-06-06 00:09:03,575] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0606 00:09:04.892000 1950090 torch/distributed/run.py:792] 
W0606 00:09:04.892000 1950090 torch/distributed/run.py:792] *****************************************
W0606 00:09:04.892000 1950090 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0606 00:09:04.892000 1950090 torch/distributed/run.py:792] *****************************************
/n/fs/similarity/open-r1/openr1/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/n/fs/similarity/open-r1/openr1/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2025-06-06 00:09:10,243] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-06 00:09:10,244] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /n/fs/similarity/open-r1/.triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /n/fs/similarity/open-r1/.triton, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2025-06-06 00:09:11,197] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-06-06 00:09:11,211] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-06-06 00:09:11,211] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
2025-06-06 00:09:11 - INFO - __main__ - Model parameters ModelConfig(model_name_or_path='Qwen/Qwen2.5-1.5B-Instruct', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, use_dora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)
2025-06-06 00:09:11 - INFO - __main__ - Script parameters ScriptArguments(dataset_name='open-r1/OpenR1-Math-220k', dataset_config='default', dataset_train_split='train', dataset_test_split='test', gradient_checkpointing_use_reentrant=False, ignore_bias_buffers=False, dataset_prompt_column='problem', dataset_response_column='solution', dataset_mixture=None)
2025-06-06 00:09:11 - INFO - __main__ - Training parameters SFTConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
benchmarks=[],
bf16=True,
bf16_full_eval=False,
callbacks=[],
chars_per_token=<CHARS_PER_TOKEN>,
chat_template=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
dataset_batch_size=None,
dataset_kwargs=None,
dataset_num_proc=None,
dataset_text_field=text,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=4,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_packing=None,
eval_steps=500000,
eval_strategy=IntervalStrategy.STEPS,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=16,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=Qwen2.5-1.5B-Instruct-SFT,
hub_model_revision=main,
hub_private_repo=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-06,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/runs/Jun06_00-09-11_node207.ionic.cs.princeton.edu,
logging_first_step=True,
logging_nan_inf_filter=True,
logging_steps=1,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.COSINE,
max_grad_norm=1.0,
max_length=1024,
max_seq_length=1024,
max_steps=-1,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_of_sequences=None,
num_train_epochs=1,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
output_dir=/n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4,
overwrite_hub_revision=False,
overwrite_output_dir=True,
packing=False,
padding_free=False,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=2,
prediction_loss_only=False,
push_to_hub=True,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_revision=False,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=Qwen1.5B-SFT-Finetune-v2-20250606_000856,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=50,
save_strategy=SaveStrategy.STEPS,
save_total_limit=100,
seed=42,
skip_memory_metrics=True,
split_batches=None,
system_prompt=You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format:
<think> ... </think> <answer> ... </answer>
,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tp_size=0,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger=None,
use_liger_kernel=False,
use_mps_device=False,
wandb_entity=None,
wandb_project=None,
wandb_run_group=None,
warmup_ratio=0.05,
warmup_steps=0,
weight_decay=0.0,
)
2025-06-06 00:09:11 - INFO - open_r1.utils.data - Loading dataset: open-r1/OpenR1-Math-220k/default
2025-06-06 00:09:11 - INFO - open_r1.utils.data - Loading dataset: open-r1/OpenR1-Math-220k/default
2025-06-06 00:09:13 - INFO - open_r1.utils.data - Tokenizing split 'train' (93733 examples)…
2025-06-06 00:09:13 - WARNING - __main__ - Requested split 'test' not found in ['train']. Creating a 1 % evaluation split from the training data.
[2025-06-06 00:09:13,556] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[WARNING|logging.py:329] 2025-06-06 00:09:13,558 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Overwrite dataset info from restored data version if exists.
2025-06-06 00:09:13 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68
2025-06-06 00:09:13 - INFO - datasets.info - Loading Dataset info from /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68
Found cached dataset open_r1-math-220k (/n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68)
2025-06-06 00:09:13 - INFO - datasets.builder - Found cached dataset open_r1-math-220k (/n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68)
Loading Dataset info from /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68
2025-06-06 00:09:13 - INFO - datasets.info - Loading Dataset info from /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,001 >> loading file vocab.json from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,001 >> loading file merges.txt from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,001 >> loading file tokenizer.json from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,001 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,001 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,001 >> loading file tokenizer_config.json from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,001 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2323] 2025-06-06 00:09:14,219 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2025-06-06 00:09:14 - INFO - open_r1.utils.data - Tokenizing split 'train' (93733 examples)…
Loading cached processed dataset at /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-6aeed7f1e1542bea.arrow
2025-06-06 00:09:14 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-6aeed7f1e1542bea.arrow
2025-06-06 00:09:14 - WARNING - __main__ - Requested split 'test' not found in ['train']. Creating a 1 % evaluation split from the training data.
Loading cached split indices for dataset at /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-f214169554aea0b8.arrow and /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-8ca86c422b54feb8.arrow
2025-06-06 00:09:14 - INFO - datasets.arrow_dataset - Loading cached split indices for dataset at /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-f214169554aea0b8.arrow and /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-8ca86c422b54feb8.arrow
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,335 >> loading file vocab.json from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,335 >> loading file merges.txt from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,335 >> loading file tokenizer.json from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,335 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,335 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,335 >> loading file tokenizer_config.json from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json
[INFO|tokenization_utils_base.py:2060] 2025-06-06 00:09:14,335 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2323] 2025-06-06 00:09:14,543 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:699] 2025-06-06 00:09:14,588 >> loading configuration file config.json from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json
[INFO|configuration_utils.py:771] 2025-06-06 00:09:14,590 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.50.0",
  "use_cache": false,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|modeling_utils.py:1154] 2025-06-06 00:09:14,638 >> loading weights file model.safetensors from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/model.safetensors
[INFO|modeling_utils.py:2170] 2025-06-06 00:09:14,639 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:3747] 2025-06-06 00:09:14,639 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[2025-06-06 00:09:14,639] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[WARNING|logging.py:329] 2025-06-06 00:09:14,642 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[INFO|configuration_utils.py:1139] 2025-06-06 00:09:14,646 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "use_cache": false
}

[2025-06-06 00:09:15,767] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 339, num_elems = 1.78B
[INFO|modeling_utils.py:4987] 2025-06-06 00:09:17,094 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.

[INFO|modeling_utils.py:4995] 2025-06-06 00:09:17,094 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1094] 2025-06-06 00:09:17,135 >> loading configuration file generation_config.json from cache at /n/fs/similarity/open-r1/.cache/huggingface/transformers/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/generation_config.json
[INFO|configuration_utils.py:1139] 2025-06-06 00:09:17,136 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "repetition_penalty": 1.1,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}

Loading cached processed dataset at /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-212db3323b9eb092.arrow
2025-06-06 00:09:17 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-212db3323b9eb092.arrow
Loading cached processed dataset at /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-eb0e30a8f560726f.arrow
2025-06-06 00:09:17 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /n/fs/similarity/open-r1/.cache/huggingface/datasets/open-r1___open_r1-math-220k/default/0.0.0/e4e141ec9dea9f8326f4d347be56105859b2bd68/cache-eb0e30a8f560726f.arrow
[INFO|trainer.py:748] 2025-06-06 00:09:17,197 >> Using auto half precision backend
2025-06-06 00:09:17 - INFO - __main__ - *** Train ***
[INFO|deepspeed.py:386] 2025-06-06 00:09:17,433 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
Using /n/fs/similarity/open-r1/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
Emitting ninja build file /n/fs/similarity/open-r1/.cache/torch_extensions/py311_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /n/fs/similarity/open-r1/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 0.2819085121154785 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 0.3584756851196289 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000002, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1
[2025-06-06 00:09:18,033] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.15.4, git-hash=unknown, git-branch=unknown
[2025-06-06 00:09:18,033] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-06-06 00:09:18,043] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-06 00:09:18,044] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-06-06 00:09:18,044] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-06 00:09:18,059] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2025-06-06 00:09:18,059] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2025-06-06 00:09:18,059] [INFO] [logging.py:128:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2025-06-06 00:09:18,060] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2025-06-06 00:09:18,241] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[2025-06-06 00:09:18,242] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.87 GB         CA 0.0 GB         Max_CA 1 GB 
[2025-06-06 00:09:18,242] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 23.48 GB, percent = 4.7%
[2025-06-06 00:09:18,243] [INFO] [stage3.py:166:__init__] Reduce bucket size 500000000
[2025-06-06 00:09:18,243] [INFO] [stage3.py:167:__init__] Prefetch bucket size 50000000
[2025-06-06 00:09:18,389] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-06-06 00:09:18,390] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2025-06-06 00:09:18,390] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 23.48 GB, percent = 4.7%
Parameter Offload: Total persistent parameters: 144896 in 141 params
[2025-06-06 00:09:18,549] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-06-06 00:09:18,550] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2025-06-06 00:09:18,550] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 23.48 GB, percent = 4.7%
[2025-06-06 00:09:18,700] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[2025-06-06 00:09:18,700] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2025-06-06 00:09:18,700] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 23.48 GB, percent = 4.7%
[2025-06-06 00:09:19,937] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 2
[2025-06-06 00:09:19,938] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2025-06-06 00:09:19,938] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 28.1 GB, percent = 5.6%
[2025-06-06 00:09:20,124] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[2025-06-06 00:09:20,125] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2025-06-06 00:09:20,125] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 28.87 GB, percent = 5.7%
[2025-06-06 00:09:21,243] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[2025-06-06 00:09:21,244] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2025-06-06 00:09:21,244] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 33.96 GB, percent = 6.8%
[2025-06-06 00:09:21,425] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-06-06 00:09:21,425] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2025-06-06 00:09:21,425] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 34.41 GB, percent = 6.8%
[2025-06-06 00:09:22,634] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-06-06 00:09:22,634] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2025-06-06 00:09:22,634] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 39.8 GB, percent = 7.9%
[2025-06-06 00:09:22,635] [INFO] [stage3.py:521:_setup_for_real_optimizer] optimizer state initialized
[2025-06-06 00:09:23,553] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-06-06 00:09:23,553] [INFO] [utils.py:782:see_memory_usage] MA 0.93 GB         Max_MA 1.8 GB         CA 1.82 GB         Max_CA 2 GB 
[2025-06-06 00:09:23,553] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 42.55 GB, percent = 8.5%
[2025-06-06 00:09:23,554] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[2025-06-06 00:09:23,554] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-06-06 00:09:23,554] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-06 00:09:23,554] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-06-06 00:09:23,554] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f02bbfc4050>
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 16
[2025-06-06 00:09:23,555] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   train_batch_size ............. 64
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  2
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   world_size ................... 2
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  True
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-06 00:09:23,556] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[2025-06-06 00:09:23,556] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 64, 
    "train_micro_batch_size_per_gpu": 2, 
    "gradient_accumulation_steps": 16, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "cpu", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "cpu", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
[INFO|trainer.py:2409] 2025-06-06 00:09:23,558 >> ***** Running training *****
[INFO|trainer.py:2410] 2025-06-06 00:09:23,558 >>   Num examples = 92,795
[INFO|trainer.py:2411] 2025-06-06 00:09:23,558 >>   Num Epochs = 1
[INFO|trainer.py:2412] 2025-06-06 00:09:23,558 >>   Instantaneous batch size per device = 2
[INFO|trainer.py:2415] 2025-06-06 00:09:23,558 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:2416] 2025-06-06 00:09:23,558 >>   Gradient Accumulation steps = 16
[INFO|trainer.py:2417] 2025-06-06 00:09:23,558 >>   Total optimization steps = 1,449
[INFO|trainer.py:2418] 2025-06-06 00:09:23,559 >>   Number of trainable parameters = 1,543,714,304
[INFO|integration_utils.py:831] 2025-06-06 00:09:23,560 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: ogd3 (ogd3-princeton-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /n/fs/similarity/open-r1/.wandb/wandb/run-20250606_000923-v96u0y67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Qwen1.5B-SFT-Finetune-v2-20250606_000856
wandb: ⭐️ View project at https://wandb.ai/ogd3-princeton-university/huggingface
wandb: 🚀 View run at https://wandb.ai/ogd3-princeton-university/huggingface/runs/v96u0y67
  0%|          | 0/1449 [00:00<?, ?it/s]  0%|          | 1/1449 [00:25<10:17:21, 25.58s/it]                                                   {'loss': 1.4013, 'grad_norm': 7.115165710449219, 'learning_rate': 2.73972602739726e-08, 'num_tokens': 5427.0, 'mean_token_accuracy': 0.6334721110761166, 'epoch': 0.0}
  0%|          | 1/1449 [00:25<10:17:21, 25.58s/it]  0%|          | 2/1449 [00:46<9:17:44, 23.13s/it]                                                   {'loss': 1.2827, 'grad_norm': 6.971931457519531, 'learning_rate': 5.47945205479452e-08, 'num_tokens': 11489.0, 'mean_token_accuracy': 0.6730691567063332, 'epoch': 0.0}
  0%|          | 2/1449 [00:46<9:17:44, 23.13s/it]  0%|          | 3/1449 [01:08<8:54:19, 22.17s/it]                                                  {'loss': 1.193, 'grad_norm': 6.016913414001465, 'learning_rate': 8.21917808219178e-08, 'num_tokens': 18093.0, 'mean_token_accuracy': 0.683920793235302, 'epoch': 0.0}
  0%|          | 3/1449 [01:08<8:54:19, 22.17s/it]  0%|          | 4/1449 [01:29<8:44:12, 21.77s/it]                                                  {'loss': 1.3166, 'grad_norm': 6.0954179763793945, 'learning_rate': 1.095890410958904e-07, 'num_tokens': 25298.0, 'mean_token_accuracy': 0.6579648293554783, 'epoch': 0.0}
  0%|          | 4/1449 [01:29<8:44:12, 21.77s/it]  0%|          | 5/1449 [01:49<8:35:32, 21.42s/it]                                                  {'loss': 1.2731, 'grad_norm': 7.529391288757324, 'learning_rate': 1.36986301369863e-07, 'num_tokens': 30708.0, 'mean_token_accuracy': 0.6679505221545696, 'epoch': 0.0}
  0%|          | 5/1449 [01:49<8:35:32, 21.42s/it]  0%|          | 6/1449 [02:11<8:33:21, 21.35s/it]                                                  {'loss': 1.3951, 'grad_norm': 7.666150093078613, 'learning_rate': 1.643835616438356e-07, 'num_tokens': 36237.0, 'mean_token_accuracy': 0.6484273560345173, 'epoch': 0.0}
  0%|          | 6/1449 [02:11<8:33:21, 21.35s/it]  0%|          | 7/1449 [02:32<8:32:03, 21.31s/it]                                                  {'loss': 1.3743, 'grad_norm': 6.7357258796691895, 'learning_rate': 1.917808219178082e-07, 'num_tokens': 42724.0, 'mean_token_accuracy': 0.635077141225338, 'epoch': 0.0}
  0%|          | 7/1449 [02:32<8:32:03, 21.31s/it]  1%|          | 8/1449 [02:53<8:28:15, 21.16s/it]                                                  {'loss': 1.3128, 'grad_norm': 7.435177326202393, 'learning_rate': 2.191780821917808e-07, 'num_tokens': 48140.0, 'mean_token_accuracy': 0.6607662849128246, 'epoch': 0.01}
  1%|          | 8/1449 [02:53<8:28:15, 21.16s/it]  1%|          | 9/1449 [03:14<8:30:15, 21.26s/it]                                                  {'loss': 1.2614, 'grad_norm': 6.350414276123047, 'learning_rate': 2.465753424657534e-07, 'num_tokens': 54288.0, 'mean_token_accuracy': 0.676834762096405, 'epoch': 0.01}
  1%|          | 9/1449 [03:14<8:30:15, 21.26s/it]  1%|          | 10/1449 [03:35<8:26:45, 21.13s/it]                                                   {'loss': 1.3057, 'grad_norm': 6.446128845214844, 'learning_rate': 2.73972602739726e-07, 'num_tokens': 60667.0, 'mean_token_accuracy': 0.6524682082235813, 'epoch': 0.01}
  1%|          | 10/1449 [03:35<8:26:45, 21.13s/it]  1%|          | 11/1449 [03:57<8:28:55, 21.23s/it]                                                   {'loss': 1.3567, 'grad_norm': 6.691532135009766, 'learning_rate': 3.013698630136986e-07, 'num_tokens': 66607.0, 'mean_token_accuracy': 0.6365336775779724, 'epoch': 0.01}
  1%|          | 11/1449 [03:57<8:28:55, 21.23s/it]  1%|          | 12/1449 [04:17<8:25:47, 21.12s/it]                                                   {'loss': 1.2435, 'grad_norm': 6.698115825653076, 'learning_rate': 3.287671232876712e-07, 'num_tokens': 72876.0, 'mean_token_accuracy': 0.6751282997429371, 'epoch': 0.01}
  1%|          | 12/1449 [04:17<8:25:47, 21.12s/it]  1%|          | 13/1449 [04:39<8:26:35, 21.17s/it]                                                   {'loss': 1.2595, 'grad_norm': 6.763347625732422, 'learning_rate': 3.561643835616438e-07, 'num_tokens': 78347.0, 'mean_token_accuracy': 0.6725441217422485, 'epoch': 0.01}
  1%|          | 13/1449 [04:39<8:26:35, 21.17s/it]  1%|          | 14/1449 [05:00<8:24:03, 21.08s/it]                                                   {'loss': 1.394, 'grad_norm': 7.906730651855469, 'learning_rate': 3.835616438356164e-07, 'num_tokens': 83513.0, 'mean_token_accuracy': 0.636437427252531, 'epoch': 0.01}
  1%|          | 14/1449 [05:00<8:24:03, 21.08s/it]  1%|          | 15/1449 [05:21<8:23:42, 21.08s/it]                                                   {'loss': 1.1872, 'grad_norm': 6.908790588378906, 'learning_rate': 4.10958904109589e-07, 'num_tokens': 89878.0, 'mean_token_accuracy': 0.6748992577195168, 'epoch': 0.01}
  1%|          | 15/1449 [05:21<8:23:42, 21.08s/it]  1%|          | 16/1449 [05:42<8:23:11, 21.07s/it]                                                   {'loss': 1.4481, 'grad_norm': 6.274990558624268, 'learning_rate': 4.383561643835616e-07, 'num_tokens': 95932.0, 'mean_token_accuracy': 0.6279730424284935, 'epoch': 0.01}
  1%|          | 16/1449 [05:42<8:23:11, 21.07s/it]  1%|          | 17/1449 [06:03<8:22:04, 21.04s/it]                                                   {'loss': 1.3155, 'grad_norm': 7.335964679718018, 'learning_rate': 4.657534246575342e-07, 'num_tokens': 101319.0, 'mean_token_accuracy': 0.6580870747566223, 'epoch': 0.01}
  1%|          | 17/1449 [06:03<8:22:04, 21.04s/it]  1%|          | 18/1449 [06:24<8:24:00, 21.13s/it]                                                   {'loss': 1.3389, 'grad_norm': 6.919323444366455, 'learning_rate': 4.931506849315068e-07, 'num_tokens': 106801.0, 'mean_token_accuracy': 0.6538033038377762, 'epoch': 0.01}
  1%|          | 18/1449 [06:24<8:24:00, 21.13s/it]  1%|▏         | 19/1449 [06:45<8:21:29, 21.04s/it]                                                   {'loss': 1.3946, 'grad_norm': 7.086327075958252, 'learning_rate': 5.205479452054794e-07, 'num_tokens': 112855.0, 'mean_token_accuracy': 0.6417123675346375, 'epoch': 0.01}
  1%|▏         | 19/1449 [06:45<8:21:29, 21.04s/it]  1%|▏         | 20/1449 [07:06<8:22:11, 21.09s/it]                                                   {'loss': 1.2988, 'grad_norm': 7.834427356719971, 'learning_rate': 5.47945205479452e-07, 'num_tokens': 118972.0, 'mean_token_accuracy': 0.6457272693514824, 'epoch': 0.01}
  1%|▏         | 20/1449 [07:06<8:22:11, 21.09s/it]  1%|▏         | 21/1449 [07:27<8:21:18, 21.06s/it]                                                   {'loss': 1.3779, 'grad_norm': 7.654954433441162, 'learning_rate': 5.753424657534246e-07, 'num_tokens': 124312.0, 'mean_token_accuracy': 0.6418646015226841, 'epoch': 0.01}
  1%|▏         | 21/1449 [07:27<8:21:18, 21.06s/it]  2%|▏         | 22/1449 [07:48<8:22:02, 21.11s/it]                                                   {'loss': 1.2275, 'grad_norm': 6.827056884765625, 'learning_rate': 6.027397260273972e-07, 'num_tokens': 130455.0, 'mean_token_accuracy': 0.6807327605783939, 'epoch': 0.02}
  2%|▏         | 22/1449 [07:48<8:22:02, 21.11s/it]  2%|▏         | 23/1449 [08:09<8:19:48, 21.03s/it]                                                   {'loss': 1.4631, 'grad_norm': 7.265579700469971, 'learning_rate': 6.301369863013698e-07, 'num_tokens': 135953.0, 'mean_token_accuracy': 0.6411265209317207, 'epoch': 0.02}
  2%|▏         | 23/1449 [08:09<8:19:48, 21.03s/it]  2%|▏         | 24/1449 [08:30<8:19:59, 21.05s/it]                                                   {'loss': 1.2879, 'grad_norm': 7.849670886993408, 'learning_rate': 6.575342465753423e-07, 'num_tokens': 141579.0, 'mean_token_accuracy': 0.6572689227759838, 'epoch': 0.02}
  2%|▏         | 24/1449 [08:30<8:19:59, 21.05s/it]  2%|▏         | 25/1449 [08:51<8:20:23, 21.08s/it]                                                   {'loss': 1.4533, 'grad_norm': 8.494632720947266, 'learning_rate': 6.84931506849315e-07, 'num_tokens': 146504.0, 'mean_token_accuracy': 0.6254400610923767, 'epoch': 0.02}
  2%|▏         | 25/1449 [08:51<8:20:23, 21.08s/it]  2%|▏         | 26/1449 [09:12<8:18:26, 21.02s/it]                                                   {'loss': 1.3099, 'grad_norm': 6.963324546813965, 'learning_rate': 7.123287671232876e-07, 'num_tokens': 152679.0, 'mean_token_accuracy': 0.6663438230752945, 'epoch': 0.02}
  2%|▏         | 26/1449 [09:12<8:18:26, 21.02s/it]  2%|▏         | 27/1449 [09:33<8:19:20, 21.07s/it]                                                   {'loss': 1.2495, 'grad_norm': 6.746429920196533, 'learning_rate': 7.397260273972602e-07, 'num_tokens': 158329.0, 'mean_token_accuracy': 0.6618391908705235, 'epoch': 0.02}
  2%|▏         | 27/1449 [09:33<8:19:20, 21.07s/it]  2%|▏         | 28/1449 [09:54<8:17:28, 21.01s/it]                                                   {'loss': 1.3328, 'grad_norm': 6.986436367034912, 'learning_rate': 7.671232876712328e-07, 'num_tokens': 163705.0, 'mean_token_accuracy': 0.6490888185799122, 'epoch': 0.02}
  2%|▏         | 28/1449 [09:54<8:17:28, 21.01s/it]  2%|▏         | 29/1449 [10:15<8:18:27, 21.06s/it]                                                   {'loss': 1.3491, 'grad_norm': 6.973186492919922, 'learning_rate': 7.945205479452054e-07, 'num_tokens': 169523.0, 'mean_token_accuracy': 0.6537458896636963, 'epoch': 0.02}
  2%|▏         | 29/1449 [10:15<8:18:27, 21.06s/it]  2%|▏         | 30/1449 [10:36<8:16:40, 21.00s/it]                                                   {'loss': 1.347, 'grad_norm': 6.420229434967041, 'learning_rate': 8.21917808219178e-07, 'num_tokens': 175967.0, 'mean_token_accuracy': 0.648872122168541, 'epoch': 0.02}
  2%|▏         | 30/1449 [10:36<8:16:40, 21.00s/it]  2%|▏         | 31/1449 [10:57<8:17:39, 21.06s/it]                                                   {'loss': 1.3448, 'grad_norm': 6.6433820724487305, 'learning_rate': 8.493150684931506e-07, 'num_tokens': 181689.0, 'mean_token_accuracy': 0.6523785591125488, 'epoch': 0.02}
  2%|▏         | 31/1449 [10:57<8:17:39, 21.06s/it]  2%|▏         | 32/1449 [11:18<8:15:52, 21.00s/it]                                                   {'loss': 1.35, 'grad_norm': 6.745405197143555, 'learning_rate': 8.767123287671232e-07, 'num_tokens': 187044.0, 'mean_token_accuracy': 0.6437696814537048, 'epoch': 0.02}
  2%|▏         | 32/1449 [11:18<8:15:52, 21.00s/it]  2%|▏         | 33/1449 [11:39<8:15:38, 21.00s/it]                                                   {'loss': 1.2935, 'grad_norm': 5.675817489624023, 'learning_rate': 9.041095890410958e-07, 'num_tokens': 192590.0, 'mean_token_accuracy': 0.6676803044974804, 'epoch': 0.02}
  2%|▏         | 33/1449 [11:39<8:15:38, 21.00s/it]  2%|▏         | 34/1449 [12:00<8:15:21, 21.00s/it]                                                   {'loss': 1.203, 'grad_norm': 5.573630332946777, 'learning_rate': 9.315068493150684e-07, 'num_tokens': 198624.0, 'mean_token_accuracy': 0.6784413792192936, 'epoch': 0.02}
  2%|▏         | 34/1449 [12:00<8:15:21, 21.00s/it]  2%|▏         | 35/1449 [12:21<8:14:00, 20.96s/it]                                                   {'loss': 1.33, 'grad_norm': 5.974151611328125, 'learning_rate': 9.58904109589041e-07, 'num_tokens': 204768.0, 'mean_token_accuracy': 0.666594598442316, 'epoch': 0.02}
  2%|▏         | 35/1449 [12:21<8:14:00, 20.96s/it]  2%|▏         | 36/1449 [12:42<8:15:44, 21.05s/it]                                                   {'loss': 1.297, 'grad_norm': 6.121656894683838, 'learning_rate': 9.863013698630137e-07, 'num_tokens': 210397.0, 'mean_token_accuracy': 0.6671470813453197, 'epoch': 0.02}
  2%|▏         | 36/1449 [12:42<8:15:44, 21.05s/it]  3%|▎         | 37/1449 [13:03<8:13:55, 20.99s/it]                                                   {'loss': 1.1921, 'grad_norm': 5.902688980102539, 'learning_rate': 1.0136986301369862e-06, 'num_tokens': 215983.0, 'mean_token_accuracy': 0.6744697690010071, 'epoch': 0.03}
  3%|▎         | 37/1449 [13:03<8:13:55, 20.99s/it]  3%|▎         | 38/1449 [13:25<8:15:22, 21.07s/it]                                                   {'loss': 1.3098, 'grad_norm': 6.261509418487549, 'learning_rate': 1.0410958904109588e-06, 'num_tokens': 221629.0, 'mean_token_accuracy': 0.6626531109213829, 'epoch': 0.03}
  3%|▎         | 38/1449 [13:25<8:15:22, 21.07s/it]  3%|▎         | 39/1449 [13:45<8:13:30, 21.00s/it]                                                   {'loss': 1.4288, 'grad_norm': 6.905079364776611, 'learning_rate': 1.0684931506849315e-06, 'num_tokens': 226507.0, 'mean_token_accuracy': 0.6334438137710094, 'epoch': 0.03}
  3%|▎         | 39/1449 [13:45<8:13:30, 21.00s/it]  3%|▎         | 40/1449 [14:07<8:14:36, 21.06s/it]                                                   {'loss': 1.2419, 'grad_norm': 5.8247880935668945, 'learning_rate': 1.095890410958904e-06, 'num_tokens': 232359.0, 'mean_token_accuracy': 0.6756292916834354, 'epoch': 0.03}
  3%|▎         | 40/1449 [14:07<8:14:36, 21.06s/it]  3%|▎         | 41/1449 [14:27<8:12:41, 21.00s/it]                                                   {'loss': 1.1499, 'grad_norm': 4.8111066818237305, 'learning_rate': 1.1232876712328766e-06, 'num_tokens': 238685.0, 'mean_token_accuracy': 0.6903329975903034, 'epoch': 0.03}
  3%|▎         | 41/1449 [14:27<8:12:41, 21.00s/it]  3%|▎         | 42/1449 [14:49<8:12:36, 21.01s/it]                                                   {'loss': 1.2126, 'grad_norm': 5.329721927642822, 'learning_rate': 1.1506849315068492e-06, 'num_tokens': 244528.0, 'mean_token_accuracy': 0.6731867976486683, 'epoch': 0.03}
  3%|▎         | 42/1449 [14:49<8:12:36, 21.01s/it]  3%|▎         | 43/1449 [15:10<8:12:16, 21.01s/it]                                                   {'loss': 1.178, 'grad_norm': 5.577686786651611, 'learning_rate': 1.178082191780822e-06, 'num_tokens': 250356.0, 'mean_token_accuracy': 0.6719384267926216, 'epoch': 0.03}
  3%|▎         | 43/1449 [15:10<8:12:16, 21.01s/it]  3%|▎         | 44/1449 [15:30<8:10:59, 20.97s/it]                                                   {'loss': 1.1424, 'grad_norm': 5.567782878875732, 'learning_rate': 1.2054794520547945e-06, 'num_tokens': 256463.0, 'mean_token_accuracy': 0.6937804892659187, 'epoch': 0.03}
  3%|▎         | 44/1449 [15:30<8:10:59, 20.97s/it]  3%|▎         | 45/1449 [15:52<8:12:10, 21.03s/it]                                                   {'loss': 1.263, 'grad_norm': 4.855529308319092, 'learning_rate': 1.232876712328767e-06, 'num_tokens': 263402.0, 'mean_token_accuracy': 0.6684509664773941, 'epoch': 0.03}
  3%|▎         | 45/1449 [15:52<8:12:10, 21.03s/it]  3%|▎         | 46/1449 [16:12<8:10:32, 20.98s/it]                                                   {'loss': 1.1312, 'grad_norm': 4.8933305740356445, 'learning_rate': 1.2602739726027396e-06, 'num_tokens': 269073.0, 'mean_token_accuracy': 0.7006328292191029, 'epoch': 0.03}
  3%|▎         | 46/1449 [16:12<8:10:32, 20.98s/it]  3%|▎         | 47/1449 [16:34<8:11:41, 21.04s/it]                                                   {'loss': 1.3152, 'grad_norm': 5.848649501800537, 'learning_rate': 1.2876712328767124e-06, 'num_tokens': 274713.0, 'mean_token_accuracy': 0.658977422863245, 'epoch': 0.03}
  3%|▎         | 47/1449 [16:34<8:11:41, 21.04s/it]  3%|▎         | 48/1449 [16:54<8:10:03, 20.99s/it]                                                   {'loss': 1.2144, 'grad_norm': 5.3240861892700195, 'learning_rate': 1.3150684931506847e-06, 'num_tokens': 280310.0, 'mean_token_accuracy': 0.6800337620079517, 'epoch': 0.03}
  3%|▎         | 48/1449 [16:54<8:10:03, 20.99s/it]  3%|▎         | 49/1449 [17:16<8:11:06, 21.05s/it]                                                   {'loss': 1.1891, 'grad_norm': 5.007350921630859, 'learning_rate': 1.3424657534246575e-06, 'num_tokens': 286192.0, 'mean_token_accuracy': 0.6851340048015118, 'epoch': 0.03}
  3%|▎         | 49/1449 [17:16<8:11:06, 21.05s/it]  3%|▎         | 50/1449 [17:37<8:09:23, 20.99s/it]                                                   {'loss': 1.0799, 'grad_norm': 4.840311527252197, 'learning_rate': 1.36986301369863e-06, 'num_tokens': 292452.0, 'mean_token_accuracy': 0.6927551031112671, 'epoch': 0.03}
  3%|▎         | 50/1449 [17:37<8:09:23, 20.99s/it][INFO|trainer.py:3966] 2025-06-06 00:27:03,035 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50
[INFO|configuration_utils.py:423] 2025-06-06 00:27:03,040 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/config.json
[INFO|configuration_utils.py:908] 2025-06-06 00:27:03,043 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 00:27:11,464 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 00:27:11,467 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 00:27:11,469 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/special_tokens_map.json
[2025-06-06 00:27:11,693] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step50 is about to be saved!
[2025-06-06 00:27:11,700] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 00:27:11,700] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 00:27:11,715] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 00:27:11,716] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 00:27:34,958] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 00:27:35,004] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-50/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 00:27:35,035] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 00:27:46,529 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 00:27:46,531 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
  4%|▎         | 51/1449 [18:44<13:31:22, 34.82s/it]                                                    {'loss': 1.094, 'grad_norm': 4.727295875549316, 'learning_rate': 1.3972602739726028e-06, 'num_tokens': 298737.0, 'mean_token_accuracy': 0.7104731500148773, 'epoch': 0.04}
  4%|▎         | 51/1449 [18:44<13:31:22, 34.82s/it]  4%|▎         | 52/1449 [19:06<12:01:31, 30.99s/it]                                                    {'loss': 1.3792, 'grad_norm': 4.5847625732421875, 'learning_rate': 1.424657534246575e-06, 'num_tokens': 304751.0, 'mean_token_accuracy': 0.6548600681126118, 'epoch': 0.04}
  4%|▎         | 52/1449 [19:06<12:01:31, 30.99s/it]  4%|▎         | 53/1449 [19:28<10:57:13, 28.25s/it]                                                    {'loss': 1.1681, 'grad_norm': 4.1287641525268555, 'learning_rate': 1.4520547945205479e-06, 'num_tokens': 311016.0, 'mean_token_accuracy': 0.6813653185963631, 'epoch': 0.04}
  4%|▎         | 53/1449 [19:28<10:57:13, 28.25s/it]  4%|▎         | 54/1449 [19:49<10:10:53, 26.28s/it]                                                    {'loss': 1.2079, 'grad_norm': 4.447936534881592, 'learning_rate': 1.4794520547945204e-06, 'num_tokens': 317207.0, 'mean_token_accuracy': 0.6782286278903484, 'epoch': 0.04}
  4%|▎         | 54/1449 [19:49<10:10:53, 26.28s/it]  4%|▍         | 55/1449 [20:11<9:40:59, 25.01s/it]                                                    {'loss': 1.289, 'grad_norm': 4.602755069732666, 'learning_rate': 1.5068493150684932e-06, 'num_tokens': 323095.0, 'mean_token_accuracy': 0.6698384955525398, 'epoch': 0.04}
  4%|▍         | 55/1449 [20:11<9:40:59, 25.01s/it]  4%|▍         | 56/1449 [20:33<9:18:12, 24.04s/it]                                                   {'loss': 1.1801, 'grad_norm': 4.4206461906433105, 'learning_rate': 1.5342465753424655e-06, 'num_tokens': 329037.0, 'mean_token_accuracy': 0.6925205439329147, 'epoch': 0.04}
  4%|▍         | 56/1449 [20:33<9:18:12, 24.04s/it]  4%|▍         | 57/1449 [20:55<9:01:46, 23.35s/it]                                                   {'loss': 1.1282, 'grad_norm': 4.293708801269531, 'learning_rate': 1.5616438356164383e-06, 'num_tokens': 335175.0, 'mean_token_accuracy': 0.6979105100035667, 'epoch': 0.04}
  4%|▍         | 57/1449 [20:55<9:01:46, 23.35s/it]  4%|▍         | 58/1449 [21:17<8:50:24, 22.88s/it]                                                   {'loss': 1.1724, 'grad_norm': 4.580864429473877, 'learning_rate': 1.5890410958904108e-06, 'num_tokens': 341195.0, 'mean_token_accuracy': 0.6909306794404984, 'epoch': 0.04}
  4%|▍         | 58/1449 [21:17<8:50:24, 22.88s/it]  4%|▍         | 59/1449 [21:38<8:38:04, 22.36s/it]                                                   {'loss': 1.2432, 'grad_norm': 4.255706310272217, 'learning_rate': 1.6164383561643836e-06, 'num_tokens': 347227.0, 'mean_token_accuracy': 0.6854199059307575, 'epoch': 0.04}
  4%|▍         | 59/1449 [21:38<8:38:04, 22.36s/it]  4%|▍         | 60/1449 [21:59<8:32:06, 22.12s/it]                                                   {'loss': 1.313, 'grad_norm': 4.926303386688232, 'learning_rate': 1.643835616438356e-06, 'num_tokens': 352785.0, 'mean_token_accuracy': 0.6490506902337074, 'epoch': 0.04}
  4%|▍         | 60/1449 [21:59<8:32:06, 22.12s/it]  4%|▍         | 61/1449 [22:20<8:25:32, 21.85s/it]                                                   {'loss': 1.1911, 'grad_norm': 3.8859407901763916, 'learning_rate': 1.6712328767123287e-06, 'num_tokens': 359439.0, 'mean_token_accuracy': 0.6842576004564762, 'epoch': 0.04}
  4%|▍         | 61/1449 [22:20<8:25:32, 21.85s/it]  4%|▍         | 62/1449 [22:42<8:24:27, 21.82s/it]                                                   {'loss': 1.0958, 'grad_norm': 4.224329471588135, 'learning_rate': 1.6986301369863012e-06, 'num_tokens': 365066.0, 'mean_token_accuracy': 0.7124580703675747, 'epoch': 0.04}
  4%|▍         | 62/1449 [22:42<8:24:27, 21.82s/it]  4%|▍         | 63/1449 [23:04<8:22:41, 21.76s/it]                                                   {'loss': 1.2671, 'grad_norm': 3.6484830379486084, 'learning_rate': 1.726027397260274e-06, 'num_tokens': 371548.0, 'mean_token_accuracy': 0.6605844087898731, 'epoch': 0.04}
  4%|▍         | 63/1449 [23:04<8:22:41, 21.76s/it]  4%|▍         | 64/1449 [23:25<8:19:39, 21.65s/it]                                                   {'loss': 1.3362, 'grad_norm': 4.484006881713867, 'learning_rate': 1.7534246575342463e-06, 'num_tokens': 377370.0, 'mean_token_accuracy': 0.657484382390976, 'epoch': 0.04}
  4%|▍         | 64/1449 [23:25<8:19:39, 21.65s/it]  4%|▍         | 65/1449 [23:47<8:17:54, 21.59s/it]                                                   {'loss': 1.3709, 'grad_norm': 4.408581256866455, 'learning_rate': 1.780821917808219e-06, 'num_tokens': 382770.0, 'mean_token_accuracy': 0.6349261067807674, 'epoch': 0.04}
  4%|▍         | 65/1449 [23:47<8:17:54, 21.59s/it]  5%|▍         | 66/1449 [24:08<8:17:19, 21.58s/it]                                                   {'loss': 1.1944, 'grad_norm': 3.8365399837493896, 'learning_rate': 1.8082191780821916e-06, 'num_tokens': 388811.0, 'mean_token_accuracy': 0.6897803321480751, 'epoch': 0.05}
  5%|▍         | 66/1449 [24:08<8:17:19, 21.58s/it]  5%|▍         | 67/1449 [24:30<8:17:10, 21.59s/it]                                                   {'loss': 1.2087, 'grad_norm': 3.78902006149292, 'learning_rate': 1.8356164383561644e-06, 'num_tokens': 394464.0, 'mean_token_accuracy': 0.6752898246049881, 'epoch': 0.05}
  5%|▍         | 67/1449 [24:30<8:17:10, 21.59s/it]  5%|▍         | 68/1449 [24:51<8:16:53, 21.59s/it]                                                   {'loss': 1.2865, 'grad_norm': 4.460819721221924, 'learning_rate': 1.8630136986301367e-06, 'num_tokens': 399635.0, 'mean_token_accuracy': 0.6628098376095295, 'epoch': 0.05}
  5%|▍         | 68/1449 [24:51<8:16:53, 21.59s/it]  5%|▍         | 69/1449 [25:13<8:13:44, 21.47s/it]                                                   {'loss': 1.2592, 'grad_norm': 4.386826515197754, 'learning_rate': 1.8904109589041095e-06, 'num_tokens': 405444.0, 'mean_token_accuracy': 0.6696244217455387, 'epoch': 0.05}
  5%|▍         | 69/1449 [25:13<8:13:44, 21.47s/it]  5%|▍         | 70/1449 [25:34<8:12:43, 21.44s/it]                                                   {'loss': 1.3294, 'grad_norm': 4.6185150146484375, 'learning_rate': 1.917808219178082e-06, 'num_tokens': 410555.0, 'mean_token_accuracy': 0.6447505541145802, 'epoch': 0.05}
  5%|▍         | 70/1449 [25:34<8:12:43, 21.44s/it]  5%|▍         | 71/1449 [25:55<8:10:19, 21.35s/it]                                                   {'loss': 1.2105, 'grad_norm': 4.404342174530029, 'learning_rate': 1.945205479452055e-06, 'num_tokens': 415902.0, 'mean_token_accuracy': 0.6857592314481735, 'epoch': 0.05}
  5%|▍         | 71/1449 [25:55<8:10:19, 21.35s/it]  5%|▍         | 72/1449 [26:17<8:10:30, 21.37s/it]                                                   {'loss': 1.3066, 'grad_norm': 4.2000346183776855, 'learning_rate': 1.9726027397260274e-06, 'num_tokens': 421660.0, 'mean_token_accuracy': 0.6731383576989174, 'epoch': 0.05}
  5%|▍         | 72/1449 [26:17<8:10:30, 21.37s/it]  5%|▌         | 73/1449 [26:38<8:08:14, 21.29s/it]                                                   {'loss': 1.1707, 'grad_norm': 4.382509231567383, 'learning_rate': 2e-06, 'num_tokens': 427651.0, 'mean_token_accuracy': 0.6940111331641674, 'epoch': 0.05}
  5%|▌         | 73/1449 [26:38<8:08:14, 21.29s/it]  5%|▌         | 74/1449 [26:59<8:10:12, 21.39s/it]                                                   {'loss': 1.1725, 'grad_norm': 3.8421847820281982, 'learning_rate': 1.9999973936502537e-06, 'num_tokens': 433328.0, 'mean_token_accuracy': 0.684824887663126, 'epoch': 0.05}
  5%|▌         | 74/1449 [26:59<8:10:12, 21.39s/it]  5%|▌         | 75/1449 [27:21<8:09:39, 21.38s/it]                                                   {'loss': 1.1798, 'grad_norm': 4.005166053771973, 'learning_rate': 1.9999895746146016e-06, 'num_tokens': 438558.0, 'mean_token_accuracy': 0.682864710688591, 'epoch': 0.05}
  5%|▌         | 75/1449 [27:21<8:09:39, 21.38s/it]  5%|▌         | 76/1449 [27:42<8:10:19, 21.43s/it]                                                   {'loss': 1.1836, 'grad_norm': 4.209487438201904, 'learning_rate': 1.9999765429338015e-06, 'num_tokens': 443863.0, 'mean_token_accuracy': 0.6724878251552582, 'epoch': 0.05}
  5%|▌         | 76/1449 [27:42<8:10:19, 21.43s/it]  5%|▌         | 77/1449 [28:03<8:08:59, 21.38s/it]                                                   {'loss': 1.1581, 'grad_norm': 4.719583988189697, 'learning_rate': 1.999958298675784e-06, 'num_tokens': 449438.0, 'mean_token_accuracy': 0.6918859854340553, 'epoch': 0.05}
  5%|▌         | 77/1449 [28:03<8:08:59, 21.38s/it]  5%|▌         | 78/1449 [28:25<8:10:06, 21.45s/it]                                                   {'loss': 1.1421, 'grad_norm': 3.425614595413208, 'learning_rate': 1.99993484193565e-06, 'num_tokens': 455811.0, 'mean_token_accuracy': 0.695323720574379, 'epoch': 0.05}
  5%|▌         | 78/1449 [28:25<8:10:06, 21.45s/it]  5%|▌         | 79/1449 [28:47<8:09:46, 21.45s/it]                                                   {'loss': 1.1437, 'grad_norm': 3.4967751502990723, 'learning_rate': 1.9999061728356743e-06, 'num_tokens': 462123.0, 'mean_token_accuracy': 0.7005429267883301, 'epoch': 0.05}
  5%|▌         | 79/1449 [28:47<8:09:46, 21.45s/it]  6%|▌         | 80/1449 [29:09<8:19:14, 21.88s/it]                                                   {'loss': 1.2408, 'grad_norm': 3.7240185737609863, 'learning_rate': 1.999872291525298e-06, 'num_tokens': 468070.0, 'mean_token_accuracy': 0.6730183474719524, 'epoch': 0.06}
  6%|▌         | 80/1449 [29:09<8:19:14, 21.88s/it]  6%|▌         | 81/1449 [29:31<8:15:31, 21.73s/it]                                                   {'loss': 1.2089, 'grad_norm': 3.973160982131958, 'learning_rate': 1.9998331981811366e-06, 'num_tokens': 474378.0, 'mean_token_accuracy': 0.6665666550397873, 'epoch': 0.06}
  6%|▌         | 81/1449 [29:31<8:15:31, 21.73s/it]  6%|▌         | 82/1449 [29:53<8:16:19, 21.78s/it]                                                   {'loss': 1.3491, 'grad_norm': 3.417583465576172, 'learning_rate': 1.9997888930069695e-06, 'num_tokens': 481490.0, 'mean_token_accuracy': 0.6639391034841537, 'epoch': 0.06}
  6%|▌         | 82/1449 [29:53<8:16:19, 21.78s/it]  6%|▌         | 83/1449 [30:14<8:11:59, 21.61s/it]                                                   {'loss': 1.2766, 'grad_norm': 3.4438364505767822, 'learning_rate': 1.9997393762337483e-06, 'num_tokens': 487793.0, 'mean_token_accuracy': 0.6739641018211842, 'epoch': 0.06}
  6%|▌         | 83/1449 [30:14<8:11:59, 21.61s/it]  6%|▌         | 84/1449 [30:35<8:10:25, 21.56s/it]                                                   {'loss': 1.1603, 'grad_norm': 3.739238739013672, 'learning_rate': 1.9996846481195882e-06, 'num_tokens': 493565.0, 'mean_token_accuracy': 0.6836163885891438, 'epoch': 0.06}
  6%|▌         | 84/1449 [30:35<8:10:25, 21.56s/it]  6%|▌         | 85/1449 [30:57<8:08:30, 21.49s/it]                                                   {'loss': 1.1509, 'grad_norm': 2.9228615760803223, 'learning_rate': 1.99962470894977e-06, 'num_tokens': 501430.0, 'mean_token_accuracy': 0.695604108273983, 'epoch': 0.06}
  6%|▌         | 85/1449 [30:57<8:08:30, 21.49s/it]  6%|▌         | 86/1449 [31:18<8:07:34, 21.46s/it]                                                   {'loss': 1.0142, 'grad_norm': 3.652390241622925, 'learning_rate': 1.9995595590367395e-06, 'num_tokens': 507397.0, 'mean_token_accuracy': 0.7132827155292034, 'epoch': 0.06}
  6%|▌         | 86/1449 [31:18<8:07:34, 21.46s/it]  6%|▌         | 87/1449 [31:39<8:05:44, 21.40s/it]                                                   {'loss': 1.3199, 'grad_norm': 3.3217670917510986, 'learning_rate': 1.999489198720103e-06, 'num_tokens': 514057.0, 'mean_token_accuracy': 0.6746940091252327, 'epoch': 0.06}
  6%|▌         | 87/1449 [31:39<8:05:44, 21.40s/it]  6%|▌         | 88/1449 [32:01<8:05:44, 21.41s/it]                                                   {'loss': 1.2059, 'grad_norm': 4.029082775115967, 'learning_rate': 1.999413628366628e-06, 'num_tokens': 519581.0, 'mean_token_accuracy': 0.6879692934453487, 'epoch': 0.06}
  6%|▌         | 88/1449 [32:01<8:05:44, 21.41s/it]  6%|▌         | 89/1449 [32:22<8:04:00, 21.35s/it]                                                   {'loss': 1.104, 'grad_norm': 4.149223804473877, 'learning_rate': 1.999332848370239e-06, 'num_tokens': 524780.0, 'mean_token_accuracy': 0.6956243850290775, 'epoch': 0.06}
  6%|▌         | 89/1449 [32:22<8:04:00, 21.35s/it]  6%|▌         | 90/1449 [32:43<8:04:46, 21.40s/it]                                                   {'loss': 1.121, 'grad_norm': 3.2865982055664062, 'learning_rate': 1.9992468591520197e-06, 'num_tokens': 531147.0, 'mean_token_accuracy': 0.6945899426937103, 'epoch': 0.06}
  6%|▌         | 90/1449 [32:43<8:04:46, 21.40s/it]  6%|▋         | 91/1449 [33:04<8:01:31, 21.28s/it]                                                   {'loss': 1.1239, 'grad_norm': 3.5720601081848145, 'learning_rate': 1.9991556611602047e-06, 'num_tokens': 536770.0, 'mean_token_accuracy': 0.7041366547346115, 'epoch': 0.06}
  6%|▋         | 91/1449 [33:04<8:01:31, 21.28s/it]  6%|▋         | 92/1449 [33:26<8:01:58, 21.31s/it]                                                   {'loss': 1.1118, 'grad_norm': 3.7350590229034424, 'learning_rate': 1.999059254870182e-06, 'num_tokens': 542831.0, 'mean_token_accuracy': 0.6994865126907825, 'epoch': 0.06}
  6%|▋         | 92/1449 [33:26<8:01:58, 21.31s/it]  6%|▋         | 93/1449 [33:47<8:00:14, 21.25s/it]                                                   {'loss': 1.1241, 'grad_norm': 3.2214839458465576, 'learning_rate': 1.9989576407844892e-06, 'num_tokens': 550883.0, 'mean_token_accuracy': 0.719831820577383, 'epoch': 0.06}
  6%|▋         | 93/1449 [33:47<8:00:14, 21.25s/it]  6%|▋         | 94/1449 [34:08<8:00:18, 21.27s/it]                                                   {'loss': 1.2477, 'grad_norm': 3.829956531524658, 'learning_rate': 1.998850819432809e-06, 'num_tokens': 556288.0, 'mean_token_accuracy': 0.6688572391867638, 'epoch': 0.06}
  6%|▋         | 94/1449 [34:08<8:00:18, 21.27s/it]  7%|▋         | 95/1449 [34:29<7:59:27, 21.25s/it]                                                   {'loss': 1.2187, 'grad_norm': 3.7118732929229736, 'learning_rate': 1.9987387913719697e-06, 'num_tokens': 562473.0, 'mean_token_accuracy': 0.6846107877790928, 'epoch': 0.07}
  7%|▋         | 95/1449 [34:29<7:59:27, 21.25s/it]  7%|▋         | 96/1449 [34:51<7:58:24, 21.22s/it]                                                   {'loss': 1.1001, 'grad_norm': 3.8540761470794678, 'learning_rate': 1.99862155718594e-06, 'num_tokens': 567573.0, 'mean_token_accuracy': 0.706253182142973, 'epoch': 0.07}
  7%|▋         | 96/1449 [34:51<7:58:24, 21.22s/it]  7%|▋         | 97/1449 [35:12<7:58:52, 21.25s/it]                                                   {'loss': 1.0644, 'grad_norm': 3.270458698272705, 'learning_rate': 1.9984991174858256e-06, 'num_tokens': 574284.0, 'mean_token_accuracy': 0.7177176475524902, 'epoch': 0.07}
  7%|▋         | 97/1449 [35:12<7:58:52, 21.25s/it]  7%|▋         | 98/1449 [35:33<7:58:03, 21.23s/it]                                                   {'loss': 1.0846, 'grad_norm': 3.4214606285095215, 'learning_rate': 1.998371472909869e-06, 'num_tokens': 580070.0, 'mean_token_accuracy': 0.7059917338192463, 'epoch': 0.07}
  7%|▋         | 98/1449 [35:33<7:58:03, 21.23s/it]  7%|▋         | 99/1449 [35:55<7:59:57, 21.33s/it]                                                   {'loss': 1.2699, 'grad_norm': 3.742027521133423, 'learning_rate': 1.9982386241234425e-06, 'num_tokens': 585615.0, 'mean_token_accuracy': 0.6626233831048012, 'epoch': 0.07}
  7%|▋         | 99/1449 [35:55<7:59:57, 21.33s/it]  7%|▋         | 100/1449 [36:16<7:56:54, 21.21s/it]                                                    {'loss': 1.0633, 'grad_norm': 3.508953809738159, 'learning_rate': 1.9981005718190466e-06, 'num_tokens': 591484.0, 'mean_token_accuracy': 0.7113370820879936, 'epoch': 0.07}
  7%|▋         | 100/1449 [36:16<7:56:54, 21.21s/it][INFO|trainer.py:3966] 2025-06-06 00:45:41,861 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100
[INFO|configuration_utils.py:423] 2025-06-06 00:45:41,868 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/config.json
[INFO|configuration_utils.py:908] 2025-06-06 00:45:41,870 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 00:45:49,477 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 00:45:49,480 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 00:45:49,482 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/special_tokens_map.json
[2025-06-06 00:45:49,684] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!
[2025-06-06 00:45:49,690] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 00:45:49,690] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 00:45:49,705] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 00:45:49,706] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 00:46:12,742] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 00:46:12,746] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-100/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 00:46:12,776] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 00:46:24,913 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 00:46:24,914 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
  7%|▋         | 101/1449 [37:22<12:58:35, 34.66s/it]                                                     {'loss': 1.2432, 'grad_norm': 3.5928986072540283, 'learning_rate': 1.997957316716307e-06, 'num_tokens': 597285.0, 'mean_token_accuracy': 0.6800919249653816, 'epoch': 0.07}
  7%|▋         | 101/1449 [37:22<12:58:35, 34.66s/it]  7%|▋         | 102/1449 [37:43<11:29:14, 30.70s/it]                                                     {'loss': 1.0792, 'grad_norm': 3.6299076080322266, 'learning_rate': 1.997808859561969e-06, 'num_tokens': 603599.0, 'mean_token_accuracy': 0.7084022872149944, 'epoch': 0.07}
  7%|▋         | 102/1449 [37:43<11:29:14, 30.70s/it]  7%|▋         | 103/1449 [38:05<10:29:12, 28.05s/it]                                                     {'loss': 1.1529, 'grad_norm': 3.915384531021118, 'learning_rate': 1.997655201129896e-06, 'num_tokens': 609700.0, 'mean_token_accuracy': 0.6994268372654915, 'epoch': 0.07}
  7%|▋         | 103/1449 [38:05<10:29:12, 28.05s/it]  7%|▋         | 104/1449 [38:26<9:40:49, 25.91s/it]                                                     {'loss': 1.3042, 'grad_norm': 4.453795909881592, 'learning_rate': 1.997496342221062e-06, 'num_tokens': 615655.0, 'mean_token_accuracy': 0.6664938107132912, 'epoch': 0.07}
  7%|▋         | 104/1449 [38:26<9:40:49, 25.91s/it]  7%|▋         | 105/1449 [38:47<9:09:26, 24.53s/it]                                                    {'loss': 1.1934, 'grad_norm': 3.514329671859741, 'learning_rate': 1.9973322836635515e-06, 'num_tokens': 621406.0, 'mean_token_accuracy': 0.6908078975975513, 'epoch': 0.07}
  7%|▋         | 105/1449 [38:47<9:09:26, 24.53s/it]  7%|▋         | 106/1449 [39:08<8:46:07, 23.51s/it]                                                    {'loss': 1.238, 'grad_norm': 3.636462926864624, 'learning_rate': 1.9971630263125527e-06, 'num_tokens': 627081.0, 'mean_token_accuracy': 0.6675082482397556, 'epoch': 0.07}
  7%|▋         | 106/1449 [39:08<8:46:07, 23.51s/it]  7%|▋         | 107/1449 [39:29<8:29:15, 22.77s/it]                                                    {'loss': 1.2053, 'grad_norm': 3.8723723888397217, 'learning_rate': 1.9969885710503526e-06, 'num_tokens': 632718.0, 'mean_token_accuracy': 0.6787847802042961, 'epoch': 0.07}
  7%|▋         | 107/1449 [39:29<8:29:15, 22.77s/it]  7%|▋         | 108/1449 [39:51<8:18:21, 22.30s/it]                                                    {'loss': 1.2234, 'grad_norm': 3.5273773670196533, 'learning_rate': 1.9968089187863346e-06, 'num_tokens': 639256.0, 'mean_token_accuracy': 0.6765892058610916, 'epoch': 0.07}
  7%|▋         | 108/1449 [39:51<8:18:21, 22.30s/it]  8%|▊         | 109/1449 [40:12<8:09:55, 21.94s/it]                                                    {'loss': 1.1381, 'grad_norm': 3.5243825912475586, 'learning_rate': 1.996624070456972e-06, 'num_tokens': 644653.0, 'mean_token_accuracy': 0.6974524259567261, 'epoch': 0.08}
  8%|▊         | 109/1449 [40:12<8:09:55, 21.94s/it]  8%|▊         | 110/1449 [40:33<8:07:07, 21.83s/it]                                                    {'loss': 1.054, 'grad_norm': 3.4772772789001465, 'learning_rate': 1.996434027025823e-06, 'num_tokens': 650635.0, 'mean_token_accuracy': 0.713633555918932, 'epoch': 0.08}
  8%|▊         | 110/1449 [40:33<8:07:07, 21.83s/it]  8%|▊         | 111/1449 [40:54<8:01:24, 21.59s/it]                                                    {'loss': 1.0464, 'grad_norm': 4.064281940460205, 'learning_rate': 1.996238789483527e-06, 'num_tokens': 655980.0, 'mean_token_accuracy': 0.7129302248358727, 'epoch': 0.08}
  8%|▊         | 111/1449 [40:54<8:01:24, 21.59s/it]  8%|▊         | 112/1449 [41:15<7:57:28, 21.43s/it]                                                    {'loss': 1.0153, 'grad_norm': 3.1313090324401855, 'learning_rate': 1.9960383588478e-06, 'num_tokens': 663061.0, 'mean_token_accuracy': 0.703792117536068, 'epoch': 0.08}
  8%|▊         | 112/1449 [41:15<7:57:28, 21.43s/it]  8%|▊         | 113/1449 [41:36<7:54:09, 21.29s/it]                                                    {'loss': 1.1828, 'grad_norm': 3.831174850463867, 'learning_rate': 1.9958327361634246e-06, 'num_tokens': 667966.0, 'mean_token_accuracy': 0.6853544600307941, 'epoch': 0.08}
  8%|▊         | 113/1449 [41:36<7:54:09, 21.29s/it]  8%|▊         | 114/1449 [41:58<7:54:08, 21.31s/it]                                                    {'loss': 1.2354, 'grad_norm': 3.6404550075531006, 'learning_rate': 1.9956219225022513e-06, 'num_tokens': 673570.0, 'mean_token_accuracy': 0.6707235276699066, 'epoch': 0.08}
  8%|▊         | 114/1449 [41:58<7:54:08, 21.31s/it]  8%|▊         | 115/1449 [42:19<7:52:30, 21.25s/it]                                                    {'loss': 1.0323, 'grad_norm': 3.3157875537872314, 'learning_rate': 1.9954059189631883e-06, 'num_tokens': 679457.0, 'mean_token_accuracy': 0.701542142778635, 'epoch': 0.08}
  8%|▊         | 115/1449 [42:19<7:52:30, 21.25s/it]  8%|▊         | 116/1449 [42:40<7:52:25, 21.26s/it]                                                    {'loss': 1.25, 'grad_norm': 3.8859333992004395, 'learning_rate': 1.9951847266721967e-06, 'num_tokens': 684858.0, 'mean_token_accuracy': 0.677164476364851, 'epoch': 0.08}
  8%|▊         | 116/1449 [42:40<7:52:25, 21.26s/it]  8%|▊         | 117/1449 [43:01<7:50:27, 21.19s/it]                                                    {'loss': 1.035, 'grad_norm': 3.4906747341156006, 'learning_rate': 1.994958346782286e-06, 'num_tokens': 691233.0, 'mean_token_accuracy': 0.7146229930222034, 'epoch': 0.08}
  8%|▊         | 117/1449 [43:01<7:50:27, 21.19s/it]  8%|▊         | 118/1449 [43:22<7:49:47, 21.18s/it]                                                    {'loss': 1.2734, 'grad_norm': 3.6670913696289062, 'learning_rate': 1.994726780473506e-06, 'num_tokens': 697713.0, 'mean_token_accuracy': 0.6700546965003014, 'epoch': 0.08}
  8%|▊         | 118/1449 [43:22<7:49:47, 21.18s/it]  8%|▊         | 119/1449 [43:43<7:48:26, 21.13s/it]                                                    {'loss': 1.1478, 'grad_norm': 3.740386962890625, 'learning_rate': 1.9944900289529425e-06, 'num_tokens': 703454.0, 'mean_token_accuracy': 0.6937252022325993, 'epoch': 0.08}
  8%|▊         | 119/1449 [43:43<7:48:26, 21.13s/it]  8%|▊         | 120/1449 [44:04<7:47:54, 21.12s/it]                                                    {'loss': 1.0139, 'grad_norm': 3.484215497970581, 'learning_rate': 1.99424809345471e-06, 'num_tokens': 709655.0, 'mean_token_accuracy': 0.7172091528773308, 'epoch': 0.08}
  8%|▊         | 120/1449 [44:04<7:47:54, 21.12s/it]  8%|▊         | 121/1449 [44:25<7:47:13, 21.11s/it]                                                    {'loss': 1.0008, 'grad_norm': 3.3514280319213867, 'learning_rate': 1.994000975239946e-06, 'num_tokens': 715647.0, 'mean_token_accuracy': 0.7202360481023788, 'epoch': 0.08}
  8%|▊         | 121/1449 [44:25<7:47:13, 21.11s/it]  8%|▊         | 122/1449 [44:47<7:48:42, 21.19s/it]                                                    {'loss': 1.1505, 'grad_norm': 3.839172840118408, 'learning_rate': 1.9937486755968026e-06, 'num_tokens': 720720.0, 'mean_token_accuracy': 0.6932005845010281, 'epoch': 0.08}
  8%|▊         | 122/1449 [44:47<7:48:42, 21.19s/it]  8%|▊         | 123/1449 [45:08<7:46:53, 21.13s/it]                                                    {'loss': 1.2171, 'grad_norm': 4.103625774383545, 'learning_rate': 1.9934911958404426e-06, 'num_tokens': 726225.0, 'mean_token_accuracy': 0.6740670576691628, 'epoch': 0.08}
  8%|▊         | 123/1449 [45:08<7:46:53, 21.13s/it]  9%|▊         | 124/1449 [45:29<7:47:50, 21.19s/it]                                                    {'loss': 1.0806, 'grad_norm': 3.3962109088897705, 'learning_rate': 1.9932285373130307e-06, 'num_tokens': 732239.0, 'mean_token_accuracy': 0.7098391391336918, 'epoch': 0.09}
  9%|▊         | 124/1449 [45:29<7:47:50, 21.19s/it]  9%|▊         | 125/1449 [45:50<7:47:10, 21.17s/it]                                                    {'loss': 1.0514, 'grad_norm': 4.210345268249512, 'learning_rate': 1.9929607013837265e-06, 'num_tokens': 738199.0, 'mean_token_accuracy': 0.7183676771819592, 'epoch': 0.09}
  9%|▊         | 125/1449 [45:50<7:47:10, 21.17s/it]  9%|▊         | 126/1449 [46:11<7:45:52, 21.13s/it]                                                    {'loss': 1.1614, 'grad_norm': 3.7928972244262695, 'learning_rate': 1.9926876894486786e-06, 'num_tokens': 743699.0, 'mean_token_accuracy': 0.6875493265688419, 'epoch': 0.09}
  9%|▊         | 126/1449 [46:11<7:45:52, 21.13s/it]  9%|▉         | 127/1449 [46:33<7:46:26, 21.17s/it]                                                    {'loss': 1.134, 'grad_norm': 3.8930914402008057, 'learning_rate': 1.9924095029310156e-06, 'num_tokens': 749152.0, 'mean_token_accuracy': 0.690268125385046, 'epoch': 0.09}
  9%|▉         | 127/1449 [46:33<7:46:26, 21.17s/it]  9%|▉         | 128/1449 [46:54<7:45:31, 21.14s/it]                                                    {'loss': 1.0932, 'grad_norm': 2.964303731918335, 'learning_rate': 1.9921261432808406e-06, 'num_tokens': 757072.0, 'mean_token_accuracy': 0.7010632641613483, 'epoch': 0.09}
  9%|▉         | 128/1449 [46:54<7:45:31, 21.14s/it]  9%|▉         | 129/1449 [47:15<7:44:36, 21.12s/it]                                                    {'loss': 1.2118, 'grad_norm': 4.784621238708496, 'learning_rate': 1.991837611975223e-06, 'num_tokens': 761931.0, 'mean_token_accuracy': 0.6808394491672516, 'epoch': 0.09}
  9%|▉         | 129/1449 [47:15<7:44:36, 21.12s/it]  9%|▉         | 130/1449 [47:36<7:43:19, 21.08s/it]                                                    {'loss': 1.1042, 'grad_norm': 3.339601516723633, 'learning_rate': 1.9915439105181882e-06, 'num_tokens': 768780.0, 'mean_token_accuracy': 0.6916160099208355, 'epoch': 0.09}
  9%|▉         | 130/1449 [47:36<7:43:19, 21.08s/it]  9%|▉         | 131/1449 [47:57<7:43:08, 21.08s/it]                                                    {'loss': 1.2285, 'grad_norm': 3.314297676086426, 'learning_rate': 1.9912450404407146e-06, 'num_tokens': 774872.0, 'mean_token_accuracy': 0.66804488748312, 'epoch': 0.09}
  9%|▉         | 131/1449 [47:57<7:43:08, 21.08s/it]  9%|▉         | 132/1449 [48:18<7:43:50, 21.13s/it]                                                    {'loss': 1.1048, 'grad_norm': 3.2972769737243652, 'learning_rate': 1.9909410033007226e-06, 'num_tokens': 780876.0, 'mean_token_accuracy': 0.7003388069570065, 'epoch': 0.09}
  9%|▉         | 132/1449 [48:18<7:43:50, 21.13s/it]  9%|▉         | 133/1449 [48:39<7:44:14, 21.17s/it]                                                    {'loss': 0.8937, 'grad_norm': 3.307779550552368, 'learning_rate': 1.9906318006830658e-06, 'num_tokens': 787345.0, 'mean_token_accuracy': 0.747828584164381, 'epoch': 0.09}
  9%|▉         | 133/1449 [48:39<7:44:14, 21.17s/it]  9%|▉         | 134/1449 [49:00<7:43:03, 21.13s/it]                                                    {'loss': 1.1232, 'grad_norm': 4.145519256591797, 'learning_rate': 1.990317434199524e-06, 'num_tokens': 792481.0, 'mean_token_accuracy': 0.6910422891378403, 'epoch': 0.09}
  9%|▉         | 134/1449 [49:00<7:43:03, 21.13s/it]  9%|▉         | 135/1449 [49:21<7:41:53, 21.09s/it]                                                    {'loss': 1.0551, 'grad_norm': 3.6072003841400146, 'learning_rate': 1.989997905488796e-06, 'num_tokens': 798676.0, 'mean_token_accuracy': 0.725806750357151, 'epoch': 0.09}
  9%|▉         | 135/1449 [49:21<7:41:53, 21.09s/it]  9%|▉         | 136/1449 [49:42<7:41:21, 21.08s/it]                                                    {'loss': 1.1657, 'grad_norm': 3.6696622371673584, 'learning_rate': 1.989673216216489e-06, 'num_tokens': 804132.0, 'mean_token_accuracy': 0.686094481498003, 'epoch': 0.09}
  9%|▉         | 136/1449 [49:42<7:41:21, 21.08s/it]  9%|▉         | 137/1449 [50:04<7:41:33, 21.11s/it]                                                    {'loss': 1.1775, 'grad_norm': 3.4896576404571533, 'learning_rate': 1.98934336807511e-06, 'num_tokens': 810359.0, 'mean_token_accuracy': 0.6761049441993237, 'epoch': 0.09}
  9%|▉         | 137/1449 [50:04<7:41:33, 21.11s/it] 10%|▉         | 138/1449 [50:25<7:41:19, 21.11s/it]                                                    {'loss': 1.0962, 'grad_norm': 3.345351457595825, 'learning_rate': 1.989008362784059e-06, 'num_tokens': 816440.0, 'mean_token_accuracy': 0.7034718096256256, 'epoch': 0.1}
 10%|▉         | 138/1449 [50:25<7:41:19, 21.11s/it] 10%|▉         | 139/1449 [50:46<7:42:08, 21.17s/it]                                                    {'loss': 1.0928, 'grad_norm': 3.9423604011535645, 'learning_rate': 1.988668202089617e-06, 'num_tokens': 822042.0, 'mean_token_accuracy': 0.6965447403490543, 'epoch': 0.1}
 10%|▉         | 139/1449 [50:46<7:42:08, 21.17s/it] 10%|▉         | 140/1449 [51:07<7:41:21, 21.15s/it]                                                    {'loss': 1.1841, 'grad_norm': 3.6523141860961914, 'learning_rate': 1.9883228877649404e-06, 'num_tokens': 827623.0, 'mean_token_accuracy': 0.6757527999579906, 'epoch': 0.1}
 10%|▉         | 140/1449 [51:07<7:41:21, 21.15s/it] 10%|▉         | 141/1449 [51:28<7:40:37, 21.13s/it]                                                    {'loss': 1.057, 'grad_norm': 3.1883702278137207, 'learning_rate': 1.9879724216100485e-06, 'num_tokens': 834055.0, 'mean_token_accuracy': 0.6996453739702702, 'epoch': 0.1}
 10%|▉         | 141/1449 [51:28<7:40:37, 21.13s/it] 10%|▉         | 142/1449 [51:49<7:40:30, 21.14s/it]                                                    {'loss': 0.9135, 'grad_norm': 3.2469558715820312, 'learning_rate': 1.987616805451816e-06, 'num_tokens': 840140.0, 'mean_token_accuracy': 0.740001730620861, 'epoch': 0.1}
 10%|▉         | 142/1449 [51:49<7:40:30, 21.14s/it] 10%|▉         | 143/1449 [52:11<7:40:43, 21.17s/it]                                                    {'loss': 1.1515, 'grad_norm': 3.686568021774292, 'learning_rate': 1.987256041143963e-06, 'num_tokens': 845993.0, 'mean_token_accuracy': 0.6843956932425499, 'epoch': 0.1}
 10%|▉         | 143/1449 [52:11<7:40:43, 21.17s/it] 10%|▉         | 144/1449 [52:32<7:39:39, 21.13s/it]                                                    {'loss': 1.1196, 'grad_norm': 3.6605637073516846, 'learning_rate': 1.986890130567046e-06, 'num_tokens': 851630.0, 'mean_token_accuracy': 0.6986645348370075, 'epoch': 0.1}
 10%|▉         | 144/1449 [52:32<7:39:39, 21.13s/it] 10%|█         | 145/1449 [52:53<7:38:42, 21.11s/it]                                                    {'loss': 0.9851, 'grad_norm': 2.9832963943481445, 'learning_rate': 1.9865190756284466e-06, 'num_tokens': 859008.0, 'mean_token_accuracy': 0.7306069955229759, 'epoch': 0.1}
 10%|█         | 145/1449 [52:53<7:38:42, 21.11s/it] 10%|█         | 146/1449 [53:14<7:37:29, 21.07s/it]                                                    {'loss': 1.0989, 'grad_norm': 4.02080774307251, 'learning_rate': 1.9861428782623623e-06, 'num_tokens': 864463.0, 'mean_token_accuracy': 0.6963517591357231, 'epoch': 0.1}
 10%|█         | 146/1449 [53:14<7:37:29, 21.07s/it] 10%|█         | 147/1449 [53:35<7:37:21, 21.08s/it]                                                    {'loss': 1.0073, 'grad_norm': 3.489738702774048, 'learning_rate': 1.985761540429797e-06, 'num_tokens': 870798.0, 'mean_token_accuracy': 0.7180332653224468, 'epoch': 0.1}
 10%|█         | 147/1449 [53:35<7:37:21, 21.08s/it] 10%|█         | 148/1449 [53:56<7:36:56, 21.07s/it]                                                    {'loss': 1.1701, 'grad_norm': 3.893097162246704, 'learning_rate': 1.985375064118551e-06, 'num_tokens': 876332.0, 'mean_token_accuracy': 0.6904609501361847, 'epoch': 0.1}
 10%|█         | 148/1449 [53:56<7:36:56, 21.07s/it] 10%|█         | 149/1449 [54:17<7:37:09, 21.10s/it]                                                    {'loss': 1.0776, 'grad_norm': 3.701277017593384, 'learning_rate': 1.9849834513432083e-06, 'num_tokens': 882270.0, 'mean_token_accuracy': 0.6986289694905281, 'epoch': 0.1}
 10%|█         | 149/1449 [54:17<7:37:09, 21.10s/it] 10%|█         | 150/1449 [54:38<7:37:54, 21.15s/it]                                                    {'loss': 1.2175, 'grad_norm': 3.9822733402252197, 'learning_rate': 1.984586704145129e-06, 'num_tokens': 888183.0, 'mean_token_accuracy': 0.6899558901786804, 'epoch': 0.1}
 10%|█         | 150/1449 [54:38<7:37:54, 21.15s/it][INFO|trainer.py:3966] 2025-06-06 01:04:04,445 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150
[INFO|configuration_utils.py:423] 2025-06-06 01:04:04,450 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/config.json
[INFO|configuration_utils.py:908] 2025-06-06 01:04:04,452 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 01:04:12,075 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 01:04:12,078 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 01:04:12,080 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/special_tokens_map.json
[2025-06-06 01:04:12,281] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step150 is about to be saved!
[2025-06-06 01:04:12,287] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/global_step150/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 01:04:12,287] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/global_step150/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 01:04:12,302] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/global_step150/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 01:04:12,303] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/global_step150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 01:04:32,490] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/global_step150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 01:04:32,495] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-150/global_step150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 01:04:32,525] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step150 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 01:04:44,502 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 01:04:44,504 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 10%|█         | 151/1449 [55:41<12:06:18, 33.57s/it]                                                     {'loss': 1.2222, 'grad_norm': 3.8256468772888184, 'learning_rate': 1.984184824592437e-06, 'num_tokens': 894654.0, 'mean_token_accuracy': 0.6773342005908489, 'epoch': 0.1}
 10%|█         | 151/1449 [55:41<12:06:18, 33.57s/it] 10%|█         | 152/1449 [56:02<10:46:56, 29.93s/it]                                                     {'loss': 1.0806, 'grad_norm': 3.3033201694488525, 'learning_rate': 1.983777814780009e-06, 'num_tokens': 901220.0, 'mean_token_accuracy': 0.702939685434103, 'epoch': 0.1}
 10%|█         | 152/1449 [56:02<10:46:56, 29.93s/it] 11%|█         | 153/1449 [56:23<9:50:31, 27.34s/it]                                                     {'loss': 0.9565, 'grad_norm': 3.2964043617248535, 'learning_rate': 1.983365676829466e-06, 'num_tokens': 907624.0, 'mean_token_accuracy': 0.7321620993316174, 'epoch': 0.11}
 11%|█         | 153/1449 [56:23<9:50:31, 27.34s/it] 11%|█         | 154/1449 [56:45<9:10:16, 25.50s/it]                                                    {'loss': 1.1219, 'grad_norm': 3.588172435760498, 'learning_rate': 1.982948412889159e-06, 'num_tokens': 913153.0, 'mean_token_accuracy': 0.6904099956154823, 'epoch': 0.11}
 11%|█         | 154/1449 [56:45<9:10:16, 25.50s/it] 11%|█         | 155/1449 [57:06<8:40:05, 24.12s/it]                                                    {'loss': 1.2413, 'grad_norm': 3.682539463043213, 'learning_rate': 1.9825260251341585e-06, 'num_tokens': 918970.0, 'mean_token_accuracy': 0.672460675239563, 'epoch': 0.11}
 11%|█         | 155/1449 [57:06<8:40:05, 24.12s/it] 11%|█         | 156/1449 [57:27<8:20:24, 23.22s/it]                                                    {'loss': 1.0925, 'grad_norm': 3.640619993209839, 'learning_rate': 1.9820985157662458e-06, 'num_tokens': 924048.0, 'mean_token_accuracy': 0.6943977996706963, 'epoch': 0.11}
 11%|█         | 156/1449 [57:27<8:20:24, 23.22s/it] 11%|█         | 157/1449 [57:48<8:05:33, 22.55s/it]                                                    {'loss': 1.1115, 'grad_norm': 3.9369993209838867, 'learning_rate': 1.981665887013899e-06, 'num_tokens': 929485.0, 'mean_token_accuracy': 0.6936537772417068, 'epoch': 0.11}
 11%|█         | 157/1449 [57:48<8:05:33, 22.55s/it] 11%|█         | 158/1449 [58:09<7:57:18, 22.18s/it]                                                    {'loss': 1.1855, 'grad_norm': 3.780571937561035, 'learning_rate': 1.9812281411322812e-06, 'num_tokens': 934663.0, 'mean_token_accuracy': 0.6853632219135761, 'epoch': 0.11}
 11%|█         | 158/1449 [58:09<7:57:18, 22.18s/it] 11%|█         | 159/1449 [58:30<7:49:48, 21.85s/it]                                                    {'loss': 1.0703, 'grad_norm': 3.1895179748535156, 'learning_rate': 1.98078528040323e-06, 'num_tokens': 941097.0, 'mean_token_accuracy': 0.7088737562298775, 'epoch': 0.11}
 11%|█         | 159/1449 [58:30<7:49:48, 21.85s/it] 11%|█         | 160/1449 [58:51<7:43:39, 21.58s/it]                                                    {'loss': 1.0622, 'grad_norm': 3.3022513389587402, 'learning_rate': 1.9803373071352464e-06, 'num_tokens': 947599.0, 'mean_token_accuracy': 0.7014632187783718, 'epoch': 0.11}
 11%|█         | 160/1449 [58:51<7:43:39, 21.58s/it] 11%|█         | 161/1449 [59:12<7:41:31, 21.50s/it]                                                    {'loss': 1.069, 'grad_norm': 3.1346354484558105, 'learning_rate': 1.9798842236634796e-06, 'num_tokens': 953880.0, 'mean_token_accuracy': 0.7025071792304516, 'epoch': 0.11}
 11%|█         | 161/1449 [59:12<7:41:31, 21.50s/it] 11%|█         | 162/1449 [59:33<7:37:09, 21.31s/it]                                                    {'loss': 0.9863, 'grad_norm': 3.1019997596740723, 'learning_rate': 1.979426032349717e-06, 'num_tokens': 960597.0, 'mean_token_accuracy': 0.7232064642012119, 'epoch': 0.11}
 11%|█         | 162/1449 [59:33<7:37:09, 21.31s/it] 11%|█         | 163/1449 [59:55<7:36:31, 21.30s/it]                                                    {'loss': 1.0894, 'grad_norm': 3.520325183868408, 'learning_rate': 1.9789627355823733e-06, 'num_tokens': 966655.0, 'mean_token_accuracy': 0.6967337168753147, 'epoch': 0.11}
 11%|█         | 163/1449 [59:55<7:36:31, 21.30s/it] 11%|█▏        | 164/1449 [1:00:15<7:33:30, 21.18s/it]                                                      {'loss': 1.2354, 'grad_norm': 3.2161200046539307, 'learning_rate': 1.9784943357764748e-06, 'num_tokens': 973439.0, 'mean_token_accuracy': 0.6909656971693039, 'epoch': 0.11}
 11%|█▏        | 164/1449 [1:00:15<7:33:30, 21.18s/it] 11%|█▏        | 165/1449 [1:00:37<7:33:48, 21.21s/it]                                                      {'loss': 1.1902, 'grad_norm': 4.02310037612915, 'learning_rate': 1.9780208353736494e-06, 'num_tokens': 978862.0, 'mean_token_accuracy': 0.677106462419033, 'epoch': 0.11}
 11%|█▏        | 165/1449 [1:00:37<7:33:48, 21.21s/it] 11%|█▏        | 166/1449 [1:00:58<7:32:10, 21.15s/it]                                                      {'loss': 1.2531, 'grad_norm': 3.6734416484832764, 'learning_rate': 1.9775422368421117e-06, 'num_tokens': 985163.0, 'mean_token_accuracy': 0.6702712401747704, 'epoch': 0.11}
 11%|█▏        | 166/1449 [1:00:58<7:32:10, 21.15s/it] 12%|█▏        | 167/1449 [1:01:19<7:31:43, 21.14s/it]                                                      {'loss': 1.1256, 'grad_norm': 3.44047474861145, 'learning_rate': 1.9770585426766525e-06, 'num_tokens': 991441.0, 'mean_token_accuracy': 0.698466818779707, 'epoch': 0.12}
 12%|█▏        | 167/1449 [1:01:19<7:31:43, 21.14s/it] 12%|█▏        | 168/1449 [1:01:40<7:33:02, 21.22s/it]                                                      {'loss': 1.0207, 'grad_norm': 3.3140647411346436, 'learning_rate': 1.9765697553986234e-06, 'num_tokens': 997227.0, 'mean_token_accuracy': 0.717526514083147, 'epoch': 0.12}
 12%|█▏        | 168/1449 [1:01:40<7:33:02, 21.22s/it] 12%|█▏        | 169/1449 [1:02:01<7:30:16, 21.11s/it]                                                      {'loss': 1.1349, 'grad_norm': 3.4488744735717773, 'learning_rate': 1.9760758775559273e-06, 'num_tokens': 1003808.0, 'mean_token_accuracy': 0.6773999705910683, 'epoch': 0.12}
 12%|█▏        | 169/1449 [1:02:01<7:30:16, 21.11s/it] 12%|█▏        | 170/1449 [1:02:22<7:30:40, 21.14s/it]                                                      {'loss': 1.224, 'grad_norm': 3.694681167602539, 'learning_rate': 1.975576911722999e-06, 'num_tokens': 1009447.0, 'mean_token_accuracy': 0.6852381266653538, 'epoch': 0.12}
 12%|█▏        | 170/1449 [1:02:22<7:30:40, 21.14s/it] 12%|█▏        | 171/1449 [1:02:44<7:31:32, 21.20s/it]                                                      {'loss': 1.1036, 'grad_norm': 3.2892110347747803, 'learning_rate': 1.9750728605007987e-06, 'num_tokens': 1015512.0, 'mean_token_accuracy': 0.7005756981670856, 'epoch': 0.12}
 12%|█▏        | 171/1449 [1:02:44<7:31:32, 21.20s/it] 12%|█▏        | 172/1449 [1:03:05<7:29:58, 21.14s/it]                                                      {'loss': 1.0482, 'grad_norm': 3.3459291458129883, 'learning_rate': 1.9745637265167935e-06, 'num_tokens': 1021788.0, 'mean_token_accuracy': 0.7051553279161453, 'epoch': 0.12}
 12%|█▏        | 172/1449 [1:03:05<7:29:58, 21.14s/it] 12%|█▏        | 173/1449 [1:03:26<7:29:47, 21.15s/it]                                                      {'loss': 1.035, 'grad_norm': 4.024381637573242, 'learning_rate': 1.974049512424946e-06, 'num_tokens': 1026926.0, 'mean_token_accuracy': 0.7188173346221447, 'epoch': 0.12}
 12%|█▏        | 173/1449 [1:03:26<7:29:47, 21.15s/it] 12%|█▏        | 174/1449 [1:03:47<7:27:15, 21.05s/it]                                                      {'loss': 1.0969, 'grad_norm': 3.4474775791168213, 'learning_rate': 1.9735302209056995e-06, 'num_tokens': 1032885.0, 'mean_token_accuracy': 0.6836987026035786, 'epoch': 0.12}
 12%|█▏        | 174/1449 [1:03:47<7:27:15, 21.05s/it] 12%|█▏        | 175/1449 [1:04:08<7:28:21, 21.12s/it]                                                      {'loss': 1.085, 'grad_norm': 3.2910308837890625, 'learning_rate': 1.973005854665965e-06, 'num_tokens': 1039063.0, 'mean_token_accuracy': 0.6947801187634468, 'epoch': 0.12}
 12%|█▏        | 175/1449 [1:04:08<7:28:21, 21.12s/it] 12%|█▏        | 176/1449 [1:04:29<7:27:07, 21.07s/it]                                                      {'loss': 1.1172, 'grad_norm': 3.3604307174682617, 'learning_rate': 1.972476416439106e-06, 'num_tokens': 1045654.0, 'mean_token_accuracy': 0.6962970867753029, 'epoch': 0.12}
 12%|█▏        | 176/1449 [1:04:29<7:27:07, 21.07s/it] 12%|█▏        | 177/1449 [1:04:50<7:26:42, 21.07s/it]                                                      {'loss': 1.1246, 'grad_norm': 3.6420252323150635, 'learning_rate': 1.9719419089849245e-06, 'num_tokens': 1051272.0, 'mean_token_accuracy': 0.6989198923110962, 'epoch': 0.12}
 12%|█▏        | 177/1449 [1:04:50<7:26:42, 21.07s/it] 12%|█▏        | 178/1449 [1:05:11<7:28:09, 21.16s/it]                                                      {'loss': 1.2262, 'grad_norm': 3.469656229019165, 'learning_rate': 1.971402335089648e-06, 'num_tokens': 1057395.0, 'mean_token_accuracy': 0.6698684096336365, 'epoch': 0.12}
 12%|█▏        | 178/1449 [1:05:11<7:28:09, 21.16s/it] 12%|█▏        | 179/1449 [1:05:32<7:26:00, 21.07s/it]                                                      {'loss': 1.0496, 'grad_norm': 3.8786118030548096, 'learning_rate': 1.9708576975659123e-06, 'num_tokens': 1063419.0, 'mean_token_accuracy': 0.7078604362905025, 'epoch': 0.12}
 12%|█▏        | 179/1449 [1:05:32<7:26:00, 21.07s/it] 12%|█▏        | 180/1449 [1:05:53<7:26:02, 21.09s/it]                                                      {'loss': 1.1105, 'grad_norm': 3.430292844772339, 'learning_rate': 1.9703079992527495e-06, 'num_tokens': 1069126.0, 'mean_token_accuracy': 0.6989178881049156, 'epoch': 0.12}
 12%|█▏        | 180/1449 [1:05:53<7:26:02, 21.09s/it] 12%|█▏        | 181/1449 [1:06:14<7:24:55, 21.05s/it]                                                      {'loss': 1.1481, 'grad_norm': 3.3993313312530518, 'learning_rate': 1.9697532430155715e-06, 'num_tokens': 1075156.0, 'mean_token_accuracy': 0.6908732354640961, 'epoch': 0.12}
 12%|█▏        | 181/1449 [1:06:14<7:24:55, 21.05s/it] 13%|█▎        | 182/1449 [1:06:35<7:24:29, 21.05s/it]                                                      {'loss': 1.0525, 'grad_norm': 3.628167152404785, 'learning_rate': 1.969193431746156e-06, 'num_tokens': 1081300.0, 'mean_token_accuracy': 0.7146540209650993, 'epoch': 0.13}
 13%|█▎        | 182/1449 [1:06:35<7:24:29, 21.05s/it] 13%|█▎        | 183/1449 [1:06:57<7:26:07, 21.14s/it]                                                      {'loss': 1.0271, 'grad_norm': 3.1376116275787354, 'learning_rate': 1.9686285683626313e-06, 'num_tokens': 1088034.0, 'mean_token_accuracy': 0.7051366530358791, 'epoch': 0.13}
 13%|█▎        | 183/1449 [1:06:57<7:26:07, 21.14s/it] 13%|█▎        | 184/1449 [1:07:18<7:24:30, 21.08s/it]                                                      {'loss': 1.0633, 'grad_norm': 3.3445472717285156, 'learning_rate': 1.96805865580946e-06, 'num_tokens': 1094309.0, 'mean_token_accuracy': 0.7213996462523937, 'epoch': 0.13}
 13%|█▎        | 184/1449 [1:07:18<7:24:30, 21.08s/it] 13%|█▎        | 185/1449 [1:07:39<7:23:52, 21.07s/it]                                                      {'loss': 1.1681, 'grad_norm': 3.7825441360473633, 'learning_rate': 1.9674836970574253e-06, 'num_tokens': 1100468.0, 'mean_token_accuracy': 0.6927823945879936, 'epoch': 0.13}
 13%|█▎        | 185/1449 [1:07:39<7:23:52, 21.07s/it] 13%|█▎        | 186/1449 [1:08:00<7:23:59, 21.09s/it]                                                      {'loss': 0.946, 'grad_norm': 3.5693793296813965, 'learning_rate': 1.966903695103614e-06, 'num_tokens': 1106079.0, 'mean_token_accuracy': 0.7331980317831039, 'epoch': 0.13}
 13%|█▎        | 186/1449 [1:08:00<7:23:59, 21.09s/it] 13%|█▎        | 187/1449 [1:08:21<7:24:49, 21.15s/it]                                                      {'loss': 1.0929, 'grad_norm': 3.821115732192993, 'learning_rate': 1.966318652971402e-06, 'num_tokens': 1111176.0, 'mean_token_accuracy': 0.6980177313089371, 'epoch': 0.13}
 13%|█▎        | 187/1449 [1:08:21<7:24:49, 21.15s/it] 13%|█▎        | 188/1449 [1:08:42<7:23:43, 21.11s/it]                                                      {'loss': 1.1053, 'grad_norm': 3.330688714981079, 'learning_rate': 1.9657285737104386e-06, 'num_tokens': 1117044.0, 'mean_token_accuracy': 0.7028811424970627, 'epoch': 0.13}
 13%|█▎        | 188/1449 [1:08:42<7:23:43, 21.11s/it] 13%|█▎        | 189/1449 [1:09:03<7:23:08, 21.10s/it]                                                      {'loss': 1.0954, 'grad_norm': 3.876784324645996, 'learning_rate': 1.9651334603966294e-06, 'num_tokens': 1122871.0, 'mean_token_accuracy': 0.6965466253459454, 'epoch': 0.13}
 13%|█▎        | 189/1449 [1:09:03<7:23:08, 21.10s/it] 13%|█▎        | 190/1449 [1:09:24<7:22:51, 21.11s/it]                                                      {'loss': 1.1943, 'grad_norm': 3.5441336631774902, 'learning_rate': 1.964533316132121e-06, 'num_tokens': 1129995.0, 'mean_token_accuracy': 0.6883018873631954, 'epoch': 0.13}
 13%|█▎        | 190/1449 [1:09:24<7:22:51, 21.11s/it] 13%|█▎        | 191/1449 [1:09:45<7:22:38, 21.11s/it]                                                      {'loss': 1.1162, 'grad_norm': 3.574220657348633, 'learning_rate': 1.9639281440452853e-06, 'num_tokens': 1135272.0, 'mean_token_accuracy': 0.6895882487297058, 'epoch': 0.13}
 13%|█▎        | 191/1449 [1:09:45<7:22:38, 21.11s/it] 13%|█▎        | 192/1449 [1:10:07<7:22:23, 21.12s/it]                                                      {'loss': 1.1706, 'grad_norm': 3.4028398990631104, 'learning_rate': 1.9633179472907033e-06, 'num_tokens': 1141180.0, 'mean_token_accuracy': 0.698941633105278, 'epoch': 0.13}
 13%|█▎        | 192/1449 [1:10:07<7:22:23, 21.12s/it] 13%|█▎        | 193/1449 [1:10:28<7:21:26, 21.09s/it]                                                      {'loss': 0.9923, 'grad_norm': 3.7840702533721924, 'learning_rate': 1.9627027290491456e-06, 'num_tokens': 1147171.0, 'mean_token_accuracy': 0.7237817645072937, 'epoch': 0.13}
 13%|█▎        | 193/1449 [1:10:28<7:21:26, 21.09s/it] 13%|█▎        | 194/1449 [1:10:49<7:22:26, 21.15s/it]                                                      {'loss': 1.0751, 'grad_norm': 3.003696918487549, 'learning_rate': 1.9620824925275616e-06, 'num_tokens': 1154344.0, 'mean_token_accuracy': 0.7106792777776718, 'epoch': 0.13}
 13%|█▎        | 194/1449 [1:10:49<7:22:26, 21.15s/it] 13%|█▎        | 195/1449 [1:11:10<7:20:59, 21.10s/it]                                                      {'loss': 0.9621, 'grad_norm': 3.737980365753174, 'learning_rate': 1.9614572409590574e-06, 'num_tokens': 1160742.0, 'mean_token_accuracy': 0.7312122136354446, 'epoch': 0.13}
 13%|█▎        | 195/1449 [1:11:10<7:20:59, 21.10s/it] 14%|█▎        | 196/1449 [1:11:31<7:20:11, 21.08s/it]                                                      {'loss': 1.133, 'grad_norm': 3.524752616882324, 'learning_rate': 1.960826977602881e-06, 'num_tokens': 1166906.0, 'mean_token_accuracy': 0.690352488309145, 'epoch': 0.14}
 14%|█▎        | 196/1449 [1:11:31<7:20:11, 21.08s/it] 14%|█▎        | 197/1449 [1:11:52<7:19:28, 21.06s/it]                                                      {'loss': 1.1643, 'grad_norm': 3.674575090408325, 'learning_rate': 1.960191705744407e-06, 'num_tokens': 1172788.0, 'mean_token_accuracy': 0.6956650279462337, 'epoch': 0.14}
 14%|█▎        | 197/1449 [1:11:52<7:19:28, 21.06s/it] 14%|█▎        | 198/1449 [1:12:13<7:18:42, 21.04s/it]                                                      {'loss': 1.0909, 'grad_norm': 3.862072467803955, 'learning_rate': 1.9595514286951153e-06, 'num_tokens': 1178405.0, 'mean_token_accuracy': 0.7059258669614792, 'epoch': 0.14}
 14%|█▎        | 198/1449 [1:12:13<7:18:42, 21.04s/it] 14%|█▎        | 199/1449 [1:12:34<7:18:40, 21.06s/it]                                                      {'loss': 1.1346, 'grad_norm': 3.7736637592315674, 'learning_rate': 1.9589061497925786e-06, 'num_tokens': 1184403.0, 'mean_token_accuracy': 0.6902900077402592, 'epoch': 0.14}
 14%|█▎        | 199/1449 [1:12:34<7:18:40, 21.06s/it] 14%|█▍        | 200/1449 [1:12:55<7:18:53, 21.08s/it]                                                      {'loss': 1.0081, 'grad_norm': 3.27412486076355, 'learning_rate': 1.958255872400442e-06, 'num_tokens': 1190769.0, 'mean_token_accuracy': 0.7267574369907379, 'epoch': 0.14}
 14%|█▍        | 200/1449 [1:12:55<7:18:53, 21.08s/it][INFO|trainer.py:3966] 2025-06-06 01:22:21,790 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200
[INFO|configuration_utils.py:423] 2025-06-06 01:22:21,829 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/config.json
[INFO|configuration_utils.py:908] 2025-06-06 01:22:21,832 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 01:22:30,185 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 01:22:30,189 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 01:22:30,191 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/special_tokens_map.json
[2025-06-06 01:22:30,410] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step200 is about to be saved!
[2025-06-06 01:22:30,416] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/global_step200/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 01:22:30,417] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/global_step200/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 01:22:30,432] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/global_step200/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 01:22:30,433] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 01:22:51,827] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 01:22:51,832] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 01:22:51,936] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step200 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 01:23:03,456 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 01:23:03,458 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 14%|█▍        | 201/1449 [1:13:59<11:48:36, 34.07s/it]                                                       {'loss': 1.1484, 'grad_norm': 3.768421173095703, 'learning_rate': 1.957600599908406e-06, 'num_tokens': 1197039.0, 'mean_token_accuracy': 0.694625910371542, 'epoch': 0.14}
 14%|█▍        | 201/1449 [1:13:59<11:48:36, 34.07s/it] 14%|█▍        | 202/1449 [1:14:21<10:30:55, 30.36s/it]                                                       {'loss': 1.065, 'grad_norm': 3.8934812545776367, 'learning_rate': 1.956940335732209e-06, 'num_tokens': 1202922.0, 'mean_token_accuracy': 0.7009630501270294, 'epoch': 0.14}
 14%|█▍        | 202/1449 [1:14:21<10:30:55, 30.36s/it] 14%|█▍        | 203/1449 [1:14:42<9:32:49, 27.58s/it]                                                       {'loss': 1.1364, 'grad_norm': 3.5434632301330566, 'learning_rate': 1.9562750833136094e-06, 'num_tokens': 1209369.0, 'mean_token_accuracy': 0.6981213949620724, 'epoch': 0.14}
 14%|█▍        | 203/1449 [1:14:42<9:32:49, 27.58s/it] 14%|█▍        | 204/1449 [1:15:04<8:53:18, 25.70s/it]                                                      {'loss': 0.9988, 'grad_norm': 3.5275962352752686, 'learning_rate': 1.955604846120369e-06, 'num_tokens': 1215178.0, 'mean_token_accuracy': 0.7172366566956043, 'epoch': 0.14}
 14%|█▍        | 204/1449 [1:15:04<8:53:18, 25.70s/it] 14%|█▍        | 205/1449 [1:15:25<8:25:00, 24.36s/it]                                                      {'loss': 1.0749, 'grad_norm': 3.402886152267456, 'learning_rate': 1.9549296276462325e-06, 'num_tokens': 1221531.0, 'mean_token_accuracy': 0.7154067903757095, 'epoch': 0.14}
 14%|█▍        | 205/1449 [1:15:25<8:25:00, 24.36s/it] 14%|█▍        | 206/1449 [1:15:46<8:03:18, 23.33s/it]                                                      {'loss': 1.1604, 'grad_norm': 4.8381428718566895, 'learning_rate': 1.9542494314109106e-06, 'num_tokens': 1226206.0, 'mean_token_accuracy': 0.6895192600786686, 'epoch': 0.14}
 14%|█▍        | 206/1449 [1:15:46<8:03:18, 23.33s/it] 14%|█▍        | 207/1449 [1:16:07<7:49:59, 22.70s/it]                                                      {'loss': 1.1306, 'grad_norm': 3.814281940460205, 'learning_rate': 1.953564260960062e-06, 'num_tokens': 1232532.0, 'mean_token_accuracy': 0.6961793191730976, 'epoch': 0.14}
 14%|█▍        | 207/1449 [1:16:07<7:49:59, 22.70s/it] 14%|█▍        | 208/1449 [1:16:28<7:39:03, 22.19s/it]                                                      {'loss': 1.0799, 'grad_norm': 3.178621530532837, 'learning_rate': 1.952874119865275e-06, 'num_tokens': 1238811.0, 'mean_token_accuracy': 0.7013346962630749, 'epoch': 0.14}
 14%|█▍        | 208/1449 [1:16:28<7:39:03, 22.19s/it] 14%|█▍        | 209/1449 [1:16:49<7:32:40, 21.90s/it]                                                      {'loss': 1.1893, 'grad_norm': 3.463934898376465, 'learning_rate': 1.952179011724047e-06, 'num_tokens': 1244619.0, 'mean_token_accuracy': 0.678000345826149, 'epoch': 0.14}
 14%|█▍        | 209/1449 [1:16:49<7:32:40, 21.90s/it] 14%|█▍        | 210/1449 [1:17:10<7:27:05, 21.65s/it]                                                      {'loss': 1.2432, 'grad_norm': 3.6921074390411377, 'learning_rate': 1.951478940159768e-06, 'num_tokens': 1250689.0, 'mean_token_accuracy': 0.6731272153556347, 'epoch': 0.14}
 14%|█▍        | 210/1449 [1:17:10<7:27:05, 21.65s/it] 15%|█▍        | 211/1449 [1:17:31<7:22:57, 21.47s/it]                                                      {'loss': 1.18, 'grad_norm': 3.354264974594116, 'learning_rate': 1.9507739088217006e-06, 'num_tokens': 1257000.0, 'mean_token_accuracy': 0.6935857459902763, 'epoch': 0.15}
 15%|█▍        | 211/1449 [1:17:31<7:22:57, 21.47s/it] 15%|█▍        | 212/1449 [1:17:52<7:19:49, 21.33s/it]                                                      {'loss': 1.0904, 'grad_norm': 3.9271702766418457, 'learning_rate': 1.9500639213849617e-06, 'num_tokens': 1262959.0, 'mean_token_accuracy': 0.6966663524508476, 'epoch': 0.15}
 15%|█▍        | 212/1449 [1:17:52<7:19:49, 21.33s/it] 15%|█▍        | 213/1449 [1:18:13<7:17:14, 21.23s/it]                                                      {'loss': 1.1149, 'grad_norm': 3.7782633304595947, 'learning_rate': 1.9493489815505018e-06, 'num_tokens': 1268852.0, 'mean_token_accuracy': 0.6920125558972359, 'epoch': 0.15}
 15%|█▍        | 213/1449 [1:18:13<7:17:14, 21.23s/it] 15%|█▍        | 214/1449 [1:18:35<7:16:38, 21.21s/it]                                                      {'loss': 1.0287, 'grad_norm': 3.336704969406128, 'learning_rate': 1.9486290930450882e-06, 'num_tokens': 1274600.0, 'mean_token_accuracy': 0.7075632400810719, 'epoch': 0.15}
 15%|█▍        | 214/1449 [1:18:35<7:16:38, 21.21s/it] 15%|█▍        | 215/1449 [1:18:56<7:15:55, 21.20s/it]                                                      {'loss': 1.1958, 'grad_norm': 3.7590761184692383, 'learning_rate': 1.947904259621283e-06, 'num_tokens': 1279754.0, 'mean_token_accuracy': 0.6718496009707451, 'epoch': 0.15}
 15%|█▍        | 215/1449 [1:18:56<7:15:55, 21.20s/it] 15%|█▍        | 216/1449 [1:19:17<7:15:55, 21.21s/it]                                                      {'loss': 1.1975, 'grad_norm': 3.504166841506958, 'learning_rate': 1.947174485057425e-06, 'num_tokens': 1285418.0, 'mean_token_accuracy': 0.6863512136042118, 'epoch': 0.15}
 15%|█▍        | 216/1449 [1:19:17<7:15:55, 21.21s/it] 15%|█▍        | 217/1449 [1:19:39<7:23:02, 21.58s/it]                                                      {'loss': 1.1297, 'grad_norm': 3.6715409755706787, 'learning_rate': 1.9464397731576094e-06, 'num_tokens': 1290900.0, 'mean_token_accuracy': 0.6947259530425072, 'epoch': 0.15}
 15%|█▍        | 217/1449 [1:19:39<7:23:02, 21.58s/it] 15%|█▌        | 218/1449 [1:20:01<7:24:18, 21.66s/it]                                                      {'loss': 1.1168, 'grad_norm': 3.351024627685547, 'learning_rate': 1.945700127751669e-06, 'num_tokens': 1296989.0, 'mean_token_accuracy': 0.6947870887815952, 'epoch': 0.15}
 15%|█▌        | 218/1449 [1:20:01<7:24:18, 21.66s/it] 15%|█▌        | 219/1449 [1:20:23<7:25:11, 21.72s/it]                                                      {'loss': 1.0845, 'grad_norm': 3.27598237991333, 'learning_rate': 1.9449555526951525e-06, 'num_tokens': 1303359.0, 'mean_token_accuracy': 0.7113590501248837, 'epoch': 0.15}
 15%|█▌        | 219/1449 [1:20:23<7:25:11, 21.72s/it] 15%|█▌        | 220/1449 [1:20:45<7:27:52, 21.87s/it]                                                      {'loss': 1.0801, 'grad_norm': 3.011913299560547, 'learning_rate': 1.944206051869307e-06, 'num_tokens': 1310694.0, 'mean_token_accuracy': 0.7016051858663559, 'epoch': 0.15}
 15%|█▌        | 220/1449 [1:20:45<7:27:52, 21.87s/it] 15%|█▌        | 221/1449 [1:21:07<7:26:41, 21.83s/it]                                                      {'loss': 1.0665, 'grad_norm': 2.7167985439300537, 'learning_rate': 1.9434516291810536e-06, 'num_tokens': 1318060.0, 'mean_token_accuracy': 0.7100858986377716, 'epoch': 0.15}
 15%|█▌        | 221/1449 [1:21:07<7:26:41, 21.83s/it] 15%|█▌        | 222/1449 [1:21:29<7:27:38, 21.89s/it]                                                      {'loss': 1.1044, 'grad_norm': 3.5453855991363525, 'learning_rate': 1.942692288562972e-06, 'num_tokens': 1323445.0, 'mean_token_accuracy': 0.7077567130327225, 'epoch': 0.15}
 15%|█▌        | 222/1449 [1:21:29<7:27:38, 21.89s/it] 15%|█▌        | 223/1449 [1:21:51<7:28:14, 21.94s/it]                                                      {'loss': 1.1376, 'grad_norm': 3.282426357269287, 'learning_rate': 1.9419280339732768e-06, 'num_tokens': 1329256.0, 'mean_token_accuracy': 0.6966135948896408, 'epoch': 0.15}
 15%|█▌        | 223/1449 [1:21:51<7:28:14, 21.94s/it] 15%|█▌        | 224/1449 [1:22:13<7:28:58, 21.99s/it]                                                      {'loss': 1.0801, 'grad_norm': 2.9297358989715576, 'learning_rate': 1.9411588693957972e-06, 'num_tokens': 1335880.0, 'mean_token_accuracy': 0.6990236602723598, 'epoch': 0.15}
 15%|█▌        | 224/1449 [1:22:13<7:28:58, 21.99s/it] 16%|█▌        | 225/1449 [1:22:36<7:30:59, 22.11s/it]                                                      {'loss': 1.0128, 'grad_norm': 3.58868145942688, 'learning_rate': 1.9403847988399566e-06, 'num_tokens': 1341750.0, 'mean_token_accuracy': 0.7170537449419498, 'epoch': 0.16}
 16%|█▌        | 225/1449 [1:22:36<7:30:59, 22.11s/it] 16%|█▌        | 226/1449 [1:22:58<7:30:07, 22.08s/it]                                                      {'loss': 0.9761, 'grad_norm': 3.4486958980560303, 'learning_rate': 1.9396058263407527e-06, 'num_tokens': 1347881.0, 'mean_token_accuracy': 0.7138722538948059, 'epoch': 0.16}
 16%|█▌        | 226/1449 [1:22:58<7:30:07, 22.08s/it] 16%|█▌        | 227/1449 [1:23:20<7:31:18, 22.16s/it]                                                      {'loss': 1.0378, 'grad_norm': 3.376772403717041, 'learning_rate': 1.938821955958735e-06, 'num_tokens': 1354127.0, 'mean_token_accuracy': 0.7213280573487282, 'epoch': 0.16}
 16%|█▌        | 227/1449 [1:23:20<7:31:18, 22.16s/it] 16%|█▌        | 228/1449 [1:23:41<7:23:15, 21.78s/it]                                                      {'loss': 0.9759, 'grad_norm': 3.115450143814087, 'learning_rate': 1.9380331917799845e-06, 'num_tokens': 1360720.0, 'mean_token_accuracy': 0.7125095762312412, 'epoch': 0.16}
 16%|█▌        | 228/1449 [1:23:41<7:23:15, 21.78s/it] 16%|█▌        | 229/1449 [1:24:03<7:24:38, 21.87s/it]                                                      {'loss': 0.974, 'grad_norm': 3.4650399684906006, 'learning_rate': 1.937239537916091e-06, 'num_tokens': 1366747.0, 'mean_token_accuracy': 0.7091583497822285, 'epoch': 0.16}
 16%|█▌        | 229/1449 [1:24:03<7:24:38, 21.87s/it] 16%|█▌        | 230/1449 [1:24:25<7:28:39, 22.08s/it]                                                      {'loss': 1.2073, 'grad_norm': 3.630467176437378, 'learning_rate': 1.9364409985041346e-06, 'num_tokens': 1372006.0, 'mean_token_accuracy': 0.6740481816232204, 'epoch': 0.16}
 16%|█▌        | 230/1449 [1:24:25<7:28:39, 22.08s/it] 16%|█▌        | 231/1449 [1:24:48<7:30:15, 22.18s/it]                                                      {'loss': 1.1111, 'grad_norm': 3.1947743892669678, 'learning_rate': 1.93563757770666e-06, 'num_tokens': 1378367.0, 'mean_token_accuracy': 0.6949500069022179, 'epoch': 0.16}
 16%|█▌        | 231/1449 [1:24:48<7:30:15, 22.18s/it] 16%|█▌        | 232/1449 [1:25:10<7:30:41, 22.22s/it]                                                      {'loss': 1.034, 'grad_norm': 3.5927937030792236, 'learning_rate': 1.9348292797116602e-06, 'num_tokens': 1384691.0, 'mean_token_accuracy': 0.7174316830933094, 'epoch': 0.16}
 16%|█▌        | 232/1449 [1:25:10<7:30:41, 22.22s/it] 16%|█▌        | 233/1449 [1:25:32<7:30:19, 22.22s/it]                                                      {'loss': 0.9247, 'grad_norm': 3.0434908866882324, 'learning_rate': 1.934016108732548e-06, 'num_tokens': 1392473.0, 'mean_token_accuracy': 0.7332190945744514, 'epoch': 0.16}
 16%|█▌        | 233/1449 [1:25:32<7:30:19, 22.22s/it] 16%|█▌        | 234/1449 [1:25:55<7:33:04, 22.37s/it]                                                      {'loss': 1.2606, 'grad_norm': 3.9525420665740967, 'learning_rate': 1.93319806900814e-06, 'num_tokens': 1397930.0, 'mean_token_accuracy': 0.6636010259389877, 'epoch': 0.16}
 16%|█▌        | 234/1449 [1:25:55<7:33:04, 22.37s/it] 16%|█▌        | 235/1449 [1:26:17<7:28:00, 22.14s/it]                                                      {'loss': 1.0726, 'grad_norm': 3.4733824729919434, 'learning_rate': 1.932375164802632e-06, 'num_tokens': 1403949.0, 'mean_token_accuracy': 0.6970183961093426, 'epoch': 0.16}
 16%|█▌        | 235/1449 [1:26:17<7:28:00, 22.14s/it] 16%|█▋        | 236/1449 [1:26:39<7:29:21, 22.23s/it]                                                      {'loss': 1.1454, 'grad_norm': 3.5894367694854736, 'learning_rate': 1.9315474004055755e-06, 'num_tokens': 1410170.0, 'mean_token_accuracy': 0.6984245702624321, 'epoch': 0.16}
 16%|█▋        | 236/1449 [1:26:39<7:29:21, 22.23s/it] 16%|█▋        | 237/1449 [1:27:01<7:26:57, 22.13s/it]                                                      {'loss': 0.9348, 'grad_norm': 3.5195131301879883, 'learning_rate': 1.9307147801318583e-06, 'num_tokens': 1416108.0, 'mean_token_accuracy': 0.7431239597499371, 'epoch': 0.16}
 16%|█▋        | 237/1449 [1:27:01<7:26:57, 22.13s/it] 16%|█▋        | 238/1449 [1:27:23<7:25:19, 22.06s/it]                                                      {'loss': 1.1136, 'grad_norm': 3.713913917541504, 'learning_rate': 1.9298773083216788e-06, 'num_tokens': 1421523.0, 'mean_token_accuracy': 0.6974822729825974, 'epoch': 0.16}
 16%|█▋        | 238/1449 [1:27:23<7:25:19, 22.06s/it] 16%|█▋        | 239/1449 [1:27:45<7:24:55, 22.06s/it]                                                      {'loss': 1.1579, 'grad_norm': 3.2226369380950928, 'learning_rate': 1.9290349893405266e-06, 'num_tokens': 1427709.0, 'mean_token_accuracy': 0.6906127855181694, 'epoch': 0.16}
 16%|█▋        | 239/1449 [1:27:45<7:24:55, 22.06s/it] 17%|█▋        | 240/1449 [1:28:07<7:25:16, 22.10s/it]                                                      {'loss': 0.9887, 'grad_norm': 3.7398643493652344, 'learning_rate': 1.928187827579157e-06, 'num_tokens': 1433794.0, 'mean_token_accuracy': 0.7234994359314442, 'epoch': 0.17}
 17%|█▋        | 240/1449 [1:28:07<7:25:16, 22.10s/it] 17%|█▋        | 241/1449 [1:28:30<7:27:46, 22.24s/it]                                                      {'loss': 1.0263, 'grad_norm': 3.692625045776367, 'learning_rate': 1.9273358274535703e-06, 'num_tokens': 1439408.0, 'mean_token_accuracy': 0.7166770696640015, 'epoch': 0.17}
 17%|█▋        | 241/1449 [1:28:30<7:27:46, 22.24s/it] 17%|█▋        | 242/1449 [1:28:52<7:29:55, 22.37s/it]                                                      {'loss': 1.098, 'grad_norm': 3.6604421138763428, 'learning_rate': 1.9264789934049864e-06, 'num_tokens': 1444859.0, 'mean_token_accuracy': 0.6862863823771477, 'epoch': 0.17}
 17%|█▋        | 242/1449 [1:28:52<7:29:55, 22.37s/it] 17%|█▋        | 243/1449 [1:29:16<7:34:29, 22.61s/it]                                                      {'loss': 1.1007, 'grad_norm': 3.2977399826049805, 'learning_rate': 1.925617329899824e-06, 'num_tokens': 1451072.0, 'mean_token_accuracy': 0.7070976160466671, 'epoch': 0.17}
 17%|█▋        | 243/1449 [1:29:16<7:34:29, 22.61s/it] 17%|█▋        | 244/1449 [1:29:38<7:33:05, 22.56s/it]                                                      {'loss': 1.1145, 'grad_norm': 4.997399806976318, 'learning_rate': 1.924750841429676e-06, 'num_tokens': 1456021.0, 'mean_token_accuracy': 0.6947570033371449, 'epoch': 0.17}
 17%|█▋        | 244/1449 [1:29:38<7:33:05, 22.56s/it] 17%|█▋        | 245/1449 [1:30:00<7:30:58, 22.47s/it]                                                      {'loss': 1.0352, 'grad_norm': 3.517819404602051, 'learning_rate': 1.9238795325112867e-06, 'num_tokens': 1461918.0, 'mean_token_accuracy': 0.7066942639648914, 'epoch': 0.17}
 17%|█▋        | 245/1449 [1:30:00<7:30:58, 22.47s/it] 17%|█▋        | 246/1449 [1:30:24<7:34:38, 22.68s/it]                                                      {'loss': 1.0726, 'grad_norm': 3.3952548503875732, 'learning_rate': 1.9230034076865272e-06, 'num_tokens': 1468551.0, 'mean_token_accuracy': 0.7101394571363926, 'epoch': 0.17}
 17%|█▋        | 246/1449 [1:30:24<7:34:38, 22.68s/it] 17%|█▋        | 247/1449 [1:30:46<7:32:37, 22.59s/it]                                                      {'loss': 1.1409, 'grad_norm': 4.00111198425293, 'learning_rate': 1.9221224715223733e-06, 'num_tokens': 1473355.0, 'mean_token_accuracy': 0.6824944503605366, 'epoch': 0.17}
 17%|█▋        | 247/1449 [1:30:46<7:32:37, 22.59s/it] 17%|█▋        | 248/1449 [1:31:08<7:29:17, 22.45s/it]                                                      {'loss': 1.0363, 'grad_norm': 3.1079540252685547, 'learning_rate': 1.92123672861088e-06, 'num_tokens': 1479643.0, 'mean_token_accuracy': 0.7202385775744915, 'epoch': 0.17}
 17%|█▋        | 248/1449 [1:31:08<7:29:17, 22.45s/it] 17%|█▋        | 249/1449 [1:31:30<7:25:58, 22.30s/it]                                                      {'loss': 1.1332, 'grad_norm': 4.348020553588867, 'learning_rate': 1.920346183569159e-06, 'num_tokens': 1484927.0, 'mean_token_accuracy': 0.701413381844759, 'epoch': 0.17}
 17%|█▋        | 249/1449 [1:31:30<7:25:58, 22.30s/it] 17%|█▋        | 250/1449 [1:31:52<7:22:38, 22.15s/it]                                                      {'loss': 1.0914, 'grad_norm': 3.312007188796997, 'learning_rate': 1.9194508410393547e-06, 'num_tokens': 1491567.0, 'mean_token_accuracy': 0.7082102000713348, 'epoch': 0.17}
 17%|█▋        | 250/1449 [1:31:52<7:22:38, 22.15s/it][INFO|trainer.py:3966] 2025-06-06 01:41:18,315 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250
[INFO|configuration_utils.py:423] 2025-06-06 01:41:18,321 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/config.json
[INFO|configuration_utils.py:908] 2025-06-06 01:41:18,323 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 01:41:26,108 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 01:41:26,112 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 01:41:26,114 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/special_tokens_map.json
[2025-06-06 01:41:26,323] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step250 is about to be saved!
[2025-06-06 01:41:26,330] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/global_step250/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 01:41:26,331] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/global_step250/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 01:41:26,346] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/global_step250/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 01:41:26,347] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/global_step250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 01:41:46,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/global_step250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 01:41:46,976] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-250/global_step250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 01:41:47,012] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step250 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 01:41:58,945 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 01:41:58,946 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 17%|█▋        | 251/1449 [1:32:57<11:39:41, 35.04s/it]                                                       {'loss': 1.108, 'grad_norm': 3.2414016723632812, 'learning_rate': 1.9185507056886183e-06, 'num_tokens': 1498192.0, 'mean_token_accuracy': 0.6905076652765274, 'epoch': 0.17}
 17%|█▋        | 251/1449 [1:32:57<11:39:41, 35.04s/it] 17%|█▋        | 252/1449 [1:33:19<10:24:15, 31.29s/it]                                                       {'loss': 1.0663, 'grad_norm': 3.6058621406555176, 'learning_rate': 1.9176457822090845e-06, 'num_tokens': 1503837.0, 'mean_token_accuracy': 0.7093534469604492, 'epoch': 0.17}
 17%|█▋        | 252/1449 [1:33:19<10:24:15, 31.29s/it] 17%|█▋        | 253/1449 [1:33:42<9:30:08, 28.60s/it]                                                       {'loss': 1.0687, 'grad_norm': 3.548185348510742, 'learning_rate': 1.9167360753178477e-06, 'num_tokens': 1509832.0, 'mean_token_accuracy': 0.702214889228344, 'epoch': 0.17}
 17%|█▋        | 253/1449 [1:33:42<9:30:08, 28.60s/it] 18%|█▊        | 254/1449 [1:34:05<8:55:49, 26.90s/it]                                                      {'loss': 1.2357, 'grad_norm': 3.5234737396240234, 'learning_rate': 1.915821589756937e-06, 'num_tokens': 1515975.0, 'mean_token_accuracy': 0.6743093244731426, 'epoch': 0.18}
 18%|█▊        | 254/1449 [1:34:05<8:55:49, 26.90s/it] 18%|█▊        | 255/1449 [1:34:27<8:29:13, 25.59s/it]                                                      {'loss': 0.902, 'grad_norm': 3.345951557159424, 'learning_rate': 1.9149023302932897e-06, 'num_tokens': 1522812.0, 'mean_token_accuracy': 0.7226850464940071, 'epoch': 0.18}
 18%|█▊        | 255/1449 [1:34:27<8:29:13, 25.59s/it] 18%|█▊        | 256/1449 [1:34:49<8:08:21, 24.56s/it]                                                      {'loss': 1.0484, 'grad_norm': 3.548164129257202, 'learning_rate': 1.9139783017187305e-06, 'num_tokens': 1528411.0, 'mean_token_accuracy': 0.7036185823380947, 'epoch': 0.18}
 18%|█▊        | 256/1449 [1:34:49<8:08:21, 24.56s/it] 18%|█▊        | 257/1449 [1:35:12<7:58:23, 24.08s/it]                                                      {'loss': 1.2007, 'grad_norm': 3.4693195819854736, 'learning_rate': 1.913049508849942e-06, 'num_tokens': 1534527.0, 'mean_token_accuracy': 0.6870145723223686, 'epoch': 0.18}
 18%|█▊        | 257/1449 [1:35:12<7:58:23, 24.08s/it] 18%|█▊        | 258/1449 [1:35:35<7:47:52, 23.57s/it]                                                      {'loss': 1.1293, 'grad_norm': 3.9713869094848633, 'learning_rate': 1.9121159565284416e-06, 'num_tokens': 1540085.0, 'mean_token_accuracy': 0.6969693079590797, 'epoch': 0.18}
 18%|█▊        | 258/1449 [1:35:35<7:47:52, 23.57s/it] 18%|█▊        | 259/1449 [1:35:58<7:46:11, 23.51s/it]                                                      {'loss': 0.9998, 'grad_norm': 3.2543628215789795, 'learning_rate': 1.911177649620558e-06, 'num_tokens': 1547027.0, 'mean_token_accuracy': 0.7169915623962879, 'epoch': 0.18}
 18%|█▊        | 259/1449 [1:35:58<7:46:11, 23.51s/it] 18%|█▊        | 260/1449 [1:36:21<7:39:46, 23.20s/it]                                                      {'loss': 1.1262, 'grad_norm': 3.0834760665893555, 'learning_rate': 1.910234593017403e-06, 'num_tokens': 1553760.0, 'mean_token_accuracy': 0.7078665383160114, 'epoch': 0.18}
 18%|█▊        | 260/1449 [1:36:21<7:39:46, 23.20s/it] 18%|█▊        | 261/1449 [1:36:43<7:33:40, 22.91s/it]                                                      {'loss': 1.1305, 'grad_norm': 3.9660937786102295, 'learning_rate': 1.9092867916348475e-06, 'num_tokens': 1559503.0, 'mean_token_accuracy': 0.6994853653013706, 'epoch': 0.18}
 18%|█▊        | 261/1449 [1:36:43<7:33:40, 22.91s/it] 18%|█▊        | 262/1449 [1:37:05<7:28:27, 22.67s/it]                                                      {'loss': 1.2706, 'grad_norm': 3.864685535430908, 'learning_rate': 1.9083342504134948e-06, 'num_tokens': 1565231.0, 'mean_token_accuracy': 0.671561274677515, 'epoch': 0.18}
 18%|█▊        | 262/1449 [1:37:05<7:28:27, 22.67s/it] 18%|█▊        | 263/1449 [1:37:27<7:24:49, 22.50s/it]                                                      {'loss': 0.9358, 'grad_norm': 2.963366746902466, 'learning_rate': 1.9073769743186558e-06, 'num_tokens': 1571680.0, 'mean_token_accuracy': 0.728523351252079, 'epoch': 0.18}
 18%|█▊        | 263/1449 [1:37:27<7:24:49, 22.50s/it] 18%|█▊        | 264/1449 [1:37:49<7:21:20, 22.35s/it]                                                      {'loss': 1.0402, 'grad_norm': 3.9608864784240723, 'learning_rate': 1.9064149683403236e-06, 'num_tokens': 1577648.0, 'mean_token_accuracy': 0.7098327279090881, 'epoch': 0.18}
 18%|█▊        | 264/1449 [1:37:49<7:21:20, 22.35s/it] 18%|█▊        | 265/1449 [1:38:11<7:17:12, 22.16s/it]                                                      {'loss': 1.0618, 'grad_norm': 3.88464093208313, 'learning_rate': 1.9054482374931466e-06, 'num_tokens': 1583488.0, 'mean_token_accuracy': 0.7086093798279762, 'epoch': 0.18}
 18%|█▊        | 265/1449 [1:38:11<7:17:12, 22.16s/it] 18%|█▊        | 266/1449 [1:38:33<7:15:20, 22.08s/it]                                                      {'loss': 0.9908, 'grad_norm': 3.521739959716797, 'learning_rate': 1.9044767868164015e-06, 'num_tokens': 1590110.0, 'mean_token_accuracy': 0.7125847414135933, 'epoch': 0.18}
 18%|█▊        | 266/1449 [1:38:33<7:15:20, 22.08s/it] 18%|█▊        | 267/1449 [1:38:55<7:15:47, 22.12s/it]                                                      {'loss': 1.0724, 'grad_norm': 3.5674362182617188, 'learning_rate': 1.9035006213739687e-06, 'num_tokens': 1595754.0, 'mean_token_accuracy': 0.6981169804930687, 'epoch': 0.18}
 18%|█▊        | 267/1449 [1:38:55<7:15:47, 22.12s/it] 18%|█▊        | 268/1449 [1:39:17<7:13:44, 22.04s/it]                                                      {'loss': 1.1439, 'grad_norm': 3.7023072242736816, 'learning_rate': 1.902519746254306e-06, 'num_tokens': 1601266.0, 'mean_token_accuracy': 0.6928136497735977, 'epoch': 0.18}
 18%|█▊        | 268/1449 [1:39:17<7:13:44, 22.04s/it] 19%|█▊        | 269/1449 [1:39:39<7:12:54, 22.01s/it]                                                      {'loss': 1.0251, 'grad_norm': 3.7701663970947266, 'learning_rate': 1.9015341665704203e-06, 'num_tokens': 1606779.0, 'mean_token_accuracy': 0.724447701126337, 'epoch': 0.19}
 19%|█▊        | 269/1449 [1:39:39<7:12:54, 22.01s/it] 19%|█▊        | 270/1449 [1:40:01<7:12:41, 22.02s/it]                                                      {'loss': 1.069, 'grad_norm': 3.513820171356201, 'learning_rate': 1.9005438874598422e-06, 'num_tokens': 1612901.0, 'mean_token_accuracy': 0.7048587836325169, 'epoch': 0.19}
 19%|█▊        | 270/1449 [1:40:01<7:12:41, 22.02s/it] 19%|█▊        | 271/1449 [1:40:23<7:16:07, 22.21s/it]                                                      {'loss': 1.1018, 'grad_norm': 4.009918212890625, 'learning_rate': 1.8995489140845993e-06, 'num_tokens': 1618774.0, 'mean_token_accuracy': 0.6966758519411087, 'epoch': 0.19}
 19%|█▊        | 271/1449 [1:40:23<7:16:07, 22.21s/it] 19%|█▉        | 272/1449 [1:40:47<7:22:43, 22.57s/it]                                                      {'loss': 1.0984, 'grad_norm': 3.72016978263855, 'learning_rate': 1.8985492516311888e-06, 'num_tokens': 1624370.0, 'mean_token_accuracy': 0.6935984529554844, 'epoch': 0.19}
 19%|█▉        | 272/1449 [1:40:47<7:22:43, 22.57s/it] 19%|█▉        | 273/1449 [1:41:09<7:20:59, 22.50s/it]                                                      {'loss': 1.0497, 'grad_norm': 3.67153000831604, 'learning_rate': 1.8975449053105504e-06, 'num_tokens': 1629825.0, 'mean_token_accuracy': 0.7093127854168415, 'epoch': 0.19}
 19%|█▉        | 273/1449 [1:41:09<7:20:59, 22.50s/it] 19%|█▉        | 274/1449 [1:41:32<7:20:57, 22.52s/it]                                                      {'loss': 0.9738, 'grad_norm': 3.4814023971557617, 'learning_rate': 1.8965358803580397e-06, 'num_tokens': 1635895.0, 'mean_token_accuracy': 0.7185669355094433, 'epoch': 0.19}
 19%|█▉        | 274/1449 [1:41:32<7:20:57, 22.52s/it] 19%|█▉        | 275/1449 [1:41:54<7:22:32, 22.62s/it]                                                      {'loss': 1.082, 'grad_norm': 3.4218060970306396, 'learning_rate': 1.8955221820334007e-06, 'num_tokens': 1642105.0, 'mean_token_accuracy': 0.7054132744669914, 'epoch': 0.19}
 19%|█▉        | 275/1449 [1:41:54<7:22:32, 22.62s/it] 19%|█▉        | 276/1449 [1:42:17<7:20:13, 22.52s/it]                                                      {'loss': 1.1577, 'grad_norm': 3.3896706104278564, 'learning_rate': 1.8945038156207381e-06, 'num_tokens': 1648167.0, 'mean_token_accuracy': 0.7027989812195301, 'epoch': 0.19}
 19%|█▉        | 276/1449 [1:42:17<7:20:13, 22.52s/it] 19%|█▉        | 277/1449 [1:42:39<7:19:55, 22.52s/it]                                                      {'loss': 1.0465, 'grad_norm': 3.6265170574188232, 'learning_rate': 1.8934807864284902e-06, 'num_tokens': 1653710.0, 'mean_token_accuracy': 0.7044336274266243, 'epoch': 0.19}
 19%|█▉        | 277/1449 [1:42:39<7:19:55, 22.52s/it] 19%|█▉        | 278/1449 [1:43:02<7:18:52, 22.49s/it]                                                      {'loss': 1.0411, 'grad_norm': 3.7580928802490234, 'learning_rate': 1.8924530997894003e-06, 'num_tokens': 1660435.0, 'mean_token_accuracy': 0.7122661992907524, 'epoch': 0.19}
 19%|█▉        | 278/1449 [1:43:02<7:18:52, 22.49s/it] 19%|█▉        | 279/1449 [1:43:25<7:21:32, 22.64s/it]                                                      {'loss': 1.1481, 'grad_norm': 3.7479288578033447, 'learning_rate': 1.8914207610604907e-06, 'num_tokens': 1666055.0, 'mean_token_accuracy': 0.6852841414511204, 'epoch': 0.19}
 19%|█▉        | 279/1449 [1:43:25<7:21:32, 22.64s/it] 19%|█▉        | 280/1449 [1:43:48<7:23:16, 22.75s/it]                                                      {'loss': 1.0814, 'grad_norm': 3.5784571170806885, 'learning_rate': 1.8903837756230324e-06, 'num_tokens': 1671999.0, 'mean_token_accuracy': 0.6971795596182346, 'epoch': 0.19}
 19%|█▉        | 280/1449 [1:43:48<7:23:16, 22.75s/it] 19%|█▉        | 281/1449 [1:44:10<7:21:43, 22.69s/it]                                                      {'loss': 1.1359, 'grad_norm': 3.9154388904571533, 'learning_rate': 1.8893421488825188e-06, 'num_tokens': 1677942.0, 'mean_token_accuracy': 0.687724269926548, 'epoch': 0.19}
 19%|█▉        | 281/1449 [1:44:10<7:21:43, 22.69s/it] 19%|█▉        | 282/1449 [1:44:33<7:19:19, 22.59s/it]                                                      {'loss': 1.0947, 'grad_norm': 3.7061538696289062, 'learning_rate': 1.8882958862686372e-06, 'num_tokens': 1683807.0, 'mean_token_accuracy': 0.7078993581235409, 'epoch': 0.19}
 19%|█▉        | 282/1449 [1:44:33<7:19:19, 22.59s/it] 20%|█▉        | 283/1449 [1:44:56<7:21:26, 22.72s/it]                                                      {'loss': 0.9587, 'grad_norm': 3.425766944885254, 'learning_rate': 1.8872449932352407e-06, 'num_tokens': 1690197.0, 'mean_token_accuracy': 0.7389948144555092, 'epoch': 0.2}
 20%|█▉        | 283/1449 [1:44:56<7:21:26, 22.72s/it] 20%|█▉        | 284/1449 [1:45:18<7:21:11, 22.72s/it]                                                      {'loss': 0.9646, 'grad_norm': 2.9852724075317383, 'learning_rate': 1.8861894752603185e-06, 'num_tokens': 1697310.0, 'mean_token_accuracy': 0.7295816540718079, 'epoch': 0.2}
 20%|█▉        | 284/1449 [1:45:18<7:21:11, 22.72s/it] 20%|█▉        | 285/1449 [1:45:41<7:20:46, 22.72s/it]                                                      {'loss': 1.1106, 'grad_norm': 3.2688441276550293, 'learning_rate': 1.8851293378459682e-06, 'num_tokens': 1703468.0, 'mean_token_accuracy': 0.6930894292891026, 'epoch': 0.2}
 20%|█▉        | 285/1449 [1:45:41<7:20:46, 22.72s/it] 20%|█▉        | 286/1449 [1:46:04<7:19:34, 22.68s/it]                                                      {'loss': 1.1399, 'grad_norm': 3.207911491394043, 'learning_rate': 1.8840645865183682e-06, 'num_tokens': 1709532.0, 'mean_token_accuracy': 0.6977550722658634, 'epoch': 0.2}
 20%|█▉        | 286/1449 [1:46:04<7:19:34, 22.68s/it] 20%|█▉        | 287/1449 [1:46:26<7:17:44, 22.60s/it]                                                      {'loss': 1.09, 'grad_norm': 3.615795373916626, 'learning_rate': 1.882995226827747e-06, 'num_tokens': 1715519.0, 'mean_token_accuracy': 0.702967919409275, 'epoch': 0.2}
 20%|█▉        | 287/1449 [1:46:26<7:17:44, 22.60s/it] 20%|█▉        | 288/1449 [1:46:48<7:15:10, 22.49s/it]                                                      {'loss': 1.0051, 'grad_norm': 3.3294317722320557, 'learning_rate': 1.8819212643483548e-06, 'num_tokens': 1722707.0, 'mean_token_accuracy': 0.7227380126714706, 'epoch': 0.2}
 20%|█▉        | 288/1449 [1:46:48<7:15:10, 22.49s/it] 20%|█▉        | 289/1449 [1:47:10<7:12:28, 22.37s/it]                                                      {'loss': 1.0385, 'grad_norm': 3.6214687824249268, 'learning_rate': 1.8808427046784363e-06, 'num_tokens': 1728563.0, 'mean_token_accuracy': 0.7161030098795891, 'epoch': 0.2}
 20%|█▉        | 289/1449 [1:47:10<7:12:28, 22.37s/it] 20%|██        | 290/1449 [1:47:32<7:09:22, 22.23s/it]                                                      {'loss': 1.0149, 'grad_norm': 3.7508833408355713, 'learning_rate': 1.879759553440198e-06, 'num_tokens': 1734132.0, 'mean_token_accuracy': 0.7083334289491177, 'epoch': 0.2}
 20%|██        | 290/1449 [1:47:32<7:09:22, 22.23s/it] 20%|██        | 291/1449 [1:47:55<7:09:56, 22.28s/it]                                                      {'loss': 1.0719, 'grad_norm': 3.384652614593506, 'learning_rate': 1.8786718162797825e-06, 'num_tokens': 1739632.0, 'mean_token_accuracy': 0.6986467726528645, 'epoch': 0.2}
 20%|██        | 291/1449 [1:47:55<7:09:56, 22.28s/it] 20%|██        | 292/1449 [1:48:17<7:07:36, 22.18s/it]                                                      {'loss': 1.0736, 'grad_norm': 3.152918815612793, 'learning_rate': 1.8775794988672362e-06, 'num_tokens': 1745601.0, 'mean_token_accuracy': 0.7057314142584801, 'epoch': 0.2}
 20%|██        | 292/1449 [1:48:17<7:07:36, 22.18s/it] 20%|██        | 293/1449 [1:48:38<7:05:06, 22.06s/it]                                                      {'loss': 1.1302, 'grad_norm': 3.772073268890381, 'learning_rate': 1.8764826068964818e-06, 'num_tokens': 1751074.0, 'mean_token_accuracy': 0.6987944468855858, 'epoch': 0.2}
 20%|██        | 293/1449 [1:48:38<7:05:06, 22.06s/it] 20%|██        | 294/1449 [1:49:00<7:03:00, 21.97s/it]                                                      {'loss': 1.15, 'grad_norm': 3.7936320304870605, 'learning_rate': 1.8753811460852876e-06, 'num_tokens': 1756009.0, 'mean_token_accuracy': 0.6908921152353287, 'epoch': 0.2}
 20%|██        | 294/1449 [1:49:00<7:03:00, 21.97s/it] 20%|██        | 295/1449 [1:49:23<7:10:03, 22.36s/it]                                                      {'loss': 1.1034, 'grad_norm': 3.7922489643096924, 'learning_rate': 1.8742751221752375e-06, 'num_tokens': 1761478.0, 'mean_token_accuracy': 0.6979727223515511, 'epoch': 0.2}
 20%|██        | 295/1449 [1:49:23<7:10:03, 22.36s/it] 20%|██        | 296/1449 [1:49:46<7:09:28, 22.35s/it]                                                      {'loss': 1.1549, 'grad_norm': 3.568153142929077, 'learning_rate': 1.873164540931702e-06, 'num_tokens': 1768070.0, 'mean_token_accuracy': 0.7034125439822674, 'epoch': 0.2}
 20%|██        | 296/1449 [1:49:46<7:09:28, 22.35s/it] 20%|██        | 297/1449 [1:50:08<7:08:47, 22.33s/it]                                                      {'loss': 1.058, 'grad_norm': 3.3854219913482666, 'learning_rate': 1.8720494081438077e-06, 'num_tokens': 1774451.0, 'mean_token_accuracy': 0.7027067542076111, 'epoch': 0.2}
 20%|██        | 297/1449 [1:50:08<7:08:47, 22.33s/it] 21%|██        | 298/1449 [1:50:30<7:07:08, 22.27s/it]                                                      {'loss': 1.0812, 'grad_norm': 4.168783187866211, 'learning_rate': 1.870929729624406e-06, 'num_tokens': 1779634.0, 'mean_token_accuracy': 0.706668633967638, 'epoch': 0.21}
 21%|██        | 298/1449 [1:50:30<7:07:08, 22.27s/it] 21%|██        | 299/1449 [1:50:52<7:06:02, 22.23s/it]                                                      {'loss': 1.0367, 'grad_norm': 3.486548662185669, 'learning_rate': 1.8698055112100447e-06, 'num_tokens': 1785327.0, 'mean_token_accuracy': 0.7094973735511303, 'epoch': 0.21}
 21%|██        | 299/1449 [1:50:52<7:06:02, 22.23s/it] 21%|██        | 300/1449 [1:51:14<7:03:36, 22.12s/it]                                                      {'loss': 1.1405, 'grad_norm': 3.981879234313965, 'learning_rate': 1.8686767587609373e-06, 'num_tokens': 1790658.0, 'mean_token_accuracy': 0.6890200152993202, 'epoch': 0.21}
 21%|██        | 300/1449 [1:51:14<7:03:36, 22.12s/it][INFO|trainer.py:3966] 2025-06-06 02:00:40,682 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300
[INFO|configuration_utils.py:423] 2025-06-06 02:00:40,688 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/config.json
[INFO|configuration_utils.py:908] 2025-06-06 02:00:40,690 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 02:00:48,867 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 02:00:48,871 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 02:00:48,873 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/special_tokens_map.json
[2025-06-06 02:00:49,083] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step300 is about to be saved!
[2025-06-06 02:00:49,090] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/global_step300/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 02:00:49,090] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/global_step300/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 02:00:49,129] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/global_step300/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 02:00:49,131] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/global_step300/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 02:01:10,462] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/global_step300/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 02:01:10,467] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-300/global_step300/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 02:01:10,503] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step300 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 02:01:22,274 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 02:01:22,276 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 21%|██        | 301/1449 [1:52:20<11:12:41, 35.16s/it]                                                       {'loss': 1.0965, 'grad_norm': 4.052961826324463, 'learning_rate': 1.8675434781609302e-06, 'num_tokens': 1795925.0, 'mean_token_accuracy': 0.7133741863071918, 'epoch': 0.21}
 21%|██        | 301/1449 [1:52:20<11:12:41, 35.16s/it] 21%|██        | 302/1449 [1:52:42<10:00:28, 31.41s/it]                                                       {'loss': 1.1666, 'grad_norm': 3.2679190635681152, 'learning_rate': 1.8664056753174751e-06, 'num_tokens': 1802302.0, 'mean_token_accuracy': 0.674750167876482, 'epoch': 0.21}
 21%|██        | 302/1449 [1:52:42<10:00:28, 31.41s/it] 21%|██        | 303/1449 [1:53:05<9:10:53, 28.84s/it]                                                       {'loss': 1.0495, 'grad_norm': 3.5435516834259033, 'learning_rate': 1.8652633561615963e-06, 'num_tokens': 1808095.0, 'mean_token_accuracy': 0.7010652460157871, 'epoch': 0.21}
 21%|██        | 303/1449 [1:53:05<9:10:53, 28.84s/it] 21%|██        | 304/1449 [1:53:27<8:29:49, 26.72s/it]                                                      {'loss': 1.102, 'grad_norm': 3.210872173309326, 'learning_rate': 1.8641165266478602e-06, 'num_tokens': 1814468.0, 'mean_token_accuracy': 0.6929690651595592, 'epoch': 0.21}
 21%|██        | 304/1449 [1:53:27<8:29:49, 26.72s/it] 21%|██        | 305/1449 [1:53:49<8:02:35, 25.31s/it]                                                      {'loss': 1.116, 'grad_norm': 3.6195008754730225, 'learning_rate': 1.8629651927543444e-06, 'num_tokens': 1820103.0, 'mean_token_accuracy': 0.696170661598444, 'epoch': 0.21}
 21%|██        | 305/1449 [1:53:49<8:02:35, 25.31s/it] 21%|██        | 306/1449 [1:54:11<7:41:02, 24.20s/it]                                                      {'loss': 1.0343, 'grad_norm': 3.394711494445801, 'learning_rate': 1.8618093604826063e-06, 'num_tokens': 1825505.0, 'mean_token_accuracy': 0.7050767950713634, 'epoch': 0.21}
 21%|██        | 306/1449 [1:54:11<7:41:02, 24.20s/it] 21%|██        | 307/1449 [1:54:33<7:27:20, 23.50s/it]                                                      {'loss': 1.1234, 'grad_norm': 3.3109853267669678, 'learning_rate': 1.8606490358576528e-06, 'num_tokens': 1831331.0, 'mean_token_accuracy': 0.693588312715292, 'epoch': 0.21}
 21%|██        | 307/1449 [1:54:33<7:27:20, 23.50s/it] 21%|██▏       | 308/1449 [1:54:54<7:17:25, 23.00s/it]                                                      {'loss': 1.0192, 'grad_norm': 3.5453357696533203, 'learning_rate': 1.8594842249279065e-06, 'num_tokens': 1837306.0, 'mean_token_accuracy': 0.7289187833666801, 'epoch': 0.21}
 21%|██▏       | 308/1449 [1:54:54<7:17:25, 23.00s/it] 21%|██▏       | 309/1449 [1:55:17<7:16:06, 22.95s/it]                                                      {'loss': 0.9923, 'grad_norm': 2.929884195327759, 'learning_rate': 1.8583149337651777e-06, 'num_tokens': 1844551.0, 'mean_token_accuracy': 0.7301122508943081, 'epoch': 0.21}
 21%|██▏       | 309/1449 [1:55:17<7:16:06, 22.95s/it] 21%|██▏       | 310/1449 [1:55:40<7:12:24, 22.78s/it]                                                      {'loss': 1.1312, 'grad_norm': 3.7979204654693604, 'learning_rate': 1.8571411684646296e-06, 'num_tokens': 1850744.0, 'mean_token_accuracy': 0.6955161951482296, 'epoch': 0.21}
 21%|██▏       | 310/1449 [1:55:40<7:12:24, 22.78s/it] 21%|██▏       | 311/1449 [1:56:01<7:06:56, 22.51s/it]                                                      {'loss': 1.0865, 'grad_norm': 3.1852939128875732, 'learning_rate': 1.8559629351447476e-06, 'num_tokens': 1856651.0, 'mean_token_accuracy': 0.6987851820886135, 'epoch': 0.21}
 21%|██▏       | 311/1449 [1:56:01<7:06:56, 22.51s/it] 22%|██▏       | 312/1449 [1:56:24<7:03:52, 22.37s/it]                                                      {'loss': 1.178, 'grad_norm': 3.646838665008545, 'learning_rate': 1.8547802399473085e-06, 'num_tokens': 1862203.0, 'mean_token_accuracy': 0.6875264756381512, 'epoch': 0.22}
 22%|██▏       | 312/1449 [1:56:24<7:03:52, 22.37s/it] 22%|██▏       | 313/1449 [1:56:45<6:59:14, 22.14s/it]                                                      {'loss': 1.0944, 'grad_norm': 3.7532076835632324, 'learning_rate': 1.8535930890373463e-06, 'num_tokens': 1867693.0, 'mean_token_accuracy': 0.7079600468277931, 'epoch': 0.22}
 22%|██▏       | 313/1449 [1:56:45<6:59:14, 22.14s/it] 22%|██▏       | 314/1449 [1:57:07<6:59:37, 22.18s/it]                                                      {'loss': 1.153, 'grad_norm': 3.872330665588379, 'learning_rate': 1.8524014886031225e-06, 'num_tokens': 1873382.0, 'mean_token_accuracy': 0.691964216530323, 'epoch': 0.22}
 22%|██▏       | 314/1449 [1:57:07<6:59:37, 22.18s/it] 22%|██▏       | 315/1449 [1:57:30<7:00:00, 22.22s/it]                                                      {'loss': 1.0341, 'grad_norm': 3.137593984603882, 'learning_rate': 1.851205444856092e-06, 'num_tokens': 1880115.0, 'mean_token_accuracy': 0.6978507116436958, 'epoch': 0.22}
 22%|██▏       | 315/1449 [1:57:30<7:00:00, 22.22s/it] 22%|██▏       | 316/1449 [1:57:52<7:00:54, 22.29s/it]                                                      {'loss': 1.1596, 'grad_norm': 3.9482920169830322, 'learning_rate': 1.850004964030871e-06, 'num_tokens': 1885755.0, 'mean_token_accuracy': 0.6887993328273296, 'epoch': 0.22}
 22%|██▏       | 316/1449 [1:57:52<7:00:54, 22.29s/it] 22%|██▏       | 317/1449 [1:58:14<7:00:01, 22.26s/it]                                                      {'loss': 1.0942, 'grad_norm': 3.4276680946350098, 'learning_rate': 1.8488000523852056e-06, 'num_tokens': 1891855.0, 'mean_token_accuracy': 0.7040537111461163, 'epoch': 0.22}
 22%|██▏       | 317/1449 [1:58:14<7:00:01, 22.26s/it] 22%|██▏       | 318/1449 [1:58:37<6:59:45, 22.27s/it]                                                      {'loss': 1.1219, 'grad_norm': 3.0722458362579346, 'learning_rate': 1.8475907161999384e-06, 'num_tokens': 1898502.0, 'mean_token_accuracy': 0.701680138707161, 'epoch': 0.22}
 22%|██▏       | 318/1449 [1:58:37<6:59:45, 22.27s/it] 22%|██▏       | 319/1449 [1:58:59<6:59:08, 22.25s/it]                                                      {'loss': 1.066, 'grad_norm': 3.4995334148406982, 'learning_rate': 1.8463769617789753e-06, 'num_tokens': 1904465.0, 'mean_token_accuracy': 0.7125252820551395, 'epoch': 0.22}
 22%|██▏       | 319/1449 [1:58:59<6:59:08, 22.25s/it] 22%|██▏       | 320/1449 [1:59:21<6:55:45, 22.10s/it]                                                      {'loss': 1.0198, 'grad_norm': 3.0889298915863037, 'learning_rate': 1.8451587954492532e-06, 'num_tokens': 1911108.0, 'mean_token_accuracy': 0.7177833206951618, 'epoch': 0.22}
 22%|██▏       | 320/1449 [1:59:21<6:55:45, 22.10s/it] 22%|██▏       | 321/1449 [1:59:43<6:56:02, 22.13s/it]                                                      {'loss': 1.108, 'grad_norm': 4.342149257659912, 'learning_rate': 1.843936223560707e-06, 'num_tokens': 1916481.0, 'mean_token_accuracy': 0.7034311778843403, 'epoch': 0.22}
 22%|██▏       | 321/1449 [1:59:43<6:56:02, 22.13s/it] 22%|██▏       | 322/1449 [2:00:05<6:55:23, 22.11s/it]                                                      {'loss': 1.0121, 'grad_norm': 3.1409554481506348, 'learning_rate': 1.8427092524862368e-06, 'num_tokens': 1922939.0, 'mean_token_accuracy': 0.7108219675719738, 'epoch': 0.22}
 22%|██▏       | 322/1449 [2:00:05<6:55:23, 22.11s/it] 22%|██▏       | 323/1449 [2:00:27<6:53:25, 22.03s/it]                                                      {'loss': 0.9527, 'grad_norm': 3.220102310180664, 'learning_rate': 1.8414778886216742e-06, 'num_tokens': 1929080.0, 'mean_token_accuracy': 0.7270766049623489, 'epoch': 0.22}
 22%|██▏       | 323/1449 [2:00:27<6:53:25, 22.03s/it] 22%|██▏       | 324/1449 [2:00:49<6:55:10, 22.14s/it]                                                      {'loss': 1.1751, 'grad_norm': 3.155895471572876, 'learning_rate': 1.8402421383857487e-06, 'num_tokens': 1935529.0, 'mean_token_accuracy': 0.6935673207044601, 'epoch': 0.22}
 22%|██▏       | 324/1449 [2:00:49<6:55:10, 22.14s/it] 22%|██▏       | 325/1449 [2:01:11<6:55:01, 22.15s/it]                                                      {'loss': 1.0083, 'grad_norm': 3.550408124923706, 'learning_rate': 1.839002008220055e-06, 'num_tokens': 1941223.0, 'mean_token_accuracy': 0.7121126018464565, 'epoch': 0.22}
 22%|██▏       | 325/1449 [2:01:11<6:55:01, 22.15s/it] 22%|██▏       | 326/1449 [2:01:34<6:56:00, 22.23s/it]                                                      {'loss': 1.0804, 'grad_norm': 3.3701491355895996, 'learning_rate': 1.8377575045890193e-06, 'num_tokens': 1947232.0, 'mean_token_accuracy': 0.7073537036776543, 'epoch': 0.22}
 22%|██▏       | 326/1449 [2:01:34<6:56:00, 22.23s/it] 23%|██▎       | 327/1449 [2:01:56<6:54:34, 22.17s/it]                                                      {'loss': 1.1426, 'grad_norm': 3.5597355365753174, 'learning_rate': 1.8365086339798649e-06, 'num_tokens': 1952969.0, 'mean_token_accuracy': 0.7011621631681919, 'epoch': 0.23}
 23%|██▎       | 327/1449 [2:01:56<6:54:34, 22.17s/it] 23%|██▎       | 328/1449 [2:02:18<6:52:18, 22.07s/it]                                                      {'loss': 1.0069, 'grad_norm': 3.3881185054779053, 'learning_rate': 1.8352554029025786e-06, 'num_tokens': 1959058.0, 'mean_token_accuracy': 0.7155399024486542, 'epoch': 0.23}
 23%|██▎       | 328/1449 [2:02:18<6:52:18, 22.07s/it] 23%|██▎       | 329/1449 [2:02:40<6:51:37, 22.05s/it]                                                      {'loss': 1.042, 'grad_norm': 3.336946725845337, 'learning_rate': 1.833997817889878e-06, 'num_tokens': 1965079.0, 'mean_token_accuracy': 0.7011167965829372, 'epoch': 0.23}
 23%|██▎       | 329/1449 [2:02:40<6:51:37, 22.05s/it] 23%|██▎       | 330/1449 [2:03:01<6:48:51, 21.92s/it]                                                      {'loss': 1.0584, 'grad_norm': 3.3987247943878174, 'learning_rate': 1.8327358854971752e-06, 'num_tokens': 1971091.0, 'mean_token_accuracy': 0.7309770621359348, 'epoch': 0.23}
 23%|██▎       | 330/1449 [2:03:01<6:48:51, 21.92s/it] 23%|██▎       | 331/1449 [2:03:23<6:49:10, 21.96s/it]                                                      {'loss': 0.9805, 'grad_norm': 3.7515602111816406, 'learning_rate': 1.8314696123025452e-06, 'num_tokens': 1976515.0, 'mean_token_accuracy': 0.7212089225649834, 'epoch': 0.23}
 23%|██▎       | 331/1449 [2:03:23<6:49:10, 21.96s/it] 23%|██▎       | 332/1449 [2:03:45<6:47:44, 21.90s/it]                                                      {'loss': 1.0096, 'grad_norm': 3.550065040588379, 'learning_rate': 1.8301990049066891e-06, 'num_tokens': 1982021.0, 'mean_token_accuracy': 0.7252496220171452, 'epoch': 0.23}
 23%|██▎       | 332/1449 [2:03:45<6:47:44, 21.90s/it] 23%|██▎       | 333/1449 [2:04:07<6:48:26, 21.96s/it]                                                      {'loss': 1.1629, 'grad_norm': 3.0552210807800293, 'learning_rate': 1.828924069932902e-06, 'num_tokens': 1988817.0, 'mean_token_accuracy': 0.6843165196478367, 'epoch': 0.23}
 23%|██▎       | 333/1449 [2:04:07<6:48:26, 21.96s/it] 23%|██▎       | 334/1449 [2:04:29<6:48:36, 21.99s/it]                                                      {'loss': 1.1485, 'grad_norm': 3.317456007003784, 'learning_rate': 1.8276448140270363e-06, 'num_tokens': 1995587.0, 'mean_token_accuracy': 0.6941283829510212, 'epoch': 0.23}
 23%|██▎       | 334/1449 [2:04:29<6:48:36, 21.99s/it] 23%|██▎       | 335/1449 [2:04:51<6:46:44, 21.91s/it]                                                      {'loss': 1.1098, 'grad_norm': 3.4007956981658936, 'learning_rate': 1.8263612438574687e-06, 'num_tokens': 2001624.0, 'mean_token_accuracy': 0.7078339904546738, 'epoch': 0.23}
 23%|██▎       | 335/1449 [2:04:51<6:46:44, 21.91s/it] 23%|██▎       | 336/1449 [2:05:13<6:47:02, 21.94s/it]                                                      {'loss': 1.1451, 'grad_norm': 3.7433807849884033, 'learning_rate': 1.8250733661150648e-06, 'num_tokens': 2007315.0, 'mean_token_accuracy': 0.6876571401953697, 'epoch': 0.23}
 23%|██▎       | 336/1449 [2:05:13<6:47:02, 21.94s/it] 23%|██▎       | 337/1449 [2:05:35<6:47:30, 21.99s/it]                                                      {'loss': 1.0946, 'grad_norm': 3.8829760551452637, 'learning_rate': 1.8237811875131443e-06, 'num_tokens': 2012634.0, 'mean_token_accuracy': 0.6839698143303394, 'epoch': 0.23}
 23%|██▎       | 337/1449 [2:05:35<6:47:30, 21.99s/it] 23%|██▎       | 338/1449 [2:05:58<6:50:43, 22.18s/it]                                                      {'loss': 1.0108, 'grad_norm': 3.6214442253112793, 'learning_rate': 1.822484714787446e-06, 'num_tokens': 2018452.0, 'mean_token_accuracy': 0.7028464525938034, 'epoch': 0.23}
 23%|██▎       | 338/1449 [2:05:58<6:50:43, 22.18s/it] 23%|██▎       | 339/1449 [2:06:20<6:51:38, 22.25s/it]                                                      {'loss': 1.0858, 'grad_norm': 3.66558837890625, 'learning_rate': 1.8211839546960926e-06, 'num_tokens': 2024350.0, 'mean_token_accuracy': 0.7035294361412525, 'epoch': 0.23}
 23%|██▎       | 339/1449 [2:06:20<6:51:38, 22.25s/it] 23%|██▎       | 340/1449 [2:06:43<6:52:30, 22.32s/it]                                                      {'loss': 0.9675, 'grad_norm': 2.985919237136841, 'learning_rate': 1.8198789140195555e-06, 'num_tokens': 2031306.0, 'mean_token_accuracy': 0.7313591279089451, 'epoch': 0.23}
 23%|██▎       | 340/1449 [2:06:43<6:52:30, 22.32s/it] 24%|██▎       | 341/1449 [2:07:05<6:55:11, 22.48s/it]                                                      {'loss': 1.0862, 'grad_norm': 3.4454989433288574, 'learning_rate': 1.8185695995606193e-06, 'num_tokens': 2037131.0, 'mean_token_accuracy': 0.6986844092607498, 'epoch': 0.24}
 24%|██▎       | 341/1449 [2:07:05<6:55:11, 22.48s/it] 24%|██▎       | 342/1449 [2:07:27<6:50:42, 22.26s/it]                                                      {'loss': 1.1034, 'grad_norm': 4.18098258972168, 'learning_rate': 1.8172560181443476e-06, 'num_tokens': 2043790.0, 'mean_token_accuracy': 0.7098734006285667, 'epoch': 0.24}
 24%|██▎       | 342/1449 [2:07:27<6:50:42, 22.26s/it] 24%|██▎       | 343/1449 [2:07:50<6:51:34, 22.33s/it]                                                      {'loss': 1.106, 'grad_norm': 3.4513375759124756, 'learning_rate': 1.815938176618045e-06, 'num_tokens': 2050082.0, 'mean_token_accuracy': 0.7008459940552711, 'epoch': 0.24}
 24%|██▎       | 343/1449 [2:07:50<6:51:34, 22.33s/it] 24%|██▎       | 344/1449 [2:08:12<6:51:09, 22.33s/it]                                                      {'loss': 1.0187, 'grad_norm': 3.6064953804016113, 'learning_rate': 1.8146160818512234e-06, 'num_tokens': 2056154.0, 'mean_token_accuracy': 0.7156281992793083, 'epoch': 0.24}
 24%|██▎       | 344/1449 [2:08:12<6:51:09, 22.33s/it] 24%|██▍       | 345/1449 [2:08:34<6:48:16, 22.19s/it]                                                      {'loss': 1.159, 'grad_norm': 3.221238851547241, 'learning_rate': 1.8132897407355654e-06, 'num_tokens': 2062789.0, 'mean_token_accuracy': 0.6865177601575851, 'epoch': 0.24}
 24%|██▍       | 345/1449 [2:08:34<6:48:16, 22.19s/it] 24%|██▍       | 346/1449 [2:08:56<6:48:45, 22.24s/it]                                                      {'loss': 1.174, 'grad_norm': 3.1108670234680176, 'learning_rate': 1.8119591601848887e-06, 'num_tokens': 2069104.0, 'mean_token_accuracy': 0.6786779947578907, 'epoch': 0.24}
 24%|██▍       | 346/1449 [2:08:56<6:48:45, 22.24s/it] 24%|██▍       | 347/1449 [2:09:18<6:45:55, 22.10s/it]                                                      {'loss': 1.0507, 'grad_norm': 3.3770596981048584, 'learning_rate': 1.8106243471351104e-06, 'num_tokens': 2074821.0, 'mean_token_accuracy': 0.7094136998057365, 'epoch': 0.24}
 24%|██▍       | 347/1449 [2:09:18<6:45:55, 22.10s/it] 24%|██▍       | 348/1449 [2:09:41<6:48:13, 22.25s/it]                                                      {'loss': 1.0748, 'grad_norm': 3.7428550720214844, 'learning_rate': 1.809285308544209e-06, 'num_tokens': 2080030.0, 'mean_token_accuracy': 0.7056149877607822, 'epoch': 0.24}
 24%|██▍       | 348/1449 [2:09:41<6:48:13, 22.25s/it] 24%|██▍       | 349/1449 [2:10:03<6:48:28, 22.28s/it]                                                      {'loss': 0.9729, 'grad_norm': 3.2409467697143555, 'learning_rate': 1.807942051392191e-06, 'num_tokens': 2085736.0, 'mean_token_accuracy': 0.722434937953949, 'epoch': 0.24}
 24%|██▍       | 349/1449 [2:10:03<6:48:28, 22.28s/it] 24%|██▍       | 350/1449 [2:10:25<6:46:13, 22.18s/it]                                                      {'loss': 1.0835, 'grad_norm': 3.0127172470092773, 'learning_rate': 1.8065945826810518e-06, 'num_tokens': 2091786.0, 'mean_token_accuracy': 0.7079051434993744, 'epoch': 0.24}
 24%|██▍       | 350/1449 [2:10:25<6:46:13, 22.18s/it][INFO|trainer.py:3966] 2025-06-06 02:19:51,319 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350
[INFO|configuration_utils.py:423] 2025-06-06 02:19:51,330 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/config.json
[INFO|configuration_utils.py:908] 2025-06-06 02:19:51,332 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 02:19:59,490 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 02:19:59,493 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 02:19:59,495 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/special_tokens_map.json
[2025-06-06 02:19:59,722] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step350 is about to be saved!
[2025-06-06 02:19:59,729] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/global_step350/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 02:19:59,729] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/global_step350/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 02:19:59,745] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/global_step350/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 02:19:59,746] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/global_step350/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 02:20:20,465] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/global_step350/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 02:20:20,472] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-350/global_step350/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 02:20:20,513] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step350 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 02:20:32,045 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 02:20:32,047 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 24%|██▍       | 351/1449 [2:11:31<10:47:41, 35.39s/it]                                                       {'loss': 1.0355, 'grad_norm': 3.4596869945526123, 'learning_rate': 1.805242909434741e-06, 'num_tokens': 2099459.0, 'mean_token_accuracy': 0.726135428994894, 'epoch': 0.24}
 24%|██▍       | 351/1449 [2:11:31<10:47:41, 35.39s/it] 24%|██▍       | 352/1449 [2:11:55<9:42:12, 31.84s/it]                                                       {'loss': 1.0487, 'grad_norm': 3.7641704082489014, 'learning_rate': 1.803887038699125e-06, 'num_tokens': 2104801.0, 'mean_token_accuracy': 0.7023555599153042, 'epoch': 0.24}
 24%|██▍       | 352/1449 [2:11:55<9:42:12, 31.84s/it] 24%|██▍       | 353/1449 [2:12:18<8:55:12, 29.30s/it]                                                      {'loss': 0.9657, 'grad_norm': 3.620861530303955, 'learning_rate': 1.8025269775419508e-06, 'num_tokens': 2110221.0, 'mean_token_accuracy': 0.7236696407198906, 'epoch': 0.24}
 24%|██▍       | 353/1449 [2:12:18<8:55:12, 29.30s/it] 24%|██▍       | 354/1449 [2:12:40<8:12:44, 27.00s/it]                                                      {'loss': 1.1881, 'grad_norm': 3.9169771671295166, 'learning_rate': 1.801162733052808e-06, 'num_tokens': 2115690.0, 'mean_token_accuracy': 0.6767984703183174, 'epoch': 0.24}
 24%|██▍       | 354/1449 [2:12:40<8:12:44, 27.00s/it] 24%|██▍       | 355/1449 [2:13:02<7:45:19, 25.52s/it]                                                      {'loss': 1.0234, 'grad_norm': 3.296130418777466, 'learning_rate': 1.7997943123430935e-06, 'num_tokens': 2121598.0, 'mean_token_accuracy': 0.7131451442837715, 'epoch': 0.24}
 24%|██▍       | 355/1449 [2:13:02<7:45:19, 25.52s/it] 25%|██▍       | 356/1449 [2:13:24<7:26:52, 24.53s/it]                                                      {'loss': 1.0755, 'grad_norm': 3.1691160202026367, 'learning_rate': 1.7984217225459733e-06, 'num_tokens': 2127502.0, 'mean_token_accuracy': 0.7081013694405556, 'epoch': 0.25}
 25%|██▍       | 356/1449 [2:13:24<7:26:52, 24.53s/it] 25%|██▍       | 357/1449 [2:13:46<7:10:52, 23.67s/it]                                                      {'loss': 1.0174, 'grad_norm': 3.569350004196167, 'learning_rate': 1.7970449708163451e-06, 'num_tokens': 2133061.0, 'mean_token_accuracy': 0.7135919630527496, 'epoch': 0.25}
 25%|██▍       | 357/1449 [2:13:46<7:10:52, 23.67s/it] 25%|██▍       | 358/1449 [2:14:08<7:01:52, 23.20s/it]                                                      {'loss': 1.0492, 'grad_norm': 3.584815263748169, 'learning_rate': 1.7956640643308025e-06, 'num_tokens': 2139150.0, 'mean_token_accuracy': 0.7195106819272041, 'epoch': 0.25}
 25%|██▍       | 358/1449 [2:14:08<7:01:52, 23.20s/it] 25%|██▍       | 359/1449 [2:14:29<6:53:30, 22.76s/it]                                                      {'loss': 1.0844, 'grad_norm': 3.503476142883301, 'learning_rate': 1.7942790102875959e-06, 'num_tokens': 2144854.0, 'mean_token_accuracy': 0.6960012577474117, 'epoch': 0.25}
 25%|██▍       | 359/1449 [2:14:29<6:53:30, 22.76s/it] 25%|██▍       | 360/1449 [2:14:51<6:48:56, 22.53s/it]                                                      {'loss': 1.0107, 'grad_norm': 3.548214912414551, 'learning_rate': 1.7928898159065953e-06, 'num_tokens': 2150913.0, 'mean_token_accuracy': 0.7270371615886688, 'epoch': 0.25}
 25%|██▍       | 360/1449 [2:14:51<6:48:56, 22.53s/it] 25%|██▍       | 361/1449 [2:15:13<6:45:16, 22.35s/it]                                                      {'loss': 0.954, 'grad_norm': 3.232992172241211, 'learning_rate': 1.791496488429254e-06, 'num_tokens': 2158294.0, 'mean_token_accuracy': 0.7326806299388409, 'epoch': 0.25}
 25%|██▍       | 361/1449 [2:15:13<6:45:16, 22.35s/it] 25%|██▍       | 362/1449 [2:15:35<6:42:25, 22.21s/it]                                                      {'loss': 1.0343, 'grad_norm': 3.05452823638916, 'learning_rate': 1.7900990351185694e-06, 'num_tokens': 2164885.0, 'mean_token_accuracy': 0.7102304026484489, 'epoch': 0.25}
 25%|██▍       | 362/1449 [2:15:35<6:42:25, 22.21s/it] 25%|██▌       | 363/1449 [2:15:57<6:39:57, 22.10s/it]                                                      {'loss': 1.1065, 'grad_norm': 3.071533679962158, 'learning_rate': 1.7886974632590457e-06, 'num_tokens': 2170971.0, 'mean_token_accuracy': 0.7043489217758179, 'epoch': 0.25}
 25%|██▌       | 363/1449 [2:15:57<6:39:57, 22.10s/it] 25%|██▌       | 364/1449 [2:16:19<6:39:13, 22.08s/it]                                                      {'loss': 1.0157, 'grad_norm': 3.2067501544952393, 'learning_rate': 1.7872917801566558e-06, 'num_tokens': 2177919.0, 'mean_token_accuracy': 0.7078168876469135, 'epoch': 0.25}
 25%|██▌       | 364/1449 [2:16:19<6:39:13, 22.08s/it] 25%|██▌       | 365/1449 [2:16:42<6:41:23, 22.22s/it]                                                      {'loss': 0.9465, 'grad_norm': 3.1441116333007812, 'learning_rate': 1.785881993138803e-06, 'num_tokens': 2184163.0, 'mean_token_accuracy': 0.7325281016528606, 'epoch': 0.25}
 25%|██▌       | 365/1449 [2:16:42<6:41:23, 22.22s/it] 25%|██▌       | 366/1449 [2:17:03<6:38:53, 22.10s/it]                                                      {'loss': 1.033, 'grad_norm': 3.5743470191955566, 'learning_rate': 1.7844681095542838e-06, 'num_tokens': 2190211.0, 'mean_token_accuracy': 0.7199339792132378, 'epoch': 0.25}
 25%|██▌       | 366/1449 [2:17:03<6:38:53, 22.10s/it] 25%|██▌       | 367/1449 [2:17:26<6:39:46, 22.17s/it]                                                      {'loss': 1.0565, 'grad_norm': 3.3840601444244385, 'learning_rate': 1.7830501367732482e-06, 'num_tokens': 2196100.0, 'mean_token_accuracy': 0.7098420970141888, 'epoch': 0.25}
 25%|██▌       | 367/1449 [2:17:26<6:39:46, 22.17s/it] 25%|██▌       | 368/1449 [2:17:48<6:38:59, 22.15s/it]                                                      {'loss': 1.0372, 'grad_norm': 3.18357515335083, 'learning_rate': 1.7816280821871623e-06, 'num_tokens': 2201942.0, 'mean_token_accuracy': 0.7161823436617851, 'epoch': 0.25}
 25%|██▌       | 368/1449 [2:17:48<6:38:59, 22.15s/it] 25%|██▌       | 369/1449 [2:18:10<6:38:07, 22.12s/it]                                                      {'loss': 1.0017, 'grad_norm': 3.57997465133667, 'learning_rate': 1.7802019532087692e-06, 'num_tokens': 2207868.0, 'mean_token_accuracy': 0.7236626483500004, 'epoch': 0.25}
 25%|██▌       | 369/1449 [2:18:10<6:38:07, 22.12s/it] 26%|██▌       | 370/1449 [2:18:32<6:39:02, 22.19s/it]                                                      {'loss': 1.1813, 'grad_norm': 3.834345817565918, 'learning_rate': 1.7787717572720506e-06, 'num_tokens': 2212754.0, 'mean_token_accuracy': 0.6805516965687275, 'epoch': 0.26}
 26%|██▌       | 370/1449 [2:18:32<6:39:02, 22.19s/it] 26%|██▌       | 371/1449 [2:18:54<6:38:33, 22.18s/it]                                                      {'loss': 1.1064, 'grad_norm': 3.6693005561828613, 'learning_rate': 1.7773375018321886e-06, 'num_tokens': 2218361.0, 'mean_token_accuracy': 0.6962563619017601, 'epoch': 0.26}
 26%|██▌       | 371/1449 [2:18:54<6:38:33, 22.18s/it] 26%|██▌       | 372/1449 [2:19:16<6:35:48, 22.05s/it]                                                      {'loss': 1.1418, 'grad_norm': 3.671786069869995, 'learning_rate': 1.7758991943655253e-06, 'num_tokens': 2224404.0, 'mean_token_accuracy': 0.6962713971734047, 'epoch': 0.26}
 26%|██▌       | 372/1449 [2:19:16<6:35:48, 22.05s/it] 26%|██▌       | 373/1449 [2:19:38<6:36:08, 22.09s/it]                                                      {'loss': 0.9466, 'grad_norm': 3.394900321960449, 'learning_rate': 1.7744568423695256e-06, 'num_tokens': 2230695.0, 'mean_token_accuracy': 0.7360901981592178, 'epoch': 0.26}
 26%|██▌       | 373/1449 [2:19:38<6:36:08, 22.09s/it] 26%|██▌       | 374/1449 [2:20:01<6:36:40, 22.14s/it]                                                      {'loss': 1.1032, 'grad_norm': 3.6049954891204834, 'learning_rate': 1.773010453362737e-06, 'num_tokens': 2235766.0, 'mean_token_accuracy': 0.699199702590704, 'epoch': 0.26}
 26%|██▌       | 374/1449 [2:20:01<6:36:40, 22.14s/it] 26%|██▌       | 375/1449 [2:20:23<6:34:58, 22.07s/it]                                                      {'loss': 1.2544, 'grad_norm': 4.058786392211914, 'learning_rate': 1.7715600348847507e-06, 'num_tokens': 2241031.0, 'mean_token_accuracy': 0.6613907106220722, 'epoch': 0.26}
 26%|██▌       | 375/1449 [2:20:23<6:34:58, 22.07s/it] 26%|██▌       | 376/1449 [2:20:44<6:32:27, 21.95s/it]                                                      {'loss': 1.1055, 'grad_norm': 3.1375911235809326, 'learning_rate': 1.770105594496162e-06, 'num_tokens': 2246946.0, 'mean_token_accuracy': 0.7049240507185459, 'epoch': 0.26}
 26%|██▌       | 376/1449 [2:20:44<6:32:27, 21.95s/it] 26%|██▌       | 377/1449 [2:21:06<6:33:29, 22.02s/it]                                                      {'loss': 1.1166, 'grad_norm': 4.16411018371582, 'learning_rate': 1.7686471397785318e-06, 'num_tokens': 2252054.0, 'mean_token_accuracy': 0.6951403841376305, 'epoch': 0.26}
 26%|██▌       | 377/1449 [2:21:06<6:33:29, 22.02s/it] 26%|██▌       | 378/1449 [2:21:29<6:34:11, 22.08s/it]                                                      {'loss': 1.1668, 'grad_norm': 3.747868537902832, 'learning_rate': 1.7671846783343467e-06, 'num_tokens': 2257680.0, 'mean_token_accuracy': 0.6870930641889572, 'epoch': 0.26}
 26%|██▌       | 378/1449 [2:21:29<6:34:11, 22.08s/it] 26%|██▌       | 379/1449 [2:21:50<6:30:30, 21.90s/it]                                                      {'loss': 0.9148, 'grad_norm': 3.3110177516937256, 'learning_rate': 1.7657182177869785e-06, 'num_tokens': 2263534.0, 'mean_token_accuracy': 0.7366790995001793, 'epoch': 0.26}
 26%|██▌       | 379/1449 [2:21:50<6:30:30, 21.90s/it] 26%|██▌       | 380/1449 [2:22:12<6:31:33, 21.98s/it]                                                      {'loss': 1.1765, 'grad_norm': 3.828852653503418, 'learning_rate': 1.7642477657806452e-06, 'num_tokens': 2268727.0, 'mean_token_accuracy': 0.6923938542604446, 'epoch': 0.26}
 26%|██▌       | 380/1449 [2:22:12<6:31:33, 21.98s/it] 26%|██▋       | 381/1449 [2:22:35<6:33:07, 22.09s/it]                                                      {'loss': 0.936, 'grad_norm': 3.1703755855560303, 'learning_rate': 1.7627733299803712e-06, 'num_tokens': 2276078.0, 'mean_token_accuracy': 0.7160296440124512, 'epoch': 0.26}
 26%|██▋       | 381/1449 [2:22:35<6:33:07, 22.09s/it] 26%|██▋       | 382/1449 [2:22:56<6:30:45, 21.97s/it]                                                      {'loss': 1.0958, 'grad_norm': 2.9868547916412354, 'learning_rate': 1.7612949180719472e-06, 'num_tokens': 2282632.0, 'mean_token_accuracy': 0.7044333443045616, 'epoch': 0.26}
 26%|██▋       | 382/1449 [2:22:56<6:30:45, 21.97s/it] 26%|██▋       | 383/1449 [2:23:19<6:31:50, 22.05s/it]                                                      {'loss': 1.0526, 'grad_norm': 3.6649460792541504, 'learning_rate': 1.7598125377618902e-06, 'num_tokens': 2288035.0, 'mean_token_accuracy': 0.7008507438004017, 'epoch': 0.26}
 26%|██▋       | 383/1449 [2:23:19<6:31:50, 22.05s/it] 27%|██▋       | 384/1449 [2:23:40<6:30:21, 21.99s/it]                                                      {'loss': 1.0227, 'grad_norm': 3.2066938877105713, 'learning_rate': 1.7583261967774038e-06, 'num_tokens': 2293915.0, 'mean_token_accuracy': 0.7117509245872498, 'epoch': 0.26}
 27%|██▋       | 384/1449 [2:23:40<6:30:21, 21.99s/it] 27%|██▋       | 385/1449 [2:24:03<6:32:38, 22.14s/it]                                                      {'loss': 1.0336, 'grad_norm': 3.1746177673339844, 'learning_rate': 1.7568359028663363e-06, 'num_tokens': 2300510.0, 'mean_token_accuracy': 0.7194733768701553, 'epoch': 0.27}
 27%|██▋       | 385/1449 [2:24:03<6:32:38, 22.14s/it] 27%|██▋       | 386/1449 [2:24:26<6:35:05, 22.30s/it]                                                      {'loss': 1.0376, 'grad_norm': 3.3798794746398926, 'learning_rate': 1.755341663797142e-06, 'num_tokens': 2306201.0, 'mean_token_accuracy': 0.7095405720174313, 'epoch': 0.27}
 27%|██▋       | 386/1449 [2:24:26<6:35:05, 22.30s/it] 27%|██▋       | 387/1449 [2:24:48<6:35:36, 22.35s/it]                                                      {'loss': 1.0454, 'grad_norm': 3.2133750915527344, 'learning_rate': 1.7538434873588408e-06, 'num_tokens': 2313889.0, 'mean_token_accuracy': 0.7020626440644264, 'epoch': 0.27}
 27%|██▋       | 387/1449 [2:24:48<6:35:36, 22.35s/it] 27%|██▋       | 388/1449 [2:25:11<6:37:44, 22.49s/it]                                                      {'loss': 1.0074, 'grad_norm': 3.271251916885376, 'learning_rate': 1.7523413813609756e-06, 'num_tokens': 2320383.0, 'mean_token_accuracy': 0.7198095172643661, 'epoch': 0.27}
 27%|██▋       | 388/1449 [2:25:11<6:37:44, 22.49s/it] 27%|██▋       | 389/1449 [2:25:33<6:36:28, 22.44s/it]                                                      {'loss': 0.8926, 'grad_norm': 3.419182300567627, 'learning_rate': 1.750835353633574e-06, 'num_tokens': 2326218.0, 'mean_token_accuracy': 0.7396729364991188, 'epoch': 0.27}
 27%|██▋       | 389/1449 [2:25:33<6:36:28, 22.44s/it] 27%|██▋       | 390/1449 [2:25:55<6:34:05, 22.33s/it]                                                      {'loss': 1.1054, 'grad_norm': 3.9666943550109863, 'learning_rate': 1.7493254120271055e-06, 'num_tokens': 2332601.0, 'mean_token_accuracy': 0.7080111354589462, 'epoch': 0.27}
 27%|██▋       | 390/1449 [2:25:55<6:34:05, 22.33s/it] 27%|██▋       | 391/1449 [2:26:18<6:34:44, 22.39s/it]                                                      {'loss': 1.2458, 'grad_norm': 3.279025077819824, 'learning_rate': 1.747811564412442e-06, 'num_tokens': 2339978.0, 'mean_token_accuracy': 0.6814905628561974, 'epoch': 0.27}
 27%|██▋       | 391/1449 [2:26:18<6:34:44, 22.39s/it] 27%|██▋       | 392/1449 [2:26:40<6:32:24, 22.27s/it]                                                      {'loss': 1.1745, 'grad_norm': 3.3053150177001953, 'learning_rate': 1.7462938186808168e-06, 'num_tokens': 2346080.0, 'mean_token_accuracy': 0.6874602288007736, 'epoch': 0.27}
 27%|██▋       | 392/1449 [2:26:40<6:32:24, 22.27s/it] 27%|██▋       | 393/1449 [2:27:02<6:30:50, 22.21s/it]                                                      {'loss': 1.0314, 'grad_norm': 3.5754683017730713, 'learning_rate': 1.7447721827437819e-06, 'num_tokens': 2351973.0, 'mean_token_accuracy': 0.7090652659535408, 'epoch': 0.27}
 27%|██▋       | 393/1449 [2:27:02<6:30:50, 22.21s/it] 27%|██▋       | 394/1449 [2:27:25<6:33:59, 22.41s/it]                                                      {'loss': 1.0321, 'grad_norm': 3.228508710861206, 'learning_rate': 1.743246664533168e-06, 'num_tokens': 2357698.0, 'mean_token_accuracy': 0.7061327584087849, 'epoch': 0.27}
 27%|██▋       | 394/1449 [2:27:25<6:33:59, 22.41s/it] 27%|██▋       | 395/1449 [2:27:47<6:34:02, 22.43s/it]                                                      {'loss': 1.0495, 'grad_norm': 3.583982467651367, 'learning_rate': 1.7417172720010433e-06, 'num_tokens': 2363021.0, 'mean_token_accuracy': 0.7041324712336063, 'epoch': 0.27}
 27%|██▋       | 395/1449 [2:27:47<6:34:02, 22.43s/it] 27%|██▋       | 396/1449 [2:28:09<6:31:45, 22.32s/it]                                                      {'loss': 1.0624, 'grad_norm': 3.4615628719329834, 'learning_rate': 1.7401840131196714e-06, 'num_tokens': 2369383.0, 'mean_token_accuracy': 0.7157457135617733, 'epoch': 0.27}
 27%|██▋       | 396/1449 [2:28:09<6:31:45, 22.32s/it] 27%|██▋       | 397/1449 [2:28:31<6:29:42, 22.23s/it]                                                      {'loss': 1.0569, 'grad_norm': 3.2406437397003174, 'learning_rate': 1.7386468958814705e-06, 'num_tokens': 2375250.0, 'mean_token_accuracy': 0.70588019490242, 'epoch': 0.27}
 27%|██▋       | 397/1449 [2:28:31<6:29:42, 22.23s/it] 27%|██▋       | 398/1449 [2:28:53<6:28:01, 22.15s/it]                                                      {'loss': 0.9771, 'grad_norm': 3.664930582046509, 'learning_rate': 1.7371059282989702e-06, 'num_tokens': 2380811.0, 'mean_token_accuracy': 0.721132155507803, 'epoch': 0.27}
 27%|██▋       | 398/1449 [2:28:53<6:28:01, 22.15s/it] 28%|██▊       | 399/1449 [2:29:15<6:26:33, 22.09s/it]                                                      {'loss': 0.9966, 'grad_norm': 3.2642858028411865, 'learning_rate': 1.7355611184047716e-06, 'num_tokens': 2386898.0, 'mean_token_accuracy': 0.7245950698852539, 'epoch': 0.28}
 28%|██▊       | 399/1449 [2:29:15<6:26:33, 22.09s/it] 28%|██▊       | 400/1449 [2:29:37<6:24:57, 22.02s/it]                                                      {'loss': 1.0006, 'grad_norm': 3.3648416996002197, 'learning_rate': 1.7340124742515048e-06, 'num_tokens': 2392636.0, 'mean_token_accuracy': 0.7241858914494514, 'epoch': 0.28}
 28%|██▊       | 400/1449 [2:29:37<6:24:57, 22.02s/it][INFO|trainer.py:3966] 2025-06-06 02:39:03,656 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400
[INFO|configuration_utils.py:423] 2025-06-06 02:39:03,662 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/config.json
[INFO|configuration_utils.py:908] 2025-06-06 02:39:03,664 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 02:39:11,872 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 02:39:11,876 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 02:39:11,878 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/special_tokens_map.json
[2025-06-06 02:39:12,103] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step400 is about to be saved!
[2025-06-06 02:39:12,110] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/global_step400/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 02:39:12,111] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/global_step400/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 02:39:12,126] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/global_step400/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 02:39:12,128] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 02:39:31,771] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 02:39:31,826] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 02:39:32,633] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step400 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 02:39:44,353 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 02:39:44,355 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 28%|██▊       | 401/1449 [2:30:42<10:09:02, 34.87s/it]                                                       {'loss': 1.054, 'grad_norm': 3.4342334270477295, 'learning_rate': 1.732460003911786e-06, 'num_tokens': 2399104.0, 'mean_token_accuracy': 0.7256152369081974, 'epoch': 0.28}
 28%|██▊       | 401/1449 [2:30:42<10:09:02, 34.87s/it] 28%|██▊       | 402/1449 [2:31:04<9:01:47, 31.05s/it]                                                       {'loss': 1.0185, 'grad_norm': 3.280888080596924, 'learning_rate': 1.7309037154781768e-06, 'num_tokens': 2405151.0, 'mean_token_accuracy': 0.7192011661827564, 'epoch': 0.28}
 28%|██▊       | 402/1449 [2:31:04<9:01:47, 31.05s/it] 28%|██▊       | 403/1449 [2:31:26<8:14:42, 28.38s/it]                                                      {'loss': 1.1598, 'grad_norm': 3.1825618743896484, 'learning_rate': 1.7293436170631413e-06, 'num_tokens': 2411362.0, 'mean_token_accuracy': 0.6902991905808449, 'epoch': 0.28}
 28%|██▊       | 403/1449 [2:31:26<8:14:42, 28.38s/it] 28%|██▊       | 404/1449 [2:31:48<7:42:18, 26.54s/it]                                                      {'loss': 1.0605, 'grad_norm': 3.2267043590545654, 'learning_rate': 1.7277797167990031e-06, 'num_tokens': 2417308.0, 'mean_token_accuracy': 0.7109290882945061, 'epoch': 0.28}
 28%|██▊       | 404/1449 [2:31:48<7:42:18, 26.54s/it] 28%|██▊       | 405/1449 [2:32:10<7:18:24, 25.20s/it]                                                      {'loss': 1.141, 'grad_norm': 3.46305251121521, 'learning_rate': 1.726212022837905e-06, 'num_tokens': 2422888.0, 'mean_token_accuracy': 0.6918235644698143, 'epoch': 0.28}
 28%|██▊       | 405/1449 [2:32:10<7:18:24, 25.20s/it] 28%|██▊       | 406/1449 [2:32:32<7:01:04, 24.22s/it]                                                      {'loss': 1.1206, 'grad_norm': 3.5950748920440674, 'learning_rate': 1.7246405433517639e-06, 'num_tokens': 2429128.0, 'mean_token_accuracy': 0.702862586826086, 'epoch': 0.28}
 28%|██▊       | 406/1449 [2:32:32<7:01:04, 24.22s/it] 28%|██▊       | 407/1449 [2:32:54<6:49:10, 23.56s/it]                                                      {'loss': 1.066, 'grad_norm': 3.3984315395355225, 'learning_rate': 1.7230652865322308e-06, 'num_tokens': 2434642.0, 'mean_token_accuracy': 0.710494264960289, 'epoch': 0.28}
 28%|██▊       | 407/1449 [2:32:54<6:49:10, 23.56s/it] 28%|██▊       | 408/1449 [2:33:16<6:40:25, 23.08s/it]                                                      {'loss': 1.0539, 'grad_norm': 3.656845808029175, 'learning_rate': 1.7214862605906455e-06, 'num_tokens': 2439973.0, 'mean_token_accuracy': 0.7034775093197823, 'epoch': 0.28}
 28%|██▊       | 408/1449 [2:33:16<6:40:25, 23.08s/it] 28%|██▊       | 409/1449 [2:33:38<6:34:47, 22.78s/it]                                                      {'loss': 1.0844, 'grad_norm': 3.466742515563965, 'learning_rate': 1.7199034737579958e-06, 'num_tokens': 2445632.0, 'mean_token_accuracy': 0.6977927051484585, 'epoch': 0.28}
 28%|██▊       | 409/1449 [2:33:38<6:34:47, 22.78s/it] 28%|██▊       | 410/1449 [2:34:00<6:29:19, 22.48s/it]                                                      {'loss': 1.1464, 'grad_norm': 3.568232774734497, 'learning_rate': 1.718316934284874e-06, 'num_tokens': 2450711.0, 'mean_token_accuracy': 0.6994306184351444, 'epoch': 0.28}
 28%|██▊       | 410/1449 [2:34:00<6:29:19, 22.48s/it] 28%|██▊       | 411/1449 [2:34:22<6:25:27, 22.28s/it]                                                      {'loss': 0.9328, 'grad_norm': 3.134608507156372, 'learning_rate': 1.7167266504414339e-06, 'num_tokens': 2456907.0, 'mean_token_accuracy': 0.7300610691308975, 'epoch': 0.28}
 28%|██▊       | 411/1449 [2:34:22<6:25:27, 22.28s/it] 28%|██▊       | 412/1449 [2:34:44<6:22:38, 22.14s/it]                                                      {'loss': 1.0464, 'grad_norm': 3.485685348510742, 'learning_rate': 1.7151326305173469e-06, 'num_tokens': 2462658.0, 'mean_token_accuracy': 0.711140900850296, 'epoch': 0.28}
 28%|██▊       | 412/1449 [2:34:44<6:22:38, 22.14s/it] 29%|██▊       | 413/1449 [2:35:06<6:20:36, 22.04s/it]                                                      {'loss': 1.092, 'grad_norm': 3.5149528980255127, 'learning_rate': 1.7135348828217597e-06, 'num_tokens': 2468297.0, 'mean_token_accuracy': 0.6990011446177959, 'epoch': 0.28}
 29%|██▊       | 413/1449 [2:35:06<6:20:36, 22.04s/it] 29%|██▊       | 414/1449 [2:35:28<6:20:06, 22.03s/it]                                                      {'loss': 1.0298, 'grad_norm': 3.8993966579437256, 'learning_rate': 1.7119334156832511e-06, 'num_tokens': 2474244.0, 'mean_token_accuracy': 0.7201835103332996, 'epoch': 0.29}
 29%|██▊       | 414/1449 [2:35:28<6:20:06, 22.03s/it] 29%|██▊       | 415/1449 [2:35:49<6:17:34, 21.91s/it]                                                      {'loss': 1.217, 'grad_norm': 4.041653633117676, 'learning_rate': 1.7103282374497883e-06, 'num_tokens': 2479266.0, 'mean_token_accuracy': 0.6782270483672619, 'epoch': 0.29}
 29%|██▊       | 415/1449 [2:35:49<6:17:34, 21.91s/it] 29%|██▊       | 416/1449 [2:36:11<6:17:15, 21.91s/it]                                                      {'loss': 1.1234, 'grad_norm': 3.596176862716675, 'learning_rate': 1.708719356488683e-06, 'num_tokens': 2485094.0, 'mean_token_accuracy': 0.6987767554819584, 'epoch': 0.29}
 29%|██▊       | 416/1449 [2:36:11<6:17:15, 21.91s/it] 29%|██▉       | 417/1449 [2:36:33<6:15:51, 21.85s/it]                                                      {'loss': 1.0964, 'grad_norm': 3.831425428390503, 'learning_rate': 1.7071067811865474e-06, 'num_tokens': 2490339.0, 'mean_token_accuracy': 0.70660699903965, 'epoch': 0.29}
 29%|██▉       | 417/1449 [2:36:33<6:15:51, 21.85s/it] 29%|██▉       | 418/1449 [2:36:55<6:14:59, 21.82s/it]                                                      {'loss': 0.9772, 'grad_norm': 3.5346996784210205, 'learning_rate': 1.705490519949253e-06, 'num_tokens': 2495595.0, 'mean_token_accuracy': 0.7359013296663761, 'epoch': 0.29}
 29%|██▉       | 418/1449 [2:36:55<6:14:59, 21.82s/it] 29%|██▉       | 419/1449 [2:37:16<6:13:59, 21.79s/it]                                                      {'loss': 1.0871, 'grad_norm': 3.541355848312378, 'learning_rate': 1.7038705812018831e-06, 'num_tokens': 2501467.0, 'mean_token_accuracy': 0.7111956588923931, 'epoch': 0.29}
 29%|██▉       | 419/1449 [2:37:16<6:13:59, 21.79s/it] 29%|██▉       | 420/1449 [2:37:38<6:13:41, 21.79s/it]                                                      {'loss': 1.0253, 'grad_norm': 3.6155946254730225, 'learning_rate': 1.7022469733886924e-06, 'num_tokens': 2506849.0, 'mean_token_accuracy': 0.7129472009837627, 'epoch': 0.29}
 29%|██▉       | 420/1449 [2:37:38<6:13:41, 21.79s/it] 29%|██▉       | 421/1449 [2:38:00<6:14:36, 21.86s/it]                                                      {'loss': 1.1109, 'grad_norm': 3.782111883163452, 'learning_rate': 1.70061970497306e-06, 'num_tokens': 2512354.0, 'mean_token_accuracy': 0.6936124265193939, 'epoch': 0.29}
 29%|██▉       | 421/1449 [2:38:00<6:14:36, 21.86s/it] 29%|██▉       | 422/1449 [2:38:22<6:13:34, 21.83s/it]                                                      {'loss': 1.1102, 'grad_norm': 3.297273635864258, 'learning_rate': 1.6989887844374471e-06, 'num_tokens': 2518197.0, 'mean_token_accuracy': 0.7027269676327705, 'epoch': 0.29}
 29%|██▉       | 422/1449 [2:38:22<6:13:34, 21.83s/it] 29%|██▉       | 423/1449 [2:38:43<6:11:00, 21.70s/it]                                                      {'loss': 1.0949, 'grad_norm': 3.5344619750976562, 'learning_rate': 1.6973542202833526e-06, 'num_tokens': 2523973.0, 'mean_token_accuracy': 0.7084389589726925, 'epoch': 0.29}
 29%|██▉       | 423/1449 [2:38:43<6:11:00, 21.70s/it] 29%|██▉       | 424/1449 [2:39:05<6:09:12, 21.61s/it]                                                      {'loss': 1.0258, 'grad_norm': 2.783369302749634, 'learning_rate': 1.6957160210312677e-06, 'num_tokens': 2531333.0, 'mean_token_accuracy': 0.7120247296988964, 'epoch': 0.29}
 29%|██▉       | 424/1449 [2:39:05<6:09:12, 21.61s/it] 29%|██▉       | 425/1449 [2:39:26<6:08:29, 21.59s/it]                                                      {'loss': 0.9821, 'grad_norm': 3.418351650238037, 'learning_rate': 1.694074195220634e-06, 'num_tokens': 2537428.0, 'mean_token_accuracy': 0.7401853017508984, 'epoch': 0.29}
 29%|██▉       | 425/1449 [2:39:26<6:08:29, 21.59s/it] 29%|██▉       | 426/1449 [2:39:48<6:08:55, 21.64s/it]                                                      {'loss': 1.0699, 'grad_norm': 3.288421392440796, 'learning_rate': 1.6924287514097948e-06, 'num_tokens': 2543699.0, 'mean_token_accuracy': 0.6977858617901802, 'epoch': 0.29}
 29%|██▉       | 426/1449 [2:39:48<6:08:55, 21.64s/it] 29%|██▉       | 427/1449 [2:40:10<6:07:38, 21.58s/it]                                                      {'loss': 1.1152, 'grad_norm': 3.364342212677002, 'learning_rate': 1.6907796981759548e-06, 'num_tokens': 2549892.0, 'mean_token_accuracy': 0.7054971270263195, 'epoch': 0.29}
 29%|██▉       | 427/1449 [2:40:10<6:07:38, 21.58s/it] 30%|██▉       | 428/1449 [2:40:31<6:07:32, 21.60s/it]                                                      {'loss': 1.0894, 'grad_norm': 3.3926687240600586, 'learning_rate': 1.6891270441151326e-06, 'num_tokens': 2555769.0, 'mean_token_accuracy': 0.6911129951477051, 'epoch': 0.3}
 30%|██▉       | 428/1449 [2:40:31<6:07:32, 21.60s/it] 30%|██▉       | 429/1449 [2:40:53<6:07:41, 21.63s/it]                                                      {'loss': 0.9165, 'grad_norm': 3.7162091732025146, 'learning_rate': 1.6874707978421178e-06, 'num_tokens': 2561283.0, 'mean_token_accuracy': 0.73952367156744, 'epoch': 0.3}
 30%|██▉       | 429/1449 [2:40:53<6:07:41, 21.63s/it] 30%|██▉       | 430/1449 [2:41:15<6:07:18, 21.63s/it]                                                      {'loss': 1.016, 'grad_norm': 3.109261989593506, 'learning_rate': 1.6858109679904243e-06, 'num_tokens': 2567585.0, 'mean_token_accuracy': 0.7236909568309784, 'epoch': 0.3}
 30%|██▉       | 430/1449 [2:41:15<6:07:18, 21.63s/it] 30%|██▉       | 431/1449 [2:41:36<6:07:18, 21.65s/it]                                                      {'loss': 0.9726, 'grad_norm': 3.481278657913208, 'learning_rate': 1.6841475632122457e-06, 'num_tokens': 2573103.0, 'mean_token_accuracy': 0.7312052734196186, 'epoch': 0.3}
 30%|██▉       | 431/1449 [2:41:36<6:07:18, 21.65s/it] 30%|██▉       | 432/1449 [2:41:58<6:06:01, 21.59s/it]                                                      {'loss': 1.0096, 'grad_norm': 3.4616963863372803, 'learning_rate': 1.682480592178412e-06, 'num_tokens': 2578953.0, 'mean_token_accuracy': 0.7190860994160175, 'epoch': 0.3}
 30%|██▉       | 432/1449 [2:41:58<6:06:01, 21.59s/it] 30%|██▉       | 433/1449 [2:42:19<6:05:12, 21.57s/it]                                                      {'loss': 1.0349, 'grad_norm': 3.3809499740600586, 'learning_rate': 1.680810063578342e-06, 'num_tokens': 2584949.0, 'mean_token_accuracy': 0.7115185484290123, 'epoch': 0.3}
 30%|██▉       | 433/1449 [2:42:19<6:05:12, 21.57s/it] 30%|██▉       | 434/1449 [2:42:41<6:04:11, 21.53s/it]                                                      {'loss': 1.0904, 'grad_norm': 4.094272613525391, 'learning_rate': 1.6791359861199994e-06, 'num_tokens': 2590702.0, 'mean_token_accuracy': 0.6958408914506435, 'epoch': 0.3}
 30%|██▉       | 434/1449 [2:42:41<6:04:11, 21.53s/it] 30%|███       | 435/1449 [2:43:02<6:04:07, 21.55s/it]                                                      {'loss': 1.0604, 'grad_norm': 3.149583101272583, 'learning_rate': 1.6774583685298466e-06, 'num_tokens': 2596707.0, 'mean_token_accuracy': 0.6980425454676151, 'epoch': 0.3}
 30%|███       | 435/1449 [2:43:02<6:04:07, 21.55s/it] 30%|███       | 436/1449 [2:43:24<6:05:01, 21.62s/it]                                                      {'loss': 1.1756, 'grad_norm': 3.4980974197387695, 'learning_rate': 1.6757772195528001e-06, 'num_tokens': 2602731.0, 'mean_token_accuracy': 0.6854519322514534, 'epoch': 0.3}
 30%|███       | 436/1449 [2:43:24<6:05:01, 21.62s/it] 30%|███       | 437/1449 [2:43:46<6:04:48, 21.63s/it]                                                      {'loss': 1.0423, 'grad_norm': 3.295485019683838, 'learning_rate': 1.6740925479521844e-06, 'num_tokens': 2609337.0, 'mean_token_accuracy': 0.7207808569073677, 'epoch': 0.3}
 30%|███       | 437/1449 [2:43:46<6:04:48, 21.63s/it] 30%|███       | 438/1449 [2:44:08<6:06:03, 21.72s/it]                                                      {'loss': 1.1374, 'grad_norm': 3.654736042022705, 'learning_rate': 1.6724043625096864e-06, 'num_tokens': 2614919.0, 'mean_token_accuracy': 0.6933881938457489, 'epoch': 0.3}
 30%|███       | 438/1449 [2:44:08<6:06:03, 21.72s/it] 30%|███       | 439/1449 [2:44:29<6:05:59, 21.74s/it]                                                      {'loss': 0.9777, 'grad_norm': 3.5708627700805664, 'learning_rate': 1.6707126720253095e-06, 'num_tokens': 2620830.0, 'mean_token_accuracy': 0.737500749528408, 'epoch': 0.3}
 30%|███       | 439/1449 [2:44:29<6:05:59, 21.74s/it] 30%|███       | 440/1449 [2:44:51<6:05:47, 21.75s/it]                                                      {'loss': 1.1507, 'grad_norm': 3.41460919380188, 'learning_rate': 1.6690174853173274e-06, 'num_tokens': 2628030.0, 'mean_token_accuracy': 0.6860772632062435, 'epoch': 0.3}
 30%|███       | 440/1449 [2:44:51<6:05:47, 21.75s/it] 30%|███       | 441/1449 [2:45:13<6:06:17, 21.80s/it]                                                      {'loss': 1.0199, 'grad_norm': 3.88429856300354, 'learning_rate': 1.6673188112222395e-06, 'num_tokens': 2633826.0, 'mean_token_accuracy': 0.7227993234992027, 'epoch': 0.3}
 30%|███       | 441/1449 [2:45:13<6:06:17, 21.80s/it] 31%|███       | 442/1449 [2:45:35<6:04:43, 21.73s/it]                                                      {'loss': 0.9828, 'grad_norm': 3.186535596847534, 'learning_rate': 1.665616658594723e-06, 'num_tokens': 2640342.0, 'mean_token_accuracy': 0.7316615134477615, 'epoch': 0.3}
 31%|███       | 442/1449 [2:45:35<6:04:43, 21.73s/it] 31%|███       | 443/1449 [2:45:57<6:05:13, 21.78s/it]                                                      {'loss': 1.0234, 'grad_norm': 3.3496487140655518, 'learning_rate': 1.6639110363075882e-06, 'num_tokens': 2646074.0, 'mean_token_accuracy': 0.7225298471748829, 'epoch': 0.31}
 31%|███       | 443/1449 [2:45:57<6:05:13, 21.78s/it] 31%|███       | 444/1449 [2:46:18<6:04:07, 21.74s/it]                                                      {'loss': 1.0226, 'grad_norm': 3.5653319358825684, 'learning_rate': 1.6622019532517318e-06, 'num_tokens': 2652003.0, 'mean_token_accuracy': 0.7192934229969978, 'epoch': 0.31}
 31%|███       | 444/1449 [2:46:18<6:04:07, 21.74s/it] 31%|███       | 445/1449 [2:46:40<6:03:42, 21.74s/it]                                                      {'loss': 1.1301, 'grad_norm': 3.420104503631592, 'learning_rate': 1.6604894183360897e-06, 'num_tokens': 2657873.0, 'mean_token_accuracy': 0.6957314759492874, 'epoch': 0.31}
 31%|███       | 445/1449 [2:46:40<6:03:42, 21.74s/it] 31%|███       | 446/1449 [2:47:02<6:04:52, 21.83s/it]                                                      {'loss': 0.9666, 'grad_norm': 3.5000760555267334, 'learning_rate': 1.658773440487592e-06, 'num_tokens': 2663774.0, 'mean_token_accuracy': 0.7325000613927841, 'epoch': 0.31}
 31%|███       | 446/1449 [2:47:02<6:04:52, 21.83s/it] 31%|███       | 447/1449 [2:47:24<6:03:26, 21.76s/it]                                                      {'loss': 1.0475, 'grad_norm': 3.7154788970947266, 'learning_rate': 1.6570540286511156e-06, 'num_tokens': 2669757.0, 'mean_token_accuracy': 0.7091869562864304, 'epoch': 0.31}
 31%|███       | 447/1449 [2:47:24<6:03:26, 21.76s/it] 31%|███       | 448/1449 [2:47:45<6:03:45, 21.80s/it]                                                      {'loss': 1.1464, 'grad_norm': 3.553743362426758, 'learning_rate': 1.655331191789438e-06, 'num_tokens': 2675089.0, 'mean_token_accuracy': 0.6852967366576195, 'epoch': 0.31}
 31%|███       | 448/1449 [2:47:45<6:03:45, 21.80s/it] 31%|███       | 449/1449 [2:48:07<6:02:42, 21.76s/it]                                                      {'loss': 1.0557, 'grad_norm': 3.409473419189453, 'learning_rate': 1.6536049388831895e-06, 'num_tokens': 2680569.0, 'mean_token_accuracy': 0.7080781981348991, 'epoch': 0.31}
 31%|███       | 449/1449 [2:48:07<6:02:42, 21.76s/it] 31%|███       | 450/1449 [2:48:29<6:02:05, 21.75s/it]                                                      {'loss': 1.1533, 'grad_norm': 3.1379594802856445, 'learning_rate': 1.6518752789308076e-06, 'num_tokens': 2686286.0, 'mean_token_accuracy': 0.6965271644294262, 'epoch': 0.31}
 31%|███       | 450/1449 [2:48:29<6:02:05, 21.75s/it][INFO|trainer.py:3966] 2025-06-06 02:57:55,425 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450
[INFO|configuration_utils.py:423] 2025-06-06 02:57:55,431 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/config.json
[INFO|configuration_utils.py:908] 2025-06-06 02:57:55,433 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 02:58:02,592 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 02:58:02,595 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 02:58:02,597 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/special_tokens_map.json
[2025-06-06 02:58:02,801] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step450 is about to be saved!
[2025-06-06 02:58:02,808] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/global_step450/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 02:58:02,808] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/global_step450/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 02:58:02,823] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/global_step450/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 02:58:02,824] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/global_step450/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 02:58:23,023] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/global_step450/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 02:58:23,094] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-450/global_step450/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 02:58:24,086] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step450 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 02:58:34,810 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 02:58:34,812 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 31%|███       | 451/1449 [2:49:32<9:27:32, 34.12s/it]                                                      {'loss': 1.0513, 'grad_norm': 2.933295965194702, 'learning_rate': 1.6501422209484905e-06, 'num_tokens': 2692819.0, 'mean_token_accuracy': 0.7124973684549332, 'epoch': 0.31}
 31%|███       | 451/1449 [2:49:32<9:27:32, 34.12s/it] 31%|███       | 452/1449 [2:49:54<8:26:02, 30.45s/it]                                                      {'loss': 0.9743, 'grad_norm': 2.950103521347046, 'learning_rate': 1.6484057739701484e-06, 'num_tokens': 2700305.0, 'mean_token_accuracy': 0.7345979325473309, 'epoch': 0.31}
 31%|███       | 452/1449 [2:49:54<8:26:02, 30.45s/it] 31%|███▏      | 453/1449 [2:50:16<7:43:22, 27.91s/it]                                                      {'loss': 1.0998, 'grad_norm': 3.3035221099853516, 'learning_rate': 1.6466659470473577e-06, 'num_tokens': 2706526.0, 'mean_token_accuracy': 0.7013257071375847, 'epoch': 0.31}
 31%|███▏      | 453/1449 [2:50:16<7:43:22, 27.91s/it] 31%|███▏      | 454/1449 [2:50:38<7:13:29, 26.14s/it]                                                      {'loss': 1.1721, 'grad_norm': 3.403388261795044, 'learning_rate': 1.6449227492493129e-06, 'num_tokens': 2712115.0, 'mean_token_accuracy': 0.6969425976276398, 'epoch': 0.31}
 31%|███▏      | 454/1449 [2:50:38<7:13:29, 26.14s/it] 31%|███▏      | 455/1449 [2:50:59<6:50:54, 24.80s/it]                                                      {'loss': 1.1104, 'grad_norm': 3.387444019317627, 'learning_rate': 1.6431761896627805e-06, 'num_tokens': 2717977.0, 'mean_token_accuracy': 0.6954375505447388, 'epoch': 0.31}
 31%|███▏      | 455/1449 [2:50:59<6:50:54, 24.80s/it] 31%|███▏      | 456/1449 [2:51:21<6:36:50, 23.98s/it]                                                      {'loss': 1.1841, 'grad_norm': 3.462472915649414, 'learning_rate': 1.641426277392051e-06, 'num_tokens': 2723762.0, 'mean_token_accuracy': 0.6858886890113354, 'epoch': 0.31}
 31%|███▏      | 456/1449 [2:51:21<6:36:50, 23.98s/it] 32%|███▏      | 457/1449 [2:51:43<6:24:45, 23.27s/it]                                                      {'loss': 1.1121, 'grad_norm': 3.3500282764434814, 'learning_rate': 1.6396730215588912e-06, 'num_tokens': 2729746.0, 'mean_token_accuracy': 0.6961408853530884, 'epoch': 0.32}
 32%|███▏      | 457/1449 [2:51:43<6:24:45, 23.27s/it] 32%|███▏      | 458/1449 [2:52:05<6:16:56, 22.82s/it]                                                      {'loss': 1.051, 'grad_norm': 3.1842803955078125, 'learning_rate': 1.6379164313024964e-06, 'num_tokens': 2735571.0, 'mean_token_accuracy': 0.713069774210453, 'epoch': 0.32}
 32%|███▏      | 458/1449 [2:52:05<6:16:56, 22.82s/it] 32%|███▏      | 459/1449 [2:52:27<6:12:40, 22.59s/it]                                                      {'loss': 1.0641, 'grad_norm': 3.5225653648376465, 'learning_rate': 1.6361565157794446e-06, 'num_tokens': 2740571.0, 'mean_token_accuracy': 0.7074466943740845, 'epoch': 0.32}
 32%|███▏      | 459/1449 [2:52:27<6:12:40, 22.59s/it] 32%|███▏      | 460/1449 [2:52:49<6:07:38, 22.30s/it]                                                      {'loss': 1.0978, 'grad_norm': 3.6279735565185547, 'learning_rate': 1.6343932841636455e-06, 'num_tokens': 2746147.0, 'mean_token_accuracy': 0.7036676704883575, 'epoch': 0.32}
 32%|███▏      | 460/1449 [2:52:49<6:07:38, 22.30s/it] 32%|███▏      | 461/1449 [2:53:11<6:06:06, 22.23s/it]                                                      {'loss': 1.0208, 'grad_norm': 3.864335536956787, 'learning_rate': 1.6326267456462963e-06, 'num_tokens': 2751418.0, 'mean_token_accuracy': 0.7148782834410667, 'epoch': 0.32}
 32%|███▏      | 461/1449 [2:53:11<6:06:06, 22.23s/it] 32%|███▏      | 462/1449 [2:53:32<6:02:47, 22.05s/it]                                                      {'loss': 1.1117, 'grad_norm': 3.310535430908203, 'learning_rate': 1.6308569094358313e-06, 'num_tokens': 2757314.0, 'mean_token_accuracy': 0.6961029656231403, 'epoch': 0.32}
 32%|███▏      | 462/1449 [2:53:32<6:02:47, 22.05s/it] 32%|███▏      | 463/1449 [2:53:54<6:01:54, 22.02s/it]                                                      {'loss': 1.1187, 'grad_norm': 3.953219413757324, 'learning_rate': 1.6290837847578747e-06, 'num_tokens': 2762773.0, 'mean_token_accuracy': 0.6981736160814762, 'epoch': 0.32}
 32%|███▏      | 463/1449 [2:53:54<6:01:54, 22.02s/it] 32%|███▏      | 464/1449 [2:54:16<5:58:42, 21.85s/it]                                                      {'loss': 1.0982, 'grad_norm': 3.883249521255493, 'learning_rate': 1.6273073808551928e-06, 'num_tokens': 2769495.0, 'mean_token_accuracy': 0.7048634476959705, 'epoch': 0.32}
 32%|███▏      | 464/1449 [2:54:16<5:58:42, 21.85s/it] 32%|███▏      | 465/1449 [2:54:38<6:00:14, 21.97s/it]                                                      {'loss': 1.165, 'grad_norm': 3.626678228378296, 'learning_rate': 1.6255277069876451e-06, 'num_tokens': 2775344.0, 'mean_token_accuracy': 0.6771959140896797, 'epoch': 0.32}
 32%|███▏      | 465/1449 [2:54:38<6:00:14, 21.97s/it] 32%|███▏      | 466/1449 [2:55:00<6:00:30, 22.00s/it]                                                      {'loss': 1.0679, 'grad_norm': 3.052659511566162, 'learning_rate': 1.6237447724321372e-06, 'num_tokens': 2781541.0, 'mean_token_accuracy': 0.7120815180242062, 'epoch': 0.32}
 32%|███▏      | 466/1449 [2:55:00<6:00:30, 22.00s/it] 32%|███▏      | 467/1449 [2:55:22<5:59:22, 21.96s/it]                                                      {'loss': 1.0108, 'grad_norm': 3.223414182662964, 'learning_rate': 1.6219585864825703e-06, 'num_tokens': 2787098.0, 'mean_token_accuracy': 0.7309311404824257, 'epoch': 0.32}
 32%|███▏      | 467/1449 [2:55:22<5:59:22, 21.96s/it] 32%|███▏      | 468/1449 [2:55:44<5:59:11, 21.97s/it]                                                      {'loss': 0.9904, 'grad_norm': 3.2450878620147705, 'learning_rate': 1.6201691584497958e-06, 'num_tokens': 2792897.0, 'mean_token_accuracy': 0.724933385848999, 'epoch': 0.32}
 32%|███▏      | 468/1449 [2:55:44<5:59:11, 21.97s/it] 32%|███▏      | 469/1449 [2:56:05<5:56:56, 21.85s/it]                                                      {'loss': 1.1101, 'grad_norm': 3.7310264110565186, 'learning_rate': 1.6183764976615639e-06, 'num_tokens': 2798263.0, 'mean_token_accuracy': 0.7000932097434998, 'epoch': 0.32}
 32%|███▏      | 469/1449 [2:56:05<5:56:56, 21.85s/it] 32%|███▏      | 470/1449 [2:56:27<5:57:30, 21.91s/it]                                                      {'loss': 1.1825, 'grad_norm': 3.7569777965545654, 'learning_rate': 1.6165806134624766e-06, 'num_tokens': 2803885.0, 'mean_token_accuracy': 0.6790575906634331, 'epoch': 0.32}
 32%|███▏      | 470/1449 [2:56:27<5:57:30, 21.91s/it] 33%|███▎      | 471/1449 [2:56:49<5:56:33, 21.87s/it]                                                      {'loss': 1.1398, 'grad_norm': 3.908273935317993, 'learning_rate': 1.6147815152139384e-06, 'num_tokens': 2809662.0, 'mean_token_accuracy': 0.6933993175625801, 'epoch': 0.32}
 33%|███▎      | 471/1449 [2:56:49<5:56:33, 21.87s/it] 33%|███▎      | 472/1449 [2:57:11<5:56:35, 21.90s/it]                                                      {'loss': 1.0699, 'grad_norm': 3.3225600719451904, 'learning_rate': 1.612979212294108e-06, 'num_tokens': 2815511.0, 'mean_token_accuracy': 0.7058695070445538, 'epoch': 0.33}
 33%|███▎      | 472/1449 [2:57:11<5:56:35, 21.90s/it] 33%|███▎      | 473/1449 [2:57:33<5:54:59, 21.82s/it]                                                      {'loss': 0.9572, 'grad_norm': 3.329505205154419, 'learning_rate': 1.6111737140978491e-06, 'num_tokens': 2821095.0, 'mean_token_accuracy': 0.7238738536834717, 'epoch': 0.33}
 33%|███▎      | 473/1449 [2:57:33<5:54:59, 21.82s/it] 33%|███▎      | 474/1449 [2:57:55<5:54:56, 21.84s/it]                                                      {'loss': 1.0464, 'grad_norm': 3.3802807331085205, 'learning_rate': 1.609365030036681e-06, 'num_tokens': 2827138.0, 'mean_token_accuracy': 0.71711540594697, 'epoch': 0.33}
 33%|███▎      | 474/1449 [2:57:55<5:54:56, 21.84s/it] 33%|███▎      | 475/1449 [2:58:17<5:56:11, 21.94s/it]                                                      {'loss': 0.9603, 'grad_norm': 3.611215829849243, 'learning_rate': 1.6075531695387302e-06, 'num_tokens': 2832848.0, 'mean_token_accuracy': 0.7319022566080093, 'epoch': 0.33}
 33%|███▎      | 475/1449 [2:58:17<5:56:11, 21.94s/it] 33%|███▎      | 476/1449 [2:58:39<5:56:54, 22.01s/it]                                                      {'loss': 1.1185, 'grad_norm': 3.7632551193237305, 'learning_rate': 1.6057381420486813e-06, 'num_tokens': 2838884.0, 'mean_token_accuracy': 0.6915957890450954, 'epoch': 0.33}
 33%|███▎      | 476/1449 [2:58:39<5:56:54, 22.01s/it] 33%|███▎      | 477/1449 [2:59:02<5:58:50, 22.15s/it]                                                      {'loss': 0.9131, 'grad_norm': 3.1068406105041504, 'learning_rate': 1.6039199570277267e-06, 'num_tokens': 2845354.0, 'mean_token_accuracy': 0.7286961935460567, 'epoch': 0.33}
 33%|███▎      | 477/1449 [2:59:02<5:58:50, 22.15s/it] 33%|███▎      | 478/1449 [2:59:23<5:57:03, 22.06s/it]                                                      {'loss': 0.9272, 'grad_norm': 3.2292072772979736, 'learning_rate': 1.6020986239535188e-06, 'num_tokens': 2851592.0, 'mean_token_accuracy': 0.7340716943144798, 'epoch': 0.33}
 33%|███▎      | 478/1449 [2:59:23<5:57:03, 22.06s/it] 33%|███▎      | 479/1449 [2:59:45<5:53:08, 21.84s/it]                                                      {'loss': 1.1483, 'grad_norm': 3.995016098022461, 'learning_rate': 1.6002741523201194e-06, 'num_tokens': 2857391.0, 'mean_token_accuracy': 0.6935136094689369, 'epoch': 0.33}
 33%|███▎      | 479/1449 [2:59:45<5:53:08, 21.84s/it] 33%|███▎      | 480/1449 [3:00:06<5:50:42, 21.72s/it]                                                      {'loss': 0.9913, 'grad_norm': 3.412623167037964, 'learning_rate': 1.5984465516379511e-06, 'num_tokens': 2863989.0, 'mean_token_accuracy': 0.717635415494442, 'epoch': 0.33}
 33%|███▎      | 480/1449 [3:00:06<5:50:42, 21.72s/it] 33%|███▎      | 481/1449 [3:00:28<5:52:36, 21.86s/it]                                                      {'loss': 1.1142, 'grad_norm': 3.449662685394287, 'learning_rate': 1.596615831433747e-06, 'num_tokens': 2869623.0, 'mean_token_accuracy': 0.6913805343210697, 'epoch': 0.33}
 33%|███▎      | 481/1449 [3:00:28<5:52:36, 21.86s/it] 33%|███▎      | 482/1449 [3:00:50<5:50:39, 21.76s/it]                                                      {'loss': 1.1026, 'grad_norm': 3.8406617641448975, 'learning_rate': 1.5947820012505013e-06, 'num_tokens': 2874938.0, 'mean_token_accuracy': 0.6967114321887493, 'epoch': 0.33}
 33%|███▎      | 482/1449 [3:00:50<5:50:39, 21.76s/it] 33%|███▎      | 483/1449 [3:01:12<5:52:05, 21.87s/it]                                                      {'loss': 1.1582, 'grad_norm': 3.9979453086853027, 'learning_rate': 1.5929450706474197e-06, 'num_tokens': 2880529.0, 'mean_token_accuracy': 0.6927737593650818, 'epoch': 0.33}
 33%|███▎      | 483/1449 [3:01:12<5:52:05, 21.87s/it] 33%|███▎      | 484/1449 [3:01:34<5:50:11, 21.77s/it]                                                      {'loss': 1.122, 'grad_norm': 3.4206666946411133, 'learning_rate': 1.5911050491998692e-06, 'num_tokens': 2886596.0, 'mean_token_accuracy': 0.6916468292474747, 'epoch': 0.33}
 33%|███▎      | 484/1449 [3:01:34<5:50:11, 21.77s/it] 33%|███▎      | 485/1449 [3:01:55<5:46:52, 21.59s/it]                                                      {'loss': 1.0858, 'grad_norm': 3.107334613800049, 'learning_rate': 1.589261946499329e-06, 'num_tokens': 2892943.0, 'mean_token_accuracy': 0.711125984787941, 'epoch': 0.33}
 33%|███▎      | 485/1449 [3:01:55<5:46:52, 21.59s/it] 34%|███▎      | 486/1449 [3:02:16<5:46:22, 21.58s/it]                                                      {'loss': 1.0969, 'grad_norm': 3.192700147628784, 'learning_rate': 1.5874157721533397e-06, 'num_tokens': 2899480.0, 'mean_token_accuracy': 0.7144103683531284, 'epoch': 0.34}
 34%|███▎      | 486/1449 [3:02:16<5:46:22, 21.58s/it] 34%|███▎      | 487/1449 [3:02:37<5:43:00, 21.39s/it]                                                      {'loss': 1.0022, 'grad_norm': 3.5445635318756104, 'learning_rate': 1.5855665357854528e-06, 'num_tokens': 2905002.0, 'mean_token_accuracy': 0.7203096300363541, 'epoch': 0.34}
 34%|███▎      | 487/1449 [3:02:37<5:43:00, 21.39s/it] 34%|███▎      | 488/1449 [3:02:59<5:43:35, 21.45s/it]                                                      {'loss': 1.0174, 'grad_norm': 3.878145694732666, 'learning_rate': 1.5837142470351825e-06, 'num_tokens': 2910001.0, 'mean_token_accuracy': 0.7130747139453888, 'epoch': 0.34}
 34%|███▎      | 488/1449 [3:02:59<5:43:35, 21.45s/it] 34%|███▎      | 489/1449 [3:03:20<5:41:45, 21.36s/it]                                                      {'loss': 0.9982, 'grad_norm': 3.8335585594177246, 'learning_rate': 1.5818589155579529e-06, 'num_tokens': 2916917.0, 'mean_token_accuracy': 0.7092443555593491, 'epoch': 0.34}
 34%|███▎      | 489/1449 [3:03:20<5:41:45, 21.36s/it] 34%|███▍      | 490/1449 [3:03:41<5:41:38, 21.38s/it]                                                      {'loss': 0.971, 'grad_norm': 3.391834259033203, 'learning_rate': 1.5800005510250496e-06, 'num_tokens': 2922397.0, 'mean_token_accuracy': 0.7148846015334129, 'epoch': 0.34}
 34%|███▍      | 490/1449 [3:03:41<5:41:38, 21.38s/it] 34%|███▍      | 491/1449 [3:04:02<5:40:03, 21.30s/it]                                                      {'loss': 1.1011, 'grad_norm': 3.5066757202148438, 'learning_rate': 1.5781391631235686e-06, 'num_tokens': 2928330.0, 'mean_token_accuracy': 0.7054607942700386, 'epoch': 0.34}
 34%|███▍      | 491/1449 [3:04:02<5:40:03, 21.30s/it] 34%|███▍      | 492/1449 [3:04:24<5:40:54, 21.37s/it]                                                      {'loss': 0.9564, 'grad_norm': 3.266735315322876, 'learning_rate': 1.5762747615563652e-06, 'num_tokens': 2934591.0, 'mean_token_accuracy': 0.730971809476614, 'epoch': 0.34}
 34%|███▍      | 492/1449 [3:04:24<5:40:54, 21.37s/it] 34%|███▍      | 493/1449 [3:04:45<5:39:12, 21.29s/it]                                                      {'loss': 1.0394, 'grad_norm': 3.3613626956939697, 'learning_rate': 1.5744073560420051e-06, 'num_tokens': 2941491.0, 'mean_token_accuracy': 0.6998903416097164, 'epoch': 0.34}
 34%|███▍      | 493/1449 [3:04:45<5:39:12, 21.29s/it] 34%|███▍      | 494/1449 [3:05:07<5:41:00, 21.42s/it]                                                      {'loss': 0.9675, 'grad_norm': 3.568096160888672, 'learning_rate': 1.5725369563147117e-06, 'num_tokens': 2947394.0, 'mean_token_accuracy': 0.7301343306899071, 'epoch': 0.34}
 34%|███▍      | 494/1449 [3:05:07<5:41:00, 21.42s/it] 34%|███▍      | 495/1449 [3:05:29<5:43:38, 21.61s/it]                                                      {'loss': 1.0643, 'grad_norm': 3.5777368545532227, 'learning_rate': 1.5706635721243172e-06, 'num_tokens': 2953067.0, 'mean_token_accuracy': 0.708204198628664, 'epoch': 0.34}
 34%|███▍      | 495/1449 [3:05:29<5:43:38, 21.61s/it] 34%|███▍      | 496/1449 [3:05:51<5:43:20, 21.62s/it]                                                      {'loss': 1.0344, 'grad_norm': 3.994713068008423, 'learning_rate': 1.5687872132362098e-06, 'num_tokens': 2958865.0, 'mean_token_accuracy': 0.7107098549604416, 'epoch': 0.34}
 34%|███▍      | 496/1449 [3:05:51<5:43:20, 21.62s/it] 34%|███▍      | 497/1449 [3:06:13<5:45:10, 21.75s/it]                                                      {'loss': 1.1116, 'grad_norm': 3.496643543243408, 'learning_rate': 1.5669078894312845e-06, 'num_tokens': 2964457.0, 'mean_token_accuracy': 0.6957414932549, 'epoch': 0.34}
 34%|███▍      | 497/1449 [3:06:13<5:45:10, 21.75s/it] 34%|███▍      | 498/1449 [3:06:34<5:44:23, 21.73s/it]                                                      {'loss': 1.092, 'grad_norm': 3.8594887256622314, 'learning_rate': 1.5650256105058921e-06, 'num_tokens': 2969911.0, 'mean_token_accuracy': 0.6956209614872932, 'epoch': 0.34}
 34%|███▍      | 498/1449 [3:06:34<5:44:23, 21.73s/it] 34%|███▍      | 499/1449 [3:06:56<5:44:38, 21.77s/it]                                                      {'loss': 0.9616, 'grad_norm': 3.264482021331787, 'learning_rate': 1.5631403862717867e-06, 'num_tokens': 2975904.0, 'mean_token_accuracy': 0.735042966902256, 'epoch': 0.34}
 34%|███▍      | 499/1449 [3:06:56<5:44:38, 21.77s/it] 35%|███▍      | 500/1449 [3:07:18<5:44:39, 21.79s/it]                                                      {'loss': 1.0115, 'grad_norm': 3.7738351821899414, 'learning_rate': 1.5612522265560758e-06, 'num_tokens': 2982138.0, 'mean_token_accuracy': 0.7134658955037594, 'epoch': 0.34}
 35%|███▍      | 500/1449 [3:07:18<5:44:39, 21.79s/it][INFO|trainer.py:3966] 2025-06-06 03:16:44,447 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500
[INFO|configuration_utils.py:423] 2025-06-06 03:16:44,452 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/config.json
[INFO|configuration_utils.py:908] 2025-06-06 03:16:44,454 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 03:16:50,619 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 03:16:50,622 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 03:16:50,624 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/special_tokens_map.json
[2025-06-06 03:16:50,844] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step500 is about to be saved!
[2025-06-06 03:16:50,850] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 03:16:50,851] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 03:16:50,866] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 03:16:50,869] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 03:17:12,797] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 03:17:12,802] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 03:17:12,835] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 03:17:24,776 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 03:17:24,778 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 35%|███▍      | 501/1449 [3:08:22<9:02:37, 34.34s/it]                                                      {'loss': 1.0407, 'grad_norm': 3.0026323795318604, 'learning_rate': 1.5593611412011684e-06, 'num_tokens': 2988600.0, 'mean_token_accuracy': 0.7105453610420227, 'epoch': 0.35}
 35%|███▍      | 501/1449 [3:08:22<9:02:37, 34.34s/it] 35%|███▍      | 502/1449 [3:08:44<8:05:09, 30.74s/it]                                                      {'loss': 1.0157, 'grad_norm': 3.134814500808716, 'learning_rate': 1.557467140064724e-06, 'num_tokens': 2994791.0, 'mean_token_accuracy': 0.7202545665204525, 'epoch': 0.35}
 35%|███▍      | 502/1449 [3:08:44<8:05:09, 30.74s/it] 35%|███▍      | 503/1449 [3:09:06<7:25:12, 28.24s/it]                                                      {'loss': 0.9199, 'grad_norm': 2.903852701187134, 'learning_rate': 1.5555702330196021e-06, 'num_tokens': 3000956.0, 'mean_token_accuracy': 0.7230654284358025, 'epoch': 0.35}
 35%|███▍      | 503/1449 [3:09:06<7:25:12, 28.24s/it] 35%|███▍      | 504/1449 [3:09:28<6:55:35, 26.39s/it]                                                      {'loss': 1.067, 'grad_norm': 3.2358741760253906, 'learning_rate': 1.5536704299538087e-06, 'num_tokens': 3007299.0, 'mean_token_accuracy': 0.7106047533452511, 'epoch': 0.35}
 35%|███▍      | 504/1449 [3:09:28<6:55:35, 26.39s/it] 35%|███▍      | 505/1449 [3:09:50<6:32:35, 24.95s/it]                                                      {'loss': 1.0598, 'grad_norm': 2.9742023944854736, 'learning_rate': 1.551767740770446e-06, 'num_tokens': 3013637.0, 'mean_token_accuracy': 0.7145615704357624, 'epoch': 0.35}
 35%|███▍      | 505/1449 [3:09:50<6:32:35, 24.95s/it] 35%|███▍      | 506/1449 [3:10:11<6:12:54, 23.73s/it]                                                      {'loss': 1.1839, 'grad_norm': 3.21783709526062, 'learning_rate': 1.549862175387661e-06, 'num_tokens': 3019905.0, 'mean_token_accuracy': 0.6814942248165607, 'epoch': 0.35}
 35%|███▍      | 506/1449 [3:10:11<6:12:54, 23.73s/it] 35%|███▍      | 507/1449 [3:10:32<6:00:29, 22.96s/it]                                                      {'loss': 1.1461, 'grad_norm': 3.26316237449646, 'learning_rate': 1.5479537437385937e-06, 'num_tokens': 3026430.0, 'mean_token_accuracy': 0.6924865990877151, 'epoch': 0.35}
 35%|███▍      | 507/1449 [3:10:32<6:00:29, 22.96s/it] 35%|███▌      | 508/1449 [3:10:53<5:52:18, 22.46s/it]                                                      {'loss': 1.0239, 'grad_norm': 3.399824857711792, 'learning_rate': 1.5460424557713248e-06, 'num_tokens': 3032389.0, 'mean_token_accuracy': 0.7162410877645016, 'epoch': 0.35}
 35%|███▌      | 508/1449 [3:10:53<5:52:18, 22.46s/it] 35%|███▌      | 509/1449 [3:11:15<5:46:17, 22.10s/it]                                                      {'loss': 0.9247, 'grad_norm': 3.2581992149353027, 'learning_rate': 1.5441283214488236e-06, 'num_tokens': 3038728.0, 'mean_token_accuracy': 0.7325982376933098, 'epoch': 0.35}
 35%|███▌      | 509/1449 [3:11:15<5:46:17, 22.10s/it] 35%|███▌      | 510/1449 [3:11:36<5:41:21, 21.81s/it]                                                      {'loss': 0.9251, 'grad_norm': 3.3394570350646973, 'learning_rate': 1.542211350748898e-06, 'num_tokens': 3044694.0, 'mean_token_accuracy': 0.7377530112862587, 'epoch': 0.35}
 35%|███▌      | 510/1449 [3:11:36<5:41:21, 21.81s/it] 35%|███▌      | 511/1449 [3:11:57<5:37:35, 21.59s/it]                                                      {'loss': 1.0349, 'grad_norm': 3.590916395187378, 'learning_rate': 1.540291553664139e-06, 'num_tokens': 3050622.0, 'mean_token_accuracy': 0.7178617268800735, 'epoch': 0.35}
 35%|███▌      | 511/1449 [3:11:57<5:37:35, 21.59s/it] 35%|███▌      | 512/1449 [3:12:18<5:34:53, 21.44s/it]                                                      {'loss': 1.0547, 'grad_norm': 3.568310260772705, 'learning_rate': 1.5383689402018729e-06, 'num_tokens': 3056633.0, 'mean_token_accuracy': 0.7220262102782726, 'epoch': 0.35}
 35%|███▌      | 512/1449 [3:12:18<5:34:53, 21.44s/it] 35%|███▌      | 513/1449 [3:12:39<5:33:02, 21.35s/it]                                                      {'loss': 1.074, 'grad_norm': 3.5505597591400146, 'learning_rate': 1.5364435203841056e-06, 'num_tokens': 3061993.0, 'mean_token_accuracy': 0.6954705379903316, 'epoch': 0.35}
 35%|███▌      | 513/1449 [3:12:39<5:33:02, 21.35s/it] 35%|███▌      | 514/1449 [3:13:00<5:31:34, 21.28s/it]                                                      {'loss': 0.9385, 'grad_norm': 3.5496110916137695, 'learning_rate': 1.534515304247472e-06, 'num_tokens': 3068041.0, 'mean_token_accuracy': 0.7364894039928913, 'epoch': 0.35}
 35%|███▌      | 514/1449 [3:13:00<5:31:34, 21.28s/it] 36%|███▌      | 515/1449 [3:13:22<5:31:57, 21.33s/it]                                                      {'loss': 1.1884, 'grad_norm': 3.9837074279785156, 'learning_rate': 1.5325843018431832e-06, 'num_tokens': 3073306.0, 'mean_token_accuracy': 0.664751835167408, 'epoch': 0.36}
 36%|███▌      | 515/1449 [3:13:22<5:31:57, 21.33s/it] 36%|███▌      | 516/1449 [3:13:43<5:29:59, 21.22s/it]                                                      {'loss': 0.9974, 'grad_norm': 3.0941827297210693, 'learning_rate': 1.5306505232369748e-06, 'num_tokens': 3080257.0, 'mean_token_accuracy': 0.721904207020998, 'epoch': 0.36}
 36%|███▌      | 516/1449 [3:13:43<5:29:59, 21.22s/it] 36%|███▌      | 517/1449 [3:14:04<5:29:22, 21.20s/it]                                                      {'loss': 1.044, 'grad_norm': 3.513000011444092, 'learning_rate': 1.5287139785090532e-06, 'num_tokens': 3085607.0, 'mean_token_accuracy': 0.7076548598706722, 'epoch': 0.36}
 36%|███▌      | 517/1449 [3:14:04<5:29:22, 21.20s/it] 36%|███▌      | 518/1449 [3:14:25<5:28:04, 21.14s/it]                                                      {'loss': 1.0312, 'grad_norm': 3.1195404529571533, 'learning_rate': 1.5267746777540445e-06, 'num_tokens': 3092341.0, 'mean_token_accuracy': 0.7095717042684555, 'epoch': 0.36}
 36%|███▌      | 518/1449 [3:14:25<5:28:04, 21.14s/it] 36%|███▌      | 519/1449 [3:14:46<5:28:51, 21.22s/it]                                                      {'loss': 1.1316, 'grad_norm': 3.3696401119232178, 'learning_rate': 1.5248326310809402e-06, 'num_tokens': 3098461.0, 'mean_token_accuracy': 0.6932053044438362, 'epoch': 0.36}
 36%|███▌      | 519/1449 [3:14:46<5:28:51, 21.22s/it] 36%|███▌      | 520/1449 [3:15:07<5:27:57, 21.18s/it]                                                      {'loss': 1.0004, 'grad_norm': 3.465994358062744, 'learning_rate': 1.5228878486130467e-06, 'num_tokens': 3104204.0, 'mean_token_accuracy': 0.717266034334898, 'epoch': 0.36}
 36%|███▌      | 520/1449 [3:15:07<5:27:57, 21.18s/it] 36%|███▌      | 521/1449 [3:15:28<5:27:47, 21.19s/it]                                                      {'loss': 1.1124, 'grad_norm': 3.5613107681274414, 'learning_rate': 1.5209403404879303e-06, 'num_tokens': 3110155.0, 'mean_token_accuracy': 0.694413997232914, 'epoch': 0.36}
 36%|███▌      | 521/1449 [3:15:28<5:27:47, 21.19s/it] 36%|███▌      | 522/1449 [3:15:50<5:28:28, 21.26s/it]                                                      {'loss': 1.129, 'grad_norm': 3.2171390056610107, 'learning_rate': 1.5189901168573652e-06, 'num_tokens': 3116355.0, 'mean_token_accuracy': 0.6996222510933876, 'epoch': 0.36}
 36%|███▌      | 522/1449 [3:15:50<5:28:28, 21.26s/it] 36%|███▌      | 523/1449 [3:16:11<5:28:47, 21.30s/it]                                                      {'loss': 0.9856, 'grad_norm': 3.1729884147644043, 'learning_rate': 1.5170371878872816e-06, 'num_tokens': 3123313.0, 'mean_token_accuracy': 0.7330207414925098, 'epoch': 0.36}
 36%|███▌      | 523/1449 [3:16:11<5:28:47, 21.30s/it] 36%|███▌      | 524/1449 [3:16:33<5:31:33, 21.51s/it]                                                      {'loss': 1.1285, 'grad_norm': 3.2902638912200928, 'learning_rate': 1.5150815637577115e-06, 'num_tokens': 3129347.0, 'mean_token_accuracy': 0.7008642889559269, 'epoch': 0.36}
 36%|███▌      | 524/1449 [3:16:33<5:31:33, 21.51s/it] 36%|███▌      | 525/1449 [3:16:55<5:31:31, 21.53s/it]                                                      {'loss': 1.1126, 'grad_norm': 3.4795520305633545, 'learning_rate': 1.5131232546627353e-06, 'num_tokens': 3135927.0, 'mean_token_accuracy': 0.706694483757019, 'epoch': 0.36}
 36%|███▌      | 525/1449 [3:16:55<5:31:31, 21.53s/it] 36%|███▋      | 526/1449 [3:17:16<5:30:02, 21.45s/it]                                                      {'loss': 1.0401, 'grad_norm': 3.208486318588257, 'learning_rate': 1.51116227081043e-06, 'num_tokens': 3143286.0, 'mean_token_accuracy': 0.7126391306519508, 'epoch': 0.36}
 36%|███▋      | 526/1449 [3:17:16<5:30:02, 21.45s/it] 36%|███▋      | 527/1449 [3:17:37<5:28:31, 21.38s/it]                                                      {'loss': 0.9764, 'grad_norm': 3.6766951084136963, 'learning_rate': 1.5091986224228155e-06, 'num_tokens': 3148854.0, 'mean_token_accuracy': 0.7186713591217995, 'epoch': 0.36}
 36%|███▋      | 527/1449 [3:17:37<5:28:31, 21.38s/it] 36%|███▋      | 528/1449 [3:17:59<5:27:30, 21.34s/it]                                                      {'loss': 1.0841, 'grad_norm': 3.70170259475708, 'learning_rate': 1.5072323197358001e-06, 'num_tokens': 3154445.0, 'mean_token_accuracy': 0.7153750248253345, 'epoch': 0.36}
 36%|███▋      | 528/1449 [3:17:59<5:27:30, 21.34s/it] 37%|███▋      | 529/1449 [3:18:20<5:26:59, 21.33s/it]                                                      {'loss': 0.9607, 'grad_norm': 3.6332743167877197, 'learning_rate': 1.5052633729991293e-06, 'num_tokens': 3160282.0, 'mean_token_accuracy': 0.7252997159957886, 'epoch': 0.36}
 37%|███▋      | 529/1449 [3:18:20<5:26:59, 21.33s/it] 37%|███▋      | 530/1449 [3:18:41<5:27:40, 21.39s/it]                                                      {'loss': 0.9537, 'grad_norm': 3.2823598384857178, 'learning_rate': 1.5032917924763306e-06, 'num_tokens': 3166238.0, 'mean_token_accuracy': 0.724232230335474, 'epoch': 0.37}
 37%|███▋      | 530/1449 [3:18:41<5:27:40, 21.39s/it] 37%|███▋      | 531/1449 [3:19:02<5:25:34, 21.28s/it]                                                      {'loss': 1.0278, 'grad_norm': 3.481933116912842, 'learning_rate': 1.5013175884446607e-06, 'num_tokens': 3172082.0, 'mean_token_accuracy': 0.7159485854208469, 'epoch': 0.37}
 37%|███▋      | 531/1449 [3:19:02<5:25:34, 21.28s/it] 37%|███▋      | 532/1449 [3:19:24<5:25:47, 21.32s/it]                                                      {'loss': 1.0298, 'grad_norm': 3.388324499130249, 'learning_rate': 1.4993407711950524e-06, 'num_tokens': 3177965.0, 'mean_token_accuracy': 0.7101244144141674, 'epoch': 0.37}
 37%|███▋      | 532/1449 [3:19:24<5:25:47, 21.32s/it] 37%|███▋      | 533/1449 [3:19:45<5:24:02, 21.23s/it]                                                      {'loss': 1.0404, 'grad_norm': 3.1563117504119873, 'learning_rate': 1.4973613510320593e-06, 'num_tokens': 3183713.0, 'mean_token_accuracy': 0.7084310464560986, 'epoch': 0.37}
 37%|███▋      | 533/1449 [3:19:45<5:24:02, 21.23s/it] 37%|███▋      | 534/1449 [3:20:06<5:23:43, 21.23s/it]                                                      {'loss': 1.0745, 'grad_norm': 3.246974229812622, 'learning_rate': 1.4953793382738044e-06, 'num_tokens': 3189737.0, 'mean_token_accuracy': 0.7057561986148357, 'epoch': 0.37}
 37%|███▋      | 534/1449 [3:20:06<5:23:43, 21.23s/it] 37%|███▋      | 535/1449 [3:20:27<5:23:05, 21.21s/it]                                                      {'loss': 1.0378, 'grad_norm': 3.5015461444854736, 'learning_rate': 1.4933947432519242e-06, 'num_tokens': 3195385.0, 'mean_token_accuracy': 0.7164512686431408, 'epoch': 0.37}
 37%|███▋      | 535/1449 [3:20:27<5:23:05, 21.21s/it] 37%|███▋      | 536/1449 [3:20:48<5:22:36, 21.20s/it]                                                      {'loss': 0.9854, 'grad_norm': 3.0029945373535156, 'learning_rate': 1.4914075763115169e-06, 'num_tokens': 3201672.0, 'mean_token_accuracy': 0.7310055941343307, 'epoch': 0.37}
 37%|███▋      | 536/1449 [3:20:48<5:22:36, 21.20s/it] 37%|███▋      | 537/1449 [3:21:10<5:21:57, 21.18s/it]                                                      {'loss': 1.1246, 'grad_norm': 3.800994873046875, 'learning_rate': 1.4894178478110854e-06, 'num_tokens': 3207453.0, 'mean_token_accuracy': 0.6914139799773693, 'epoch': 0.37}
 37%|███▋      | 537/1449 [3:21:10<5:21:57, 21.18s/it] 37%|███▋      | 538/1449 [3:21:31<5:21:00, 21.14s/it]                                                      {'loss': 0.8276, 'grad_norm': 3.225341796875, 'learning_rate': 1.4874255681224875e-06, 'num_tokens': 3213592.0, 'mean_token_accuracy': 0.7616499662399292, 'epoch': 0.37}
 37%|███▋      | 538/1449 [3:21:31<5:21:00, 21.14s/it] 37%|███▋      | 539/1449 [3:21:52<5:21:32, 21.20s/it]                                                      {'loss': 1.0993, 'grad_norm': 3.1551337242126465, 'learning_rate': 1.485430747630878e-06, 'num_tokens': 3219589.0, 'mean_token_accuracy': 0.7031289078295231, 'epoch': 0.37}
 37%|███▋      | 539/1449 [3:21:52<5:21:32, 21.20s/it] 37%|███▋      | 540/1449 [3:22:13<5:21:25, 21.22s/it]                                                      {'loss': 1.1214, 'grad_norm': 3.2730700969696045, 'learning_rate': 1.4834333967346572e-06, 'num_tokens': 3225982.0, 'mean_token_accuracy': 0.6938830763101578, 'epoch': 0.37}
 37%|███▋      | 540/1449 [3:22:13<5:21:25, 21.22s/it] 37%|███▋      | 541/1449 [3:22:35<5:22:36, 21.32s/it]                                                      {'loss': 1.0123, 'grad_norm': 3.2932255268096924, 'learning_rate': 1.4814335258454143e-06, 'num_tokens': 3232147.0, 'mean_token_accuracy': 0.7203222960233688, 'epoch': 0.37}
 37%|███▋      | 541/1449 [3:22:35<5:22:36, 21.32s/it] 37%|███▋      | 542/1449 [3:22:56<5:23:41, 21.41s/it]                                                      {'loss': 1.0754, 'grad_norm': 3.4382400512695312, 'learning_rate': 1.4794311453878758e-06, 'num_tokens': 3237993.0, 'mean_token_accuracy': 0.7064313627779484, 'epoch': 0.37}
 37%|███▋      | 542/1449 [3:22:56<5:23:41, 21.41s/it] 37%|███▋      | 543/1449 [3:23:18<5:25:06, 21.53s/it]                                                      {'loss': 1.0185, 'grad_norm': 3.128972291946411, 'learning_rate': 1.477426265799849e-06, 'num_tokens': 3244469.0, 'mean_token_accuracy': 0.7127017341554165, 'epoch': 0.37}
 37%|███▋      | 543/1449 [3:23:18<5:25:06, 21.53s/it] 38%|███▊      | 544/1449 [3:23:40<5:24:19, 21.50s/it]                                                      {'loss': 1.1574, 'grad_norm': 3.5656187534332275, 'learning_rate': 1.4754188975321691e-06, 'num_tokens': 3250521.0, 'mean_token_accuracy': 0.676520224660635, 'epoch': 0.38}
 38%|███▊      | 544/1449 [3:23:40<5:24:19, 21.50s/it] 38%|███▊      | 545/1449 [3:24:01<5:24:09, 21.52s/it]                                                      {'loss': 1.0529, 'grad_norm': 3.3172173500061035, 'learning_rate': 1.4734090510486433e-06, 'num_tokens': 3256462.0, 'mean_token_accuracy': 0.7104241885244846, 'epoch': 0.38}
 38%|███▊      | 545/1449 [3:24:01<5:24:09, 21.52s/it] 38%|███▊      | 546/1449 [3:24:22<5:22:40, 21.44s/it]                                                      {'loss': 1.0242, 'grad_norm': 3.6305181980133057, 'learning_rate': 1.4713967368259978e-06, 'num_tokens': 3261857.0, 'mean_token_accuracy': 0.7172501944005489, 'epoch': 0.38}
 38%|███▊      | 546/1449 [3:24:22<5:22:40, 21.44s/it] 38%|███▊      | 547/1449 [3:24:44<5:21:12, 21.37s/it]                                                      {'loss': 1.0174, 'grad_norm': 2.9652512073516846, 'learning_rate': 1.4693819653538213e-06, 'num_tokens': 3268268.0, 'mean_token_accuracy': 0.699346512556076, 'epoch': 0.38}
 38%|███▊      | 547/1449 [3:24:44<5:21:12, 21.37s/it] 38%|███▊      | 548/1449 [3:25:05<5:19:02, 21.25s/it]                                                      {'loss': 1.0754, 'grad_norm': 3.6972744464874268, 'learning_rate': 1.4673647471345123e-06, 'num_tokens': 3273949.0, 'mean_token_accuracy': 0.7069611102342606, 'epoch': 0.38}
 38%|███▊      | 548/1449 [3:25:05<5:19:02, 21.25s/it] 38%|███▊      | 549/1449 [3:25:26<5:19:05, 21.27s/it]                                                      {'loss': 0.9525, 'grad_norm': 3.6465108394622803, 'learning_rate': 1.4653450926832234e-06, 'num_tokens': 3279561.0, 'mean_token_accuracy': 0.7308352664113045, 'epoch': 0.38}
 38%|███▊      | 549/1449 [3:25:26<5:19:05, 21.27s/it] 38%|███▊      | 550/1449 [3:25:47<5:17:43, 21.20s/it]                                                      {'loss': 1.0608, 'grad_norm': 3.6984407901763916, 'learning_rate': 1.463323012527806e-06, 'num_tokens': 3284679.0, 'mean_token_accuracy': 0.7107541337609291, 'epoch': 0.38}
 38%|███▊      | 550/1449 [3:25:47<5:17:43, 21.20s/it][INFO|trainer.py:3966] 2025-06-06 03:35:13,430 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550
[INFO|configuration_utils.py:423] 2025-06-06 03:35:13,440 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/config.json
[INFO|configuration_utils.py:908] 2025-06-06 03:35:13,442 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 03:35:21,228 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 03:35:21,232 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 03:35:21,234 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/special_tokens_map.json
[2025-06-06 03:35:21,433] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step550 is about to be saved!
[2025-06-06 03:35:21,439] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/global_step550/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 03:35:21,439] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/global_step550/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 03:35:21,454] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/global_step550/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 03:35:21,455] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/global_step550/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 03:35:40,569] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/global_step550/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 03:35:40,576] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-550/global_step550/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 03:35:40,608] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step550 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 03:35:51,027 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 03:35:51,028 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 38%|███▊      | 551/1449 [3:26:47<8:12:46, 32.92s/it]                                                      {'loss': 1.0192, 'grad_norm': 3.248560905456543, 'learning_rate': 1.4612985172087565e-06, 'num_tokens': 3290757.0, 'mean_token_accuracy': 0.7099638655781746, 'epoch': 0.38}
 38%|███▊      | 551/1449 [3:26:47<8:12:46, 32.92s/it] 38%|███▊      | 552/1449 [3:27:09<7:21:56, 29.56s/it]                                                      {'loss': 0.9663, 'grad_norm': 3.0204052925109863, 'learning_rate': 1.4592716172791605e-06, 'num_tokens': 3298060.0, 'mean_token_accuracy': 0.7187596783041954, 'epoch': 0.38}
 38%|███▊      | 552/1449 [3:27:09<7:21:56, 29.56s/it] 38%|███▊      | 553/1449 [3:27:30<6:43:54, 27.05s/it]                                                      {'loss': 1.022, 'grad_norm': 3.2244904041290283, 'learning_rate': 1.4572423233046385e-06, 'num_tokens': 3304217.0, 'mean_token_accuracy': 0.7127091772854328, 'epoch': 0.38}
 38%|███▊      | 553/1449 [3:27:30<6:43:54, 27.05s/it] 38%|███▊      | 554/1449 [3:27:52<6:18:22, 25.37s/it]                                                      {'loss': 1.0383, 'grad_norm': 3.729454517364502, 'learning_rate': 1.45521064586329e-06, 'num_tokens': 3310427.0, 'mean_token_accuracy': 0.7081965133547783, 'epoch': 0.38}
 38%|███▊      | 554/1449 [3:27:52<6:18:22, 25.37s/it] 38%|███▊      | 555/1449 [3:28:13<5:58:12, 24.04s/it]                                                      {'loss': 1.1274, 'grad_norm': 3.3992152214050293, 'learning_rate': 1.4531765955456387e-06, 'num_tokens': 3316355.0, 'mean_token_accuracy': 0.6924522221088409, 'epoch': 0.38}
 38%|███▊      | 555/1449 [3:28:13<5:58:12, 24.04s/it] 38%|███▊      | 556/1449 [3:28:34<5:44:20, 23.14s/it]                                                      {'loss': 1.0154, 'grad_norm': 3.465179681777954, 'learning_rate': 1.451140182954578e-06, 'num_tokens': 3322887.0, 'mean_token_accuracy': 0.7235455922782421, 'epoch': 0.38}
 38%|███▊      | 556/1449 [3:28:34<5:44:20, 23.14s/it] 38%|███▊      | 557/1449 [3:28:55<5:35:44, 22.58s/it]                                                      {'loss': 0.951, 'grad_norm': 3.573662281036377, 'learning_rate': 1.4491014187053147e-06, 'num_tokens': 3329081.0, 'mean_token_accuracy': 0.7277514412999153, 'epoch': 0.38}
 38%|███▊      | 557/1449 [3:28:55<5:35:44, 22.58s/it] 39%|███▊      | 558/1449 [3:29:16<5:27:52, 22.08s/it]                                                      {'loss': 1.1653, 'grad_norm': 3.568506956100464, 'learning_rate': 1.447060313425314e-06, 'num_tokens': 3335087.0, 'mean_token_accuracy': 0.6885651424527168, 'epoch': 0.38}
 39%|███▊      | 558/1449 [3:29:16<5:27:52, 22.08s/it] 39%|███▊      | 559/1449 [3:29:37<5:23:26, 21.81s/it]                                                      {'loss': 1.0451, 'grad_norm': 3.331084966659546, 'learning_rate': 1.445016877754245e-06, 'num_tokens': 3340758.0, 'mean_token_accuracy': 0.7098021171987057, 'epoch': 0.39}
 39%|███▊      | 559/1449 [3:29:37<5:23:26, 21.81s/it] 39%|███▊      | 560/1449 [3:29:58<5:19:14, 21.55s/it]                                                      {'loss': 1.1557, 'grad_norm': 3.5527236461639404, 'learning_rate': 1.442971122343923e-06, 'num_tokens': 3346496.0, 'mean_token_accuracy': 0.6852039098739624, 'epoch': 0.39}
 39%|███▊      | 560/1449 [3:29:58<5:19:14, 21.55s/it] 39%|███▊      | 561/1449 [3:30:19<5:17:37, 21.46s/it]                                                      {'loss': 1.1905, 'grad_norm': 3.6369035243988037, 'learning_rate': 1.4409230578582565e-06, 'num_tokens': 3351930.0, 'mean_token_accuracy': 0.6721810884773731, 'epoch': 0.39}
 39%|███▊      | 561/1449 [3:30:19<5:17:37, 21.46s/it] 39%|███▉      | 562/1449 [3:30:40<5:14:55, 21.30s/it]                                                      {'loss': 1.0916, 'grad_norm': 3.733361005783081, 'learning_rate': 1.43887269497319e-06, 'num_tokens': 3357439.0, 'mean_token_accuracy': 0.7026761658489704, 'epoch': 0.39}
 39%|███▉      | 562/1449 [3:30:40<5:14:55, 21.30s/it] 39%|███▉      | 563/1449 [3:31:01<5:13:34, 21.24s/it]                                                      {'loss': 1.178, 'grad_norm': 3.7582666873931885, 'learning_rate': 1.4368200443766493e-06, 'num_tokens': 3362402.0, 'mean_token_accuracy': 0.6756102256476879, 'epoch': 0.39}
 39%|███▉      | 563/1449 [3:31:01<5:13:34, 21.24s/it] 39%|███▉      | 564/1449 [3:31:22<5:12:36, 21.19s/it]                                                      {'loss': 1.0632, 'grad_norm': 3.1997628211975098, 'learning_rate': 1.4347651167684851e-06, 'num_tokens': 3369220.0, 'mean_token_accuracy': 0.7116221152245998, 'epoch': 0.39}
 39%|███▉      | 564/1449 [3:31:22<5:12:36, 21.19s/it] 39%|███▉      | 565/1449 [3:31:43<5:10:51, 21.10s/it]                                                      {'loss': 1.1184, 'grad_norm': 3.8137519359588623, 'learning_rate': 1.4327079228604176e-06, 'num_tokens': 3374702.0, 'mean_token_accuracy': 0.6916246823966503, 'epoch': 0.39}
 39%|███▉      | 565/1449 [3:31:43<5:10:51, 21.10s/it] 39%|███▉      | 566/1449 [3:32:04<5:11:00, 21.13s/it]                                                      {'loss': 0.8915, 'grad_norm': 3.32535719871521, 'learning_rate': 1.4306484733759804e-06, 'num_tokens': 3381596.0, 'mean_token_accuracy': 0.7377301268279552, 'epoch': 0.39}
 39%|███▉      | 566/1449 [3:32:04<5:11:00, 21.13s/it] 39%|███▉      | 567/1449 [3:32:25<5:08:56, 21.02s/it]                                                      {'loss': 0.9644, 'grad_norm': 3.4082188606262207, 'learning_rate': 1.4285867790504647e-06, 'num_tokens': 3386990.0, 'mean_token_accuracy': 0.7287350259721279, 'epoch': 0.39}
 39%|███▉      | 567/1449 [3:32:25<5:08:56, 21.02s/it] 39%|███▉      | 568/1449 [3:32:46<5:09:21, 21.07s/it]                                                      {'loss': 0.8682, 'grad_norm': 3.2940285205841064, 'learning_rate': 1.4265228506308635e-06, 'num_tokens': 3393144.0, 'mean_token_accuracy': 0.7477712742984295, 'epoch': 0.39}
 39%|███▉      | 568/1449 [3:32:46<5:09:21, 21.07s/it] 39%|███▉      | 569/1449 [3:33:07<5:09:41, 21.12s/it]                                                      {'loss': 1.0956, 'grad_norm': 3.8216023445129395, 'learning_rate': 1.424456698875815e-06, 'num_tokens': 3398669.0, 'mean_token_accuracy': 0.7033635079860687, 'epoch': 0.39}
 39%|███▉      | 569/1449 [3:33:08<5:09:41, 21.12s/it] 39%|███▉      | 570/1449 [3:33:28<5:07:36, 21.00s/it]                                                      {'loss': 1.2083, 'grad_norm': 4.379156589508057, 'learning_rate': 1.4223883345555481e-06, 'num_tokens': 3403331.0, 'mean_token_accuracy': 0.6766356639564037, 'epoch': 0.39}
 39%|███▉      | 570/1449 [3:33:28<5:07:36, 21.00s/it] 39%|███▉      | 571/1449 [3:33:49<5:08:14, 21.06s/it]                                                      {'loss': 1.0182, 'grad_norm': 4.052868843078613, 'learning_rate': 1.4203177684518242e-06, 'num_tokens': 3408436.0, 'mean_token_accuracy': 0.7137754149734974, 'epoch': 0.39}
 39%|███▉      | 571/1449 [3:33:49<5:08:14, 21.06s/it] 39%|███▉      | 572/1449 [3:34:10<5:06:45, 20.99s/it]                                                      {'loss': 0.9854, 'grad_norm': 3.5329842567443848, 'learning_rate': 1.418245011357882e-06, 'num_tokens': 3414573.0, 'mean_token_accuracy': 0.7136287838220596, 'epoch': 0.39}
 39%|███▉      | 572/1449 [3:34:10<5:06:45, 20.99s/it] 40%|███▉      | 573/1449 [3:34:31<5:07:04, 21.03s/it]                                                      {'loss': 1.0079, 'grad_norm': 3.9536499977111816, 'learning_rate': 1.4161700740783812e-06, 'num_tokens': 3419801.0, 'mean_token_accuracy': 0.7282411493360996, 'epoch': 0.4}
 40%|███▉      | 573/1449 [3:34:31<5:07:04, 21.03s/it] 40%|███▉      | 574/1449 [3:34:53<5:07:41, 21.10s/it]                                                      {'loss': 0.9962, 'grad_norm': 3.621086835861206, 'learning_rate': 1.414092967429347e-06, 'num_tokens': 3425202.0, 'mean_token_accuracy': 0.7095959521830082, 'epoch': 0.4}
 40%|███▉      | 574/1449 [3:34:53<5:07:41, 21.10s/it] 40%|███▉      | 575/1449 [3:35:13<5:05:55, 21.00s/it]                                                      {'loss': 0.994, 'grad_norm': 4.496849060058594, 'learning_rate': 1.4120137022381115e-06, 'num_tokens': 3431194.0, 'mean_token_accuracy': 0.7197877280414104, 'epoch': 0.4}
 40%|███▉      | 575/1449 [3:35:13<5:05:55, 21.00s/it] 40%|███▉      | 576/1449 [3:35:35<5:08:59, 21.24s/it]                                                      {'loss': 1.06, 'grad_norm': 3.371088743209839, 'learning_rate': 1.4099322893432594e-06, 'num_tokens': 3437326.0, 'mean_token_accuracy': 0.7049840986728668, 'epoch': 0.4}
 40%|███▉      | 576/1449 [3:35:35<5:08:59, 21.24s/it] 40%|███▉      | 577/1449 [3:35:56<5:07:32, 21.16s/it]                                                      {'loss': 0.9117, 'grad_norm': 3.4701032638549805, 'learning_rate': 1.4078487395945712e-06, 'num_tokens': 3443905.0, 'mean_token_accuracy': 0.727938137948513, 'epoch': 0.4}
 40%|███▉      | 577/1449 [3:35:56<5:07:32, 21.16s/it] 40%|███▉      | 578/1449 [3:36:17<5:06:52, 21.14s/it]                                                      {'loss': 1.0823, 'grad_norm': 3.4080941677093506, 'learning_rate': 1.405763063852965e-06, 'num_tokens': 3450160.0, 'mean_token_accuracy': 0.7087903171777725, 'epoch': 0.4}
 40%|███▉      | 578/1449 [3:36:17<5:06:52, 21.14s/it] 40%|███▉      | 579/1449 [3:36:39<5:07:33, 21.21s/it]                                                      {'loss': 1.0739, 'grad_norm': 3.3306894302368164, 'learning_rate': 1.4036752729904419e-06, 'num_tokens': 3456669.0, 'mean_token_accuracy': 0.7167051173746586, 'epoch': 0.4}
 40%|███▉      | 579/1449 [3:36:39<5:07:33, 21.21s/it] 40%|████      | 580/1449 [3:37:00<5:06:30, 21.16s/it]                                                      {'loss': 0.8364, 'grad_norm': 3.6905879974365234, 'learning_rate': 1.4015853778900282e-06, 'num_tokens': 3462318.0, 'mean_token_accuracy': 0.7592624127864838, 'epoch': 0.4}
 40%|████      | 580/1449 [3:37:00<5:06:30, 21.16s/it] 40%|████      | 581/1449 [3:37:21<5:06:20, 21.18s/it]                                                      {'loss': 0.893, 'grad_norm': 3.7192494869232178, 'learning_rate': 1.399493389445719e-06, 'num_tokens': 3468564.0, 'mean_token_accuracy': 0.7332086861133575, 'epoch': 0.4}
 40%|████      | 581/1449 [3:37:21<5:06:20, 21.18s/it] 40%|████      | 582/1449 [3:37:42<5:05:13, 21.12s/it]                                                      {'loss': 1.1048, 'grad_norm': 3.5796968936920166, 'learning_rate': 1.3973993185624219e-06, 'num_tokens': 3474630.0, 'mean_token_accuracy': 0.698235247284174, 'epoch': 0.4}
 40%|████      | 582/1449 [3:37:42<5:05:13, 21.12s/it] 40%|████      | 583/1449 [3:38:03<5:05:15, 21.15s/it]                                                      {'loss': 1.0051, 'grad_norm': 3.5967535972595215, 'learning_rate': 1.3953031761558982e-06, 'num_tokens': 3480162.0, 'mean_token_accuracy': 0.7192875072360039, 'epoch': 0.4}
 40%|████      | 583/1449 [3:38:03<5:05:15, 21.15s/it] 40%|████      | 584/1449 [3:38:24<5:05:32, 21.19s/it]                                                      {'loss': 1.1137, 'grad_norm': 3.4441027641296387, 'learning_rate': 1.3932049731527088e-06, 'num_tokens': 3485728.0, 'mean_token_accuracy': 0.6916216351091862, 'epoch': 0.4}
 40%|████      | 584/1449 [3:38:24<5:05:32, 21.19s/it] 40%|████      | 585/1449 [3:38:45<5:04:30, 21.15s/it]                                                      {'loss': 1.1307, 'grad_norm': 3.439784526824951, 'learning_rate': 1.3911047204901558e-06, 'num_tokens': 3491367.0, 'mean_token_accuracy': 0.7069125398993492, 'epoch': 0.4}
 40%|████      | 585/1449 [3:38:45<5:04:30, 21.15s/it] 40%|████      | 586/1449 [3:39:07<5:04:31, 21.17s/it]                                                      {'loss': 0.9044, 'grad_norm': 2.9688773155212402, 'learning_rate': 1.3890024291162252e-06, 'num_tokens': 3497911.0, 'mean_token_accuracy': 0.7374772019684315, 'epoch': 0.4}
 40%|████      | 586/1449 [3:39:07<5:04:31, 21.17s/it] 41%|████      | 587/1449 [3:39:28<5:03:57, 21.16s/it]                                                      {'loss': 1.0528, 'grad_norm': 3.332900047302246, 'learning_rate': 1.3868981099895293e-06, 'num_tokens': 3503948.0, 'mean_token_accuracy': 0.7076307497918606, 'epoch': 0.4}
 41%|████      | 587/1449 [3:39:28<5:03:57, 21.16s/it] 41%|████      | 588/1449 [3:39:49<5:04:50, 21.24s/it]                                                      {'loss': 1.0061, 'grad_norm': 3.1761415004730225, 'learning_rate': 1.3847917740792523e-06, 'num_tokens': 3510113.0, 'mean_token_accuracy': 0.7049396559596062, 'epoch': 0.41}
 41%|████      | 588/1449 [3:39:49<5:04:50, 21.24s/it] 41%|████      | 589/1449 [3:40:10<5:03:27, 21.17s/it]                                                      {'loss': 0.9418, 'grad_norm': 2.9578840732574463, 'learning_rate': 1.3826834323650898e-06, 'num_tokens': 3516772.0, 'mean_token_accuracy': 0.737418994307518, 'epoch': 0.41}
 41%|████      | 589/1449 [3:40:10<5:03:27, 21.17s/it] 41%|████      | 590/1449 [3:40:32<5:04:06, 21.24s/it]                                                      {'loss': 1.116, 'grad_norm': 3.7548975944519043, 'learning_rate': 1.3805730958371937e-06, 'num_tokens': 3522121.0, 'mean_token_accuracy': 0.701421320438385, 'epoch': 0.41}
 41%|████      | 590/1449 [3:40:32<5:04:06, 21.24s/it] 41%|████      | 591/1449 [3:40:53<5:03:34, 21.23s/it]                                                      {'loss': 1.0766, 'grad_norm': 3.7490768432617188, 'learning_rate': 1.378460775496114e-06, 'num_tokens': 3527310.0, 'mean_token_accuracy': 0.7045754119753838, 'epoch': 0.41}
 41%|████      | 591/1449 [3:40:53<5:03:34, 21.23s/it] 41%|████      | 592/1449 [3:41:14<5:02:13, 21.16s/it]                                                      {'loss': 1.038, 'grad_norm': 3.123593330383301, 'learning_rate': 1.3763464823527421e-06, 'num_tokens': 3533573.0, 'mean_token_accuracy': 0.713103424757719, 'epoch': 0.41}
 41%|████      | 592/1449 [3:41:14<5:02:13, 21.16s/it] 41%|████      | 593/1449 [3:41:36<5:07:55, 21.58s/it]                                                      {'loss': 0.9697, 'grad_norm': 3.214813709259033, 'learning_rate': 1.374230227428253e-06, 'num_tokens': 3539369.0, 'mean_token_accuracy': 0.7266733646392822, 'epoch': 0.41}
 41%|████      | 593/1449 [3:41:36<5:07:55, 21.58s/it] 41%|████      | 594/1449 [3:41:58<5:08:25, 21.64s/it]                                                      {'loss': 1.0765, 'grad_norm': 3.548560619354248, 'learning_rate': 1.3721120217540474e-06, 'num_tokens': 3544620.0, 'mean_token_accuracy': 0.690406171604991, 'epoch': 0.41}
 41%|████      | 594/1449 [3:41:58<5:08:25, 21.64s/it] 41%|████      | 595/1449 [3:42:20<5:10:13, 21.80s/it]                                                      {'loss': 1.0376, 'grad_norm': 3.6236534118652344, 'learning_rate': 1.369991876371695e-06, 'num_tokens': 3549991.0, 'mean_token_accuracy': 0.7048754617571831, 'epoch': 0.41}
 41%|████      | 595/1449 [3:42:20<5:10:13, 21.80s/it] 41%|████      | 596/1449 [3:42:42<5:11:13, 21.89s/it]                                                      {'loss': 0.9904, 'grad_norm': 3.598870038986206, 'learning_rate': 1.3678698023328761e-06, 'num_tokens': 3555470.0, 'mean_token_accuracy': 0.7153141982853413, 'epoch': 0.41}
 41%|████      | 596/1449 [3:42:42<5:11:13, 21.89s/it] 41%|████      | 597/1449 [3:43:04<5:11:06, 21.91s/it]                                                      {'loss': 1.0712, 'grad_norm': 3.9435410499572754, 'learning_rate': 1.3657458106993255e-06, 'num_tokens': 3561207.0, 'mean_token_accuracy': 0.6947065591812134, 'epoch': 0.41}
 41%|████      | 597/1449 [3:43:04<5:11:06, 21.91s/it] 41%|████▏     | 598/1449 [3:43:27<5:12:27, 22.03s/it]                                                      {'loss': 1.0903, 'grad_norm': 3.60048508644104, 'learning_rate': 1.3636199125427732e-06, 'num_tokens': 3567238.0, 'mean_token_accuracy': 0.7067649066448212, 'epoch': 0.41}
 41%|████▏     | 598/1449 [3:43:27<5:12:27, 22.03s/it] 41%|████▏     | 599/1449 [3:43:48<5:10:07, 21.89s/it]                                                      {'loss': 1.0525, 'grad_norm': 3.464341878890991, 'learning_rate': 1.3614921189448877e-06, 'num_tokens': 3573173.0, 'mean_token_accuracy': 0.7115840837359428, 'epoch': 0.41}
 41%|████▏     | 599/1449 [3:43:48<5:10:07, 21.89s/it] 41%|████▏     | 600/1449 [3:44:11<5:11:15, 22.00s/it]                                                      {'loss': 1.1486, 'grad_norm': 3.468940019607544, 'learning_rate': 1.3593624409972172e-06, 'num_tokens': 3578879.0, 'mean_token_accuracy': 0.7071086950600147, 'epoch': 0.41}
 41%|████▏     | 600/1449 [3:44:11<5:11:15, 22.00s/it][INFO|trainer.py:3966] 2025-06-06 03:53:37,107 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600
[INFO|configuration_utils.py:423] 2025-06-06 03:53:37,114 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/config.json
[INFO|configuration_utils.py:908] 2025-06-06 03:53:37,116 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 03:53:44,842 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 03:53:44,846 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 03:53:44,848 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/special_tokens_map.json
[2025-06-06 03:53:45,056] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step600 is about to be saved!
[2025-06-06 03:53:45,063] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/global_step600/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 03:53:45,063] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/global_step600/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 03:53:45,078] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/global_step600/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 03:53:45,079] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/global_step600/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 03:54:06,520] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/global_step600/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 03:54:06,525] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-600/global_step600/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 03:54:07,378] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step600 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 03:54:16,737 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 03:54:16,739 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 41%|████▏     | 601/1449 [3:45:14<8:05:08, 34.33s/it]                                                      {'loss': 1.0163, 'grad_norm': 3.5120620727539062, 'learning_rate': 1.3572308898011327e-06, 'num_tokens': 3584712.0, 'mean_token_accuracy': 0.7240278013050556, 'epoch': 0.41}
 41%|████▏     | 601/1449 [3:45:14<8:05:08, 34.33s/it] 42%|████▏     | 602/1449 [3:45:35<7:11:14, 30.55s/it]                                                      {'loss': 1.0632, 'grad_norm': 3.6384880542755127, 'learning_rate': 1.3550974764677705e-06, 'num_tokens': 3589871.0, 'mean_token_accuracy': 0.7045646123588085, 'epoch': 0.42}
 42%|████▏     | 602/1449 [3:45:35<7:11:14, 30.55s/it] 42%|████▏     | 603/1449 [3:45:57<6:33:11, 27.89s/it]                                                      {'loss': 1.1049, 'grad_norm': 3.6334598064422607, 'learning_rate': 1.3529622121179732e-06, 'num_tokens': 3595423.0, 'mean_token_accuracy': 0.7018727883696556, 'epoch': 0.42}
 42%|████▏     | 603/1449 [3:45:57<6:33:11, 27.89s/it] 42%|████▏     | 604/1449 [3:46:19<6:05:57, 25.99s/it]                                                      {'loss': 1.1073, 'grad_norm': 3.8679394721984863, 'learning_rate': 1.3508251078822318e-06, 'num_tokens': 3601565.0, 'mean_token_accuracy': 0.7105974070727825, 'epoch': 0.42}
 42%|████▏     | 604/1449 [3:46:19<6:05:57, 25.99s/it] 42%|████▏     | 605/1449 [3:46:40<5:47:39, 24.72s/it]                                                      {'loss': 1.1056, 'grad_norm': 3.5188586711883545, 'learning_rate': 1.3486861749006285e-06, 'num_tokens': 3607167.0, 'mean_token_accuracy': 0.6904744505882263, 'epoch': 0.42}
 42%|████▏     | 605/1449 [3:46:40<5:47:39, 24.72s/it] 42%|████▏     | 606/1449 [3:47:02<5:33:28, 23.73s/it]                                                      {'loss': 1.0965, 'grad_norm': 3.4586074352264404, 'learning_rate': 1.3465454243227788e-06, 'num_tokens': 3613546.0, 'mean_token_accuracy': 0.6957461833953857, 'epoch': 0.42}
 42%|████▏     | 606/1449 [3:47:02<5:33:28, 23.73s/it] 42%|████▏     | 607/1449 [3:47:23<5:24:27, 23.12s/it]                                                      {'loss': 1.0428, 'grad_norm': 4.303149700164795, 'learning_rate': 1.3444028673077715e-06, 'num_tokens': 3618562.0, 'mean_token_accuracy': 0.7138156518340111, 'epoch': 0.42}
 42%|████▏     | 607/1449 [3:47:23<5:24:27, 23.12s/it] 42%|████▏     | 608/1449 [3:47:45<5:16:55, 22.61s/it]                                                      {'loss': 0.974, 'grad_norm': 3.5802998542785645, 'learning_rate': 1.3422585150241125e-06, 'num_tokens': 3624882.0, 'mean_token_accuracy': 0.7266013436019421, 'epoch': 0.42}
 42%|████▏     | 608/1449 [3:47:45<5:16:55, 22.61s/it] 42%|████▏     | 609/1449 [3:48:07<5:12:24, 22.31s/it]                                                      {'loss': 1.0907, 'grad_norm': 4.017465114593506, 'learning_rate': 1.3401123786496661e-06, 'num_tokens': 3630314.0, 'mean_token_accuracy': 0.7050699032843113, 'epoch': 0.42}
 42%|████▏     | 609/1449 [3:48:07<5:12:24, 22.31s/it] 42%|████▏     | 610/1449 [3:48:28<5:07:43, 22.01s/it]                                                      {'loss': 0.9466, 'grad_norm': 3.5394575595855713, 'learning_rate': 1.3379644693715964e-06, 'num_tokens': 3636659.0, 'mean_token_accuracy': 0.7250308953225613, 'epoch': 0.42}
 42%|████▏     | 610/1449 [3:48:28<5:07:43, 22.01s/it] 42%|████▏     | 611/1449 [3:48:50<5:06:32, 21.95s/it]                                                      {'loss': 0.9277, 'grad_norm': 3.310408353805542, 'learning_rate': 1.3358147983863085e-06, 'num_tokens': 3643154.0, 'mean_token_accuracy': 0.7412176318466663, 'epoch': 0.42}
 42%|████▏     | 611/1449 [3:48:50<5:06:32, 21.95s/it] 42%|████▏     | 612/1449 [3:49:11<5:04:51, 21.85s/it]                                                      {'loss': 0.9553, 'grad_norm': 3.1751160621643066, 'learning_rate': 1.3336633768993918e-06, 'num_tokens': 3650085.0, 'mean_token_accuracy': 0.7309717871248722, 'epoch': 0.42}
 42%|████▏     | 612/1449 [3:49:11<5:04:51, 21.85s/it] 42%|████▏     | 613/1449 [3:49:33<5:02:48, 21.73s/it]                                                      {'loss': 1.0297, 'grad_norm': 3.487245559692383, 'learning_rate': 1.33151021612556e-06, 'num_tokens': 3656025.0, 'mean_token_accuracy': 0.7164948023855686, 'epoch': 0.42}
 42%|████▏     | 613/1449 [3:49:33<5:02:48, 21.73s/it] 42%|████▏     | 614/1449 [3:49:55<5:02:50, 21.76s/it]                                                      {'loss': 1.0983, 'grad_norm': 3.055255889892578, 'learning_rate': 1.3293553272885926e-06, 'num_tokens': 3663266.0, 'mean_token_accuracy': 0.7042862176895142, 'epoch': 0.42}
 42%|████▏     | 614/1449 [3:49:55<5:02:50, 21.76s/it] 42%|████▏     | 615/1449 [3:50:16<5:01:10, 21.67s/it]                                                      {'loss': 0.9462, 'grad_norm': 3.4274191856384277, 'learning_rate': 1.3271987216212778e-06, 'num_tokens': 3669833.0, 'mean_token_accuracy': 0.7513145543634892, 'epoch': 0.42}
 42%|████▏     | 615/1449 [3:50:16<5:01:10, 21.67s/it] 43%|████▎     | 616/1449 [3:50:38<5:00:51, 21.67s/it]                                                      {'loss': 0.943, 'grad_norm': 3.2686784267425537, 'learning_rate': 1.3250404103653531e-06, 'num_tokens': 3675968.0, 'mean_token_accuracy': 0.7337425649166107, 'epoch': 0.42}
 43%|████▎     | 616/1449 [3:50:38<5:00:51, 21.67s/it] 43%|████▎     | 617/1449 [3:50:59<5:00:23, 21.66s/it]                                                      {'loss': 1.0772, 'grad_norm': 3.501692533493042, 'learning_rate': 1.3228804047714462e-06, 'num_tokens': 3681791.0, 'mean_token_accuracy': 0.7029880955815315, 'epoch': 0.43}
 43%|████▎     | 617/1449 [3:50:59<5:00:23, 21.66s/it] 43%|████▎     | 618/1449 [3:51:21<4:59:51, 21.65s/it]                                                      {'loss': 0.9687, 'grad_norm': 2.985886812210083, 'learning_rate': 1.3207187160990173e-06, 'num_tokens': 3688946.0, 'mean_token_accuracy': 0.7130734249949455, 'epoch': 0.43}
 43%|████▎     | 618/1449 [3:51:21<4:59:51, 21.65s/it] 43%|████▎     | 619/1449 [3:51:43<4:59:22, 21.64s/it]                                                      {'loss': 0.9743, 'grad_norm': 3.372854232788086, 'learning_rate': 1.3185553556162998e-06, 'num_tokens': 3694991.0, 'mean_token_accuracy': 0.7332593128085136, 'epoch': 0.43}
 43%|████▎     | 619/1449 [3:51:43<4:59:22, 21.64s/it] 43%|████▎     | 620/1449 [3:52:04<4:58:00, 21.57s/it]                                                      {'loss': 1.0572, 'grad_norm': 3.6905713081359863, 'learning_rate': 1.3163903346002424e-06, 'num_tokens': 3700373.0, 'mean_token_accuracy': 0.6995369642972946, 'epoch': 0.43}
 43%|████▎     | 620/1449 [3:52:04<4:58:00, 21.57s/it] 43%|████▎     | 621/1449 [3:52:26<4:58:47, 21.65s/it]                                                      {'loss': 0.9051, 'grad_norm': 3.007188081741333, 'learning_rate': 1.314223664336448e-06, 'num_tokens': 3707024.0, 'mean_token_accuracy': 0.7260173223912716, 'epoch': 0.43}
 43%|████▎     | 621/1449 [3:52:26<4:58:47, 21.65s/it] 43%|████▎     | 622/1449 [3:52:47<4:57:53, 21.61s/it]                                                      {'loss': 0.9509, 'grad_norm': 3.7088303565979004, 'learning_rate': 1.312055356119118e-06, 'num_tokens': 3712955.0, 'mean_token_accuracy': 0.7053057439625263, 'epoch': 0.43}
 43%|████▎     | 622/1449 [3:52:47<4:57:53, 21.61s/it] 43%|████▎     | 623/1449 [3:53:09<4:57:26, 21.61s/it]                                                      {'loss': 1.0939, 'grad_norm': 3.068054676055908, 'learning_rate': 1.3098854212509916e-06, 'num_tokens': 3718972.0, 'mean_token_accuracy': 0.7002773582935333, 'epoch': 0.43}
 43%|████▎     | 623/1449 [3:53:09<4:57:26, 21.61s/it] 43%|████▎     | 624/1449 [3:53:30<4:56:42, 21.58s/it]                                                      {'loss': 0.8848, 'grad_norm': 3.4747443199157715, 'learning_rate': 1.3077138710432874e-06, 'num_tokens': 3726965.0, 'mean_token_accuracy': 0.7458681277930737, 'epoch': 0.43}
 43%|████▎     | 624/1449 [3:53:30<4:56:42, 21.58s/it] 43%|████▎     | 625/1449 [3:53:52<4:56:15, 21.57s/it]                                                      {'loss': 1.0193, 'grad_norm': 3.6352474689483643, 'learning_rate': 1.3055407168156435e-06, 'num_tokens': 3733096.0, 'mean_token_accuracy': 0.7216957248747349, 'epoch': 0.43}
 43%|████▎     | 625/1449 [3:53:52<4:56:15, 21.57s/it] 43%|████▎     | 626/1449 [3:54:14<4:56:55, 21.65s/it]                                                      {'loss': 1.2038, 'grad_norm': 3.366121530532837, 'learning_rate': 1.3033659698960607e-06, 'num_tokens': 3739404.0, 'mean_token_accuracy': 0.6802018284797668, 'epoch': 0.43}
 43%|████▎     | 626/1449 [3:54:14<4:56:55, 21.65s/it] 43%|████▎     | 627/1449 [3:54:35<4:55:02, 21.54s/it]                                                      {'loss': 1.0139, 'grad_norm': 3.5512454509735107, 'learning_rate': 1.3011896416208404e-06, 'num_tokens': 3745026.0, 'mean_token_accuracy': 0.7182857319712639, 'epoch': 0.43}
 43%|████▎     | 627/1449 [3:54:35<4:55:02, 21.54s/it] 43%|████▎     | 628/1449 [3:54:57<4:55:52, 21.62s/it]                                                      {'loss': 1.0196, 'grad_norm': 3.7676849365234375, 'learning_rate': 1.299011743334528e-06, 'num_tokens': 3750254.0, 'mean_token_accuracy': 0.7156527936458588, 'epoch': 0.43}
 43%|████▎     | 628/1449 [3:54:57<4:55:52, 21.62s/it] 43%|████▎     | 629/1449 [3:55:19<4:55:29, 21.62s/it]                                                      {'loss': 0.9136, 'grad_norm': 3.1757290363311768, 'learning_rate': 1.296832286389853e-06, 'num_tokens': 3756179.0, 'mean_token_accuracy': 0.7492721937596798, 'epoch': 0.43}
 43%|████▎     | 629/1449 [3:55:19<4:55:29, 21.62s/it] 43%|████▎     | 630/1449 [3:55:40<4:54:21, 21.56s/it]                                                      {'loss': 1.0268, 'grad_norm': 2.936065912246704, 'learning_rate': 1.2946512821476696e-06, 'num_tokens': 3762335.0, 'mean_token_accuracy': 0.7253443114459515, 'epoch': 0.43}
 43%|████▎     | 630/1449 [3:55:40<4:54:21, 21.56s/it] 44%|████▎     | 631/1449 [3:56:02<4:55:03, 21.64s/it]                                                      {'loss': 0.9978, 'grad_norm': 3.7291336059570312, 'learning_rate': 1.2924687419768974e-06, 'num_tokens': 3768601.0, 'mean_token_accuracy': 0.7199807055294514, 'epoch': 0.44}
 44%|████▎     | 631/1449 [3:56:02<4:55:03, 21.64s/it] 44%|████▎     | 632/1449 [3:56:23<4:54:24, 21.62s/it]                                                      {'loss': 1.0648, 'grad_norm': 3.2486350536346436, 'learning_rate': 1.2902846772544622e-06, 'num_tokens': 3775528.0, 'mean_token_accuracy': 0.7072763964533806, 'epoch': 0.44}
 44%|████▎     | 632/1449 [3:56:23<4:54:24, 21.62s/it] 44%|████▎     | 633/1449 [3:56:45<4:54:11, 21.63s/it]                                                      {'loss': 1.1018, 'grad_norm': 3.362133741378784, 'learning_rate': 1.2880990993652377e-06, 'num_tokens': 3781865.0, 'mean_token_accuracy': 0.6947007589042187, 'epoch': 0.44}
 44%|████▎     | 633/1449 [3:56:45<4:54:11, 21.63s/it] 44%|████▍     | 634/1449 [3:57:07<4:53:56, 21.64s/it]                                                      {'loss': 1.0198, 'grad_norm': 3.4451944828033447, 'learning_rate': 1.2859120197019838e-06, 'num_tokens': 3787766.0, 'mean_token_accuracy': 0.7086914665997028, 'epoch': 0.44}
 44%|████▍     | 634/1449 [3:57:07<4:53:56, 21.64s/it] 44%|████▍     | 635/1449 [3:57:28<4:53:17, 21.62s/it]                                                      {'loss': 1.1482, 'grad_norm': 4.114511489868164, 'learning_rate': 1.28372344966529e-06, 'num_tokens': 3792645.0, 'mean_token_accuracy': 0.7005096897482872, 'epoch': 0.44}
 44%|████▍     | 635/1449 [3:57:28<4:53:17, 21.62s/it] 44%|████▍     | 636/1449 [3:57:50<4:53:11, 21.64s/it]                                                      {'loss': 1.0936, 'grad_norm': 3.2808220386505127, 'learning_rate': 1.2815334006635143e-06, 'num_tokens': 3799179.0, 'mean_token_accuracy': 0.7079944983124733, 'epoch': 0.44}
 44%|████▍     | 636/1449 [3:57:50<4:53:11, 21.64s/it] 44%|████▍     | 637/1449 [3:58:11<4:51:48, 21.56s/it]                                                      {'loss': 1.1342, 'grad_norm': 3.0585179328918457, 'learning_rate': 1.2793418841127239e-06, 'num_tokens': 3805950.0, 'mean_token_accuracy': 0.7028938457369804, 'epoch': 0.44}
 44%|████▍     | 637/1449 [3:58:11<4:51:48, 21.56s/it] 44%|████▍     | 638/1449 [3:58:33<4:52:30, 21.64s/it]                                                      {'loss': 1.0507, 'grad_norm': 3.580700159072876, 'learning_rate': 1.277148911436636e-06, 'num_tokens': 3811642.0, 'mean_token_accuracy': 0.7096839584410191, 'epoch': 0.44}
 44%|████▍     | 638/1449 [3:58:33<4:52:30, 21.64s/it] 44%|████▍     | 639/1449 [3:58:55<4:51:39, 21.60s/it]                                                      {'loss': 1.1504, 'grad_norm': 3.4555540084838867, 'learning_rate': 1.2749544940665583e-06, 'num_tokens': 3817070.0, 'mean_token_accuracy': 0.6785290651023388, 'epoch': 0.44}
 44%|████▍     | 639/1449 [3:58:55<4:51:39, 21.60s/it] 44%|████▍     | 640/1449 [3:59:17<4:52:20, 21.68s/it]                                                      {'loss': 1.0472, 'grad_norm': 3.468562126159668, 'learning_rate': 1.2727586434413289e-06, 'num_tokens': 3822375.0, 'mean_token_accuracy': 0.6913285553455353, 'epoch': 0.44}
 44%|████▍     | 640/1449 [3:59:17<4:52:20, 21.68s/it] 44%|████▍     | 641/1449 [3:59:38<4:52:37, 21.73s/it]                                                      {'loss': 1.0771, 'grad_norm': 3.577301263809204, 'learning_rate': 1.2705613710072573e-06, 'num_tokens': 3828210.0, 'mean_token_accuracy': 0.7022040262818336, 'epoch': 0.44}
 44%|████▍     | 641/1449 [3:59:38<4:52:37, 21.73s/it] 44%|████▍     | 642/1449 [4:00:00<4:50:26, 21.59s/it]                                                      {'loss': 0.9311, 'grad_norm': 3.371553897857666, 'learning_rate': 1.2683626882180644e-06, 'num_tokens': 3835586.0, 'mean_token_accuracy': 0.7419980391860008, 'epoch': 0.44}
 44%|████▍     | 642/1449 [4:00:00<4:50:26, 21.59s/it] 44%|████▍     | 643/1449 [4:00:21<4:50:45, 21.64s/it]                                                      {'loss': 1.0552, 'grad_norm': 3.292428493499756, 'learning_rate': 1.2661626065348229e-06, 'num_tokens': 3841596.0, 'mean_token_accuracy': 0.7176671214401722, 'epoch': 0.44}
 44%|████▍     | 643/1449 [4:00:21<4:50:45, 21.64s/it] 44%|████▍     | 644/1449 [4:00:43<4:49:42, 21.59s/it]                                                      {'loss': 0.9565, 'grad_norm': 3.7530105113983154, 'learning_rate': 1.2639611374258975e-06, 'num_tokens': 3847300.0, 'mean_token_accuracy': 0.7339607626199722, 'epoch': 0.44}
 44%|████▍     | 644/1449 [4:00:43<4:49:42, 21.59s/it] 45%|████▍     | 645/1449 [4:01:04<4:49:21, 21.59s/it]                                                      {'loss': 1.0235, 'grad_norm': 3.2081961631774902, 'learning_rate': 1.2617582923668852e-06, 'num_tokens': 3853781.0, 'mean_token_accuracy': 0.7232729718089104, 'epoch': 0.44}
 45%|████▍     | 645/1449 [4:01:04<4:49:21, 21.59s/it] 45%|████▍     | 646/1449 [4:01:26<4:49:57, 21.67s/it]                                                      {'loss': 1.1015, 'grad_norm': 3.4282658100128174, 'learning_rate': 1.2595540828405553e-06, 'num_tokens': 3860240.0, 'mean_token_accuracy': 0.7099135555326939, 'epoch': 0.45}
 45%|████▍     | 646/1449 [4:01:26<4:49:57, 21.67s/it] 45%|████▍     | 647/1449 [4:01:48<4:48:08, 21.56s/it]                                                      {'loss': 1.0582, 'grad_norm': 4.012270927429199, 'learning_rate': 1.2573485203367892e-06, 'num_tokens': 3866069.0, 'mean_token_accuracy': 0.7065008394420147, 'epoch': 0.45}
 45%|████▍     | 647/1449 [4:01:48<4:48:08, 21.56s/it] 45%|████▍     | 648/1449 [4:02:10<4:49:13, 21.66s/it]                                                      {'loss': 1.0408, 'grad_norm': 4.10699987411499, 'learning_rate': 1.2551416163525218e-06, 'num_tokens': 3871328.0, 'mean_token_accuracy': 0.7010711692273617, 'epoch': 0.45}
 45%|████▍     | 648/1449 [4:02:10<4:49:13, 21.66s/it] 45%|████▍     | 649/1449 [4:02:31<4:49:21, 21.70s/it]                                                      {'loss': 1.2096, 'grad_norm': 3.7493109703063965, 'learning_rate': 1.2529333823916806e-06, 'num_tokens': 3876617.0, 'mean_token_accuracy': 0.6655984409153461, 'epoch': 0.45}
 45%|████▍     | 649/1449 [4:02:31<4:49:21, 21.70s/it] 45%|████▍     | 650/1449 [4:02:53<4:48:35, 21.67s/it]                                                      {'loss': 1.0696, 'grad_norm': 3.5090343952178955, 'learning_rate': 1.2507238299651253e-06, 'num_tokens': 3882266.0, 'mean_token_accuracy': 0.7013296782970428, 'epoch': 0.45}
 45%|████▍     | 650/1449 [4:02:53<4:48:35, 21.67s/it][INFO|trainer.py:3966] 2025-06-06 04:12:19,391 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650
[INFO|configuration_utils.py:423] 2025-06-06 04:12:19,397 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/config.json
[INFO|configuration_utils.py:908] 2025-06-06 04:12:19,399 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 04:12:26,595 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 04:12:26,599 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 04:12:26,601 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/special_tokens_map.json
[2025-06-06 04:12:26,807] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step650 is about to be saved!
[2025-06-06 04:12:26,813] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/global_step650/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 04:12:26,813] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/global_step650/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 04:12:26,828] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/global_step650/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 04:12:26,829] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/global_step650/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 04:12:48,559] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/global_step650/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 04:12:48,568] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-650/global_step650/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 04:12:48,901] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step650 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 04:13:00,177 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 04:13:00,180 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 45%|████▍     | 651/1449 [4:03:57<7:37:52, 34.43s/it]                                                      {'loss': 1.0399, 'grad_norm': 3.605762243270874, 'learning_rate': 1.248512970590589e-06, 'num_tokens': 3888320.0, 'mean_token_accuracy': 0.7136507779359818, 'epoch': 0.45}
 45%|████▍     | 651/1449 [4:03:57<7:37:52, 34.43s/it] 45%|████▍     | 652/1449 [4:04:19<6:48:07, 30.72s/it]                                                      {'loss': 0.8825, 'grad_norm': 3.295445203781128, 'learning_rate': 1.2463008157926171e-06, 'num_tokens': 3895397.0, 'mean_token_accuracy': 0.7407153844833374, 'epoch': 0.45}
 45%|████▍     | 652/1449 [4:04:19<6:48:07, 30.72s/it] 45%|████▌     | 653/1449 [4:04:41<6:12:41, 28.09s/it]                                                      {'loss': 1.1748, 'grad_norm': 3.719660520553589, 'learning_rate': 1.2440873771025079e-06, 'num_tokens': 3901414.0, 'mean_token_accuracy': 0.6884703449904919, 'epoch': 0.45}
 45%|████▌     | 653/1449 [4:04:41<6:12:41, 28.09s/it] 45%|████▌     | 654/1449 [4:05:03<5:46:45, 26.17s/it]                                                      {'loss': 1.0872, 'grad_norm': 3.495384693145752, 'learning_rate': 1.241872666058252e-06, 'num_tokens': 3907780.0, 'mean_token_accuracy': 0.6905135959386826, 'epoch': 0.45}
 45%|████▌     | 654/1449 [4:05:03<5:46:45, 26.17s/it] 45%|████▌     | 655/1449 [4:05:25<5:29:13, 24.88s/it]                                                      {'loss': 0.9878, 'grad_norm': 3.2961924076080322, 'learning_rate': 1.2396566942044723e-06, 'num_tokens': 3914389.0, 'mean_token_accuracy': 0.7246505059301853, 'epoch': 0.45}
 45%|████▌     | 655/1449 [4:05:25<5:29:13, 24.88s/it] 45%|████▌     | 656/1449 [4:05:46<5:16:07, 23.92s/it]                                                      {'loss': 1.1004, 'grad_norm': 3.5015203952789307, 'learning_rate': 1.2374394730923642e-06, 'num_tokens': 3919496.0, 'mean_token_accuracy': 0.7034605145454407, 'epoch': 0.45}
 45%|████▌     | 656/1449 [4:05:46<5:16:07, 23.92s/it] 45%|████▌     | 657/1449 [4:06:08<5:08:26, 23.37s/it]                                                      {'loss': 1.1372, 'grad_norm': 3.3705904483795166, 'learning_rate': 1.2352210142796357e-06, 'num_tokens': 3925655.0, 'mean_token_accuracy': 0.7010515667498112, 'epoch': 0.45}
 45%|████▌     | 657/1449 [4:06:08<5:08:26, 23.37s/it] 45%|████▌     | 658/1449 [4:06:30<5:00:19, 22.78s/it]                                                      {'loss': 1.0612, 'grad_norm': 3.3995461463928223, 'learning_rate': 1.2330013293304453e-06, 'num_tokens': 3931513.0, 'mean_token_accuracy': 0.7132957577705383, 'epoch': 0.45}
 45%|████▌     | 658/1449 [4:06:30<5:00:19, 22.78s/it] 45%|████▌     | 659/1449 [4:06:52<4:56:27, 22.52s/it]                                                      {'loss': 1.0682, 'grad_norm': 3.6315524578094482, 'learning_rate': 1.230780429815344e-06, 'num_tokens': 3936871.0, 'mean_token_accuracy': 0.7008539997041225, 'epoch': 0.45}
 45%|████▌     | 659/1449 [4:06:52<4:56:27, 22.52s/it] 46%|████▌     | 660/1449 [4:07:13<4:52:39, 22.26s/it]                                                      {'loss': 1.0782, 'grad_norm': 3.4258787631988525, 'learning_rate': 1.2285583273112131e-06, 'num_tokens': 3942910.0, 'mean_token_accuracy': 0.7060146629810333, 'epoch': 0.46}
 46%|████▌     | 660/1449 [4:07:13<4:52:39, 22.26s/it] 46%|████▌     | 661/1449 [4:07:35<4:50:36, 22.13s/it]                                                      {'loss': 1.1599, 'grad_norm': 3.714540481567383, 'learning_rate': 1.2263350334012058e-06, 'num_tokens': 3949059.0, 'mean_token_accuracy': 0.6791177876293659, 'epoch': 0.46}
 46%|████▌     | 661/1449 [4:07:35<4:50:36, 22.13s/it] 46%|████▌     | 662/1449 [4:07:57<4:49:05, 22.04s/it]                                                      {'loss': 1.1213, 'grad_norm': 3.504626989364624, 'learning_rate': 1.2241105596746845e-06, 'num_tokens': 3954546.0, 'mean_token_accuracy': 0.6854545213282108, 'epoch': 0.46}
 46%|████▌     | 662/1449 [4:07:57<4:49:05, 22.04s/it] 46%|████▌     | 663/1449 [4:08:19<4:47:53, 21.98s/it]                                                      {'loss': 1.0649, 'grad_norm': 3.1959280967712402, 'learning_rate': 1.2218849177271627e-06, 'num_tokens': 3960991.0, 'mean_token_accuracy': 0.7102869562804699, 'epoch': 0.46}
 46%|████▌     | 663/1449 [4:08:19<4:47:53, 21.98s/it] 46%|████▌     | 664/1449 [4:08:41<4:46:44, 21.92s/it]                                                      {'loss': 1.0876, 'grad_norm': 3.715667724609375, 'learning_rate': 1.219658119160243e-06, 'num_tokens': 3966679.0, 'mean_token_accuracy': 0.7055552862584591, 'epoch': 0.46}
 46%|████▌     | 664/1449 [4:08:41<4:46:44, 21.92s/it] 46%|████▌     | 665/1449 [4:09:02<4:45:07, 21.82s/it]                                                      {'loss': 1.1219, 'grad_norm': 3.3417227268218994, 'learning_rate': 1.217430175581557e-06, 'num_tokens': 3972152.0, 'mean_token_accuracy': 0.7061965130269527, 'epoch': 0.46}
 46%|████▌     | 665/1449 [4:09:02<4:45:07, 21.82s/it] 46%|████▌     | 666/1449 [4:09:24<4:45:43, 21.89s/it]                                                      {'loss': 1.0087, 'grad_norm': 3.7678301334381104, 'learning_rate': 1.2152010986047053e-06, 'num_tokens': 3977893.0, 'mean_token_accuracy': 0.7107677347958088, 'epoch': 0.46}
 46%|████▌     | 666/1449 [4:09:24<4:45:43, 21.89s/it] 46%|████▌     | 667/1449 [4:09:46<4:44:21, 21.82s/it]                                                      {'loss': 1.0701, 'grad_norm': 3.4938087463378906, 'learning_rate': 1.212970899849196e-06, 'num_tokens': 3983904.0, 'mean_token_accuracy': 0.7035057730972767, 'epoch': 0.46}
 46%|████▌     | 667/1449 [4:09:46<4:44:21, 21.82s/it] 46%|████▌     | 668/1449 [4:10:08<4:43:59, 21.82s/it]                                                      {'loss': 1.0812, 'grad_norm': 3.673920154571533, 'learning_rate': 1.2107395909403852e-06, 'num_tokens': 3990044.0, 'mean_token_accuracy': 0.7014088444411755, 'epoch': 0.46}
 46%|████▌     | 668/1449 [4:10:08<4:43:59, 21.82s/it] 46%|████▌     | 669/1449 [4:10:30<4:43:37, 21.82s/it]                                                      {'loss': 1.0406, 'grad_norm': 3.2243478298187256, 'learning_rate': 1.2085071835094158e-06, 'num_tokens': 3995951.0, 'mean_token_accuracy': 0.704752366989851, 'epoch': 0.46}
 46%|████▌     | 669/1449 [4:10:30<4:43:37, 21.82s/it] 46%|████▌     | 670/1449 [4:10:51<4:42:23, 21.75s/it]                                                      {'loss': 1.1141, 'grad_norm': 2.8130011558532715, 'learning_rate': 1.2062736891931567e-06, 'num_tokens': 4003635.0, 'mean_token_accuracy': 0.7182301692664623, 'epoch': 0.46}
 46%|████▌     | 670/1449 [4:10:51<4:42:23, 21.75s/it] 46%|████▋     | 671/1449 [4:11:13<4:42:15, 21.77s/it]                                                      {'loss': 1.0928, 'grad_norm': 3.600126028060913, 'learning_rate': 1.2040391196341426e-06, 'num_tokens': 4009064.0, 'mean_token_accuracy': 0.6968697942793369, 'epoch': 0.46}
 46%|████▋     | 671/1449 [4:11:13<4:42:15, 21.77s/it] 46%|████▋     | 672/1449 [4:11:35<4:41:49, 21.76s/it]                                                      {'loss': 0.9878, 'grad_norm': 3.478231906890869, 'learning_rate': 1.2018034864805136e-06, 'num_tokens': 4015394.0, 'mean_token_accuracy': 0.7155735641717911, 'epoch': 0.46}
 46%|████▋     | 672/1449 [4:11:35<4:41:49, 21.76s/it] 46%|████▋     | 673/1449 [4:11:56<4:40:56, 21.72s/it]                                                      {'loss': 1.0405, 'grad_norm': 3.7884914875030518, 'learning_rate': 1.1995668013859528e-06, 'num_tokens': 4021116.0, 'mean_token_accuracy': 0.7064933069050312, 'epoch': 0.46}
 46%|████▋     | 673/1449 [4:11:56<4:40:56, 21.72s/it] 47%|████▋     | 674/1449 [4:12:18<4:41:36, 21.80s/it]                                                      {'loss': 0.9389, 'grad_norm': 3.4872779846191406, 'learning_rate': 1.1973290760096278e-06, 'num_tokens': 4026880.0, 'mean_token_accuracy': 0.7330713048577309, 'epoch': 0.46}
 47%|████▋     | 674/1449 [4:12:18<4:41:36, 21.80s/it] 47%|████▋     | 675/1449 [4:12:40<4:39:43, 21.68s/it]                                                      {'loss': 1.0409, 'grad_norm': 4.362945556640625, 'learning_rate': 1.1950903220161284e-06, 'num_tokens': 4032415.0, 'mean_token_accuracy': 0.7071606367826462, 'epoch': 0.47}
 47%|████▋     | 675/1449 [4:12:40<4:39:43, 21.68s/it] 47%|████▋     | 676/1449 [4:13:02<4:39:53, 21.73s/it]                                                      {'loss': 1.0806, 'grad_norm': 3.6062862873077393, 'learning_rate': 1.1928505510754064e-06, 'num_tokens': 4037872.0, 'mean_token_accuracy': 0.6892959475517273, 'epoch': 0.47}
 47%|████▋     | 676/1449 [4:13:02<4:39:53, 21.73s/it] 47%|████▋     | 677/1449 [4:13:23<4:39:57, 21.76s/it]                                                      {'loss': 0.9095, 'grad_norm': 3.867539882659912, 'learning_rate': 1.1906097748627149e-06, 'num_tokens': 4043904.0, 'mean_token_accuracy': 0.7190549485385418, 'epoch': 0.47}
 47%|████▋     | 677/1449 [4:13:23<4:39:57, 21.76s/it] 47%|████▋     | 678/1449 [4:13:45<4:38:43, 21.69s/it]                                                      {'loss': 1.0621, 'grad_norm': 3.2714576721191406, 'learning_rate': 1.1883680050585465e-06, 'num_tokens': 4049833.0, 'mean_token_accuracy': 0.7015840448439121, 'epoch': 0.47}
 47%|████▋     | 678/1449 [4:13:45<4:38:43, 21.69s/it] 47%|████▋     | 679/1449 [4:14:07<4:39:44, 21.80s/it]                                                      {'loss': 0.981, 'grad_norm': 3.3275303840637207, 'learning_rate': 1.1861252533485742e-06, 'num_tokens': 4055381.0, 'mean_token_accuracy': 0.7155700623989105, 'epoch': 0.47}
 47%|████▋     | 679/1449 [4:14:07<4:39:44, 21.80s/it] 47%|████▋     | 680/1449 [4:14:29<4:38:51, 21.76s/it]                                                      {'loss': 1.0376, 'grad_norm': 3.485396146774292, 'learning_rate': 1.183881531423588e-06, 'num_tokens': 4061104.0, 'mean_token_accuracy': 0.7207388393580914, 'epoch': 0.47}
 47%|████▋     | 680/1449 [4:14:29<4:38:51, 21.76s/it] 47%|████▋     | 681/1449 [4:14:50<4:38:32, 21.76s/it]                                                      {'loss': 1.0489, 'grad_norm': 3.2761752605438232, 'learning_rate': 1.1816368509794364e-06, 'num_tokens': 4066738.0, 'mean_token_accuracy': 0.7107137925922871, 'epoch': 0.47}
 47%|████▋     | 681/1449 [4:14:50<4:38:32, 21.76s/it] 47%|████▋     | 682/1449 [4:15:12<4:38:09, 21.76s/it]                                                      {'loss': 1.0569, 'grad_norm': 3.519418478012085, 'learning_rate': 1.179391223716964e-06, 'num_tokens': 4072745.0, 'mean_token_accuracy': 0.7109123133122921, 'epoch': 0.47}
 47%|████▋     | 682/1449 [4:15:12<4:38:09, 21.76s/it] 47%|████▋     | 683/1449 [4:15:34<4:37:17, 21.72s/it]                                                      {'loss': 1.0511, 'grad_norm': 3.5828299522399902, 'learning_rate': 1.1771446613419506e-06, 'num_tokens': 4078539.0, 'mean_token_accuracy': 0.7072498425841331, 'epoch': 0.47}
 47%|████▋     | 683/1449 [4:15:34<4:37:17, 21.72s/it] 47%|████▋     | 684/1449 [4:15:55<4:36:06, 21.66s/it]                                                      {'loss': 0.9704, 'grad_norm': 2.7837390899658203, 'learning_rate': 1.174897175565051e-06, 'num_tokens': 4085740.0, 'mean_token_accuracy': 0.7255343310534954, 'epoch': 0.47}
 47%|████▋     | 684/1449 [4:15:55<4:36:06, 21.66s/it] 47%|████▋     | 685/1449 [4:16:17<4:35:59, 21.67s/it]                                                      {'loss': 0.9549, 'grad_norm': 3.6352198123931885, 'learning_rate': 1.1726487781017337e-06, 'num_tokens': 4090828.0, 'mean_token_accuracy': 0.7361651808023453, 'epoch': 0.47}
 47%|████▋     | 685/1449 [4:16:17<4:35:59, 21.67s/it] 47%|████▋     | 686/1449 [4:16:39<4:35:07, 21.63s/it]                                                      {'loss': 1.0928, 'grad_norm': 3.247246026992798, 'learning_rate': 1.1703994806722177e-06, 'num_tokens': 4097634.0, 'mean_token_accuracy': 0.7133371792733669, 'epoch': 0.47}
 47%|████▋     | 686/1449 [4:16:39<4:35:07, 21.63s/it] 47%|████▋     | 687/1449 [4:17:01<4:36:56, 21.81s/it]                                                      {'loss': 1.1255, 'grad_norm': 3.499157667160034, 'learning_rate': 1.1681492950014155e-06, 'num_tokens': 4103978.0, 'mean_token_accuracy': 0.6873192526400089, 'epoch': 0.47}
 47%|████▋     | 687/1449 [4:17:01<4:36:56, 21.81s/it] 47%|████▋     | 688/1449 [4:17:23<4:37:13, 21.86s/it]                                                      {'loss': 1.0324, 'grad_norm': 3.327543020248413, 'learning_rate': 1.165898232818869e-06, 'num_tokens': 4109210.0, 'mean_token_accuracy': 0.7051907554268837, 'epoch': 0.47}
 47%|████▋     | 688/1449 [4:17:23<4:37:13, 21.86s/it] 48%|████▊     | 689/1449 [4:17:45<4:37:35, 21.92s/it]                                                      {'loss': 1.0808, 'grad_norm': 3.6525063514709473, 'learning_rate': 1.163646305858688e-06, 'num_tokens': 4114817.0, 'mean_token_accuracy': 0.7085751816630363, 'epoch': 0.48}
 48%|████▊     | 689/1449 [4:17:45<4:37:35, 21.92s/it] 48%|████▊     | 690/1449 [4:18:06<4:34:44, 21.72s/it]                                                      {'loss': 1.0919, 'grad_norm': 3.844421863555908, 'learning_rate': 1.1613935258594919e-06, 'num_tokens': 4120233.0, 'mean_token_accuracy': 0.69905935972929, 'epoch': 0.48}
 48%|████▊     | 690/1449 [4:18:06<4:34:44, 21.72s/it] 48%|████▊     | 691/1449 [4:18:28<4:34:00, 21.69s/it]                                                      {'loss': 0.8773, 'grad_norm': 3.0954363346099854, 'learning_rate': 1.1591399045643454e-06, 'num_tokens': 4126460.0, 'mean_token_accuracy': 0.741695262491703, 'epoch': 0.48}
 48%|████▊     | 691/1449 [4:18:28<4:34:00, 21.69s/it] 48%|████▊     | 692/1449 [4:18:49<4:32:03, 21.56s/it]                                                      {'loss': 1.1191, 'grad_norm': 3.3860509395599365, 'learning_rate': 1.1568854537206994e-06, 'num_tokens': 4132166.0, 'mean_token_accuracy': 0.6975858248770237, 'epoch': 0.48}
 48%|████▊     | 692/1449 [4:18:49<4:32:03, 21.56s/it] 48%|████▊     | 693/1449 [4:19:10<4:31:16, 21.53s/it]                                                      {'loss': 1.0585, 'grad_norm': 3.5282833576202393, 'learning_rate': 1.1546301850803282e-06, 'num_tokens': 4138121.0, 'mean_token_accuracy': 0.7153918333351612, 'epoch': 0.48}
 48%|████▊     | 693/1449 [4:19:10<4:31:16, 21.53s/it] 48%|████▊     | 694/1449 [4:19:32<4:31:16, 21.56s/it]                                                      {'loss': 1.0269, 'grad_norm': 3.712891101837158, 'learning_rate': 1.1523741103992696e-06, 'num_tokens': 4143896.0, 'mean_token_accuracy': 0.7225178182125092, 'epoch': 0.48}
 48%|████▊     | 694/1449 [4:19:32<4:31:16, 21.56s/it] 48%|████▊     | 695/1449 [4:19:53<4:29:46, 21.47s/it]                                                      {'loss': 1.0883, 'grad_norm': 3.733150005340576, 'learning_rate': 1.1501172414377633e-06, 'num_tokens': 4149434.0, 'mean_token_accuracy': 0.7104724012315273, 'epoch': 0.48}
 48%|████▊     | 695/1449 [4:19:53<4:29:46, 21.47s/it] 48%|████▊     | 696/1449 [4:20:15<4:29:57, 21.51s/it]                                                      {'loss': 0.9406, 'grad_norm': 3.4179601669311523, 'learning_rate': 1.1478595899601888e-06, 'num_tokens': 4156317.0, 'mean_token_accuracy': 0.7385750263929367, 'epoch': 0.48}
 48%|████▊     | 696/1449 [4:20:15<4:29:57, 21.51s/it] 48%|████▊     | 697/1449 [4:20:36<4:28:39, 21.44s/it]                                                      {'loss': 0.9901, 'grad_norm': 3.394794225692749, 'learning_rate': 1.145601167735005e-06, 'num_tokens': 4162750.0, 'mean_token_accuracy': 0.7119689770042896, 'epoch': 0.48}
 48%|████▊     | 697/1449 [4:20:36<4:28:39, 21.44s/it] 48%|████▊     | 698/1449 [4:20:58<4:28:57, 21.49s/it]                                                      {'loss': 1.0603, 'grad_norm': 3.7190277576446533, 'learning_rate': 1.1433419865346876e-06, 'num_tokens': 4168482.0, 'mean_token_accuracy': 0.7119233645498753, 'epoch': 0.48}
 48%|████▊     | 698/1449 [4:20:58<4:28:57, 21.49s/it] 48%|████▊     | 699/1449 [4:21:19<4:28:29, 21.48s/it]                                                      {'loss': 0.8881, 'grad_norm': 3.0950005054473877, 'learning_rate': 1.1410820581356704e-06, 'num_tokens': 4174378.0, 'mean_token_accuracy': 0.7401897460222244, 'epoch': 0.48}
 48%|████▊     | 699/1449 [4:21:19<4:28:29, 21.48s/it] 48%|████▊     | 700/1449 [4:21:41<4:27:57, 21.47s/it]                                                      {'loss': 1.1257, 'grad_norm': 3.9687376022338867, 'learning_rate': 1.13882139431828e-06, 'num_tokens': 4180086.0, 'mean_token_accuracy': 0.705130722373724, 'epoch': 0.48}
 48%|████▊     | 700/1449 [4:21:41<4:27:57, 21.47s/it][INFO|trainer.py:3966] 2025-06-06 04:31:07,223 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700
[INFO|configuration_utils.py:423] 2025-06-06 04:31:07,229 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/config.json
[INFO|configuration_utils.py:908] 2025-06-06 04:31:07,231 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 04:31:13,993 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 04:31:13,996 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 04:31:13,998 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/special_tokens_map.json
[2025-06-06 04:31:14,199] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step700 is about to be saved!
[2025-06-06 04:31:14,205] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/global_step700/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 04:31:14,206] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/global_step700/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 04:31:14,220] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/global_step700/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 04:31:14,221] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/global_step700/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 04:31:35,572] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/global_step700/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 04:31:35,577] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-700/global_step700/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 04:31:35,607] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step700 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 04:31:46,319 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 04:31:46,321 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 48%|████▊     | 701/1449 [4:22:43<7:01:59, 33.85s/it]                                                      {'loss': 1.0825, 'grad_norm': 4.053781509399414, 'learning_rate': 1.1365600068666778e-06, 'num_tokens': 4185628.0, 'mean_token_accuracy': 0.6994335912168026, 'epoch': 0.48}
 48%|████▊     | 701/1449 [4:22:43<7:01:59, 33.85s/it] 48%|████▊     | 702/1449 [4:23:05<6:16:34, 30.25s/it]                                                      {'loss': 0.8495, 'grad_norm': 2.8781206607818604, 'learning_rate': 1.1342979075687973e-06, 'num_tokens': 4192493.0, 'mean_token_accuracy': 0.7539895996451378, 'epoch': 0.48}
 48%|████▊     | 702/1449 [4:23:05<6:16:34, 30.25s/it] 49%|████▊     | 703/1449 [4:23:27<5:44:09, 27.68s/it]                                                      {'loss': 0.9865, 'grad_norm': 4.022517681121826, 'learning_rate': 1.132035108216282e-06, 'num_tokens': 4198814.0, 'mean_token_accuracy': 0.7168441079556942, 'epoch': 0.48}
 49%|████▊     | 703/1449 [4:23:27<5:44:09, 27.68s/it] 49%|████▊     | 704/1449 [4:23:49<5:20:53, 25.84s/it]                                                      {'loss': 1.0567, 'grad_norm': 3.527125358581543, 'learning_rate': 1.1297716206044255e-06, 'num_tokens': 4204772.0, 'mean_token_accuracy': 0.71452946215868, 'epoch': 0.49}
 49%|████▊     | 704/1449 [4:23:49<5:20:53, 25.84s/it] 49%|████▊     | 705/1449 [4:24:10<5:03:51, 24.50s/it]                                                      {'loss': 0.9116, 'grad_norm': 3.2278590202331543, 'learning_rate': 1.127507456532108e-06, 'num_tokens': 4211789.0, 'mean_token_accuracy': 0.7386180870234966, 'epoch': 0.49}
 49%|████▊     | 705/1449 [4:24:10<5:03:51, 24.50s/it] 49%|████▊     | 706/1449 [4:24:32<4:52:50, 23.65s/it]                                                      {'loss': 0.9426, 'grad_norm': 3.4600958824157715, 'learning_rate': 1.1252426278017366e-06, 'num_tokens': 4218404.0, 'mean_token_accuracy': 0.7082680463790894, 'epoch': 0.49}
 49%|████▊     | 706/1449 [4:24:32<4:52:50, 23.65s/it] 49%|████▉     | 707/1449 [4:24:53<4:44:06, 22.97s/it]                                                      {'loss': 1.0445, 'grad_norm': 3.870391845703125, 'learning_rate': 1.1229771462191829e-06, 'num_tokens': 4223901.0, 'mean_token_accuracy': 0.7135654948651791, 'epoch': 0.49}
 49%|████▉     | 707/1449 [4:24:53<4:44:06, 22.97s/it] 49%|████▉     | 708/1449 [4:25:15<4:38:58, 22.59s/it]                                                      {'loss': 0.996, 'grad_norm': 3.387280225753784, 'learning_rate': 1.1207110235937214e-06, 'num_tokens': 4230415.0, 'mean_token_accuracy': 0.7227435186505318, 'epoch': 0.49}
 49%|████▉     | 708/1449 [4:25:15<4:38:58, 22.59s/it] 49%|████▉     | 709/1449 [4:25:36<4:33:42, 22.19s/it]                                                      {'loss': 1.1892, 'grad_norm': 3.9762346744537354, 'learning_rate': 1.1184442717379685e-06, 'num_tokens': 4236383.0, 'mean_token_accuracy': 0.6867336370050907, 'epoch': 0.49}
 49%|████▉     | 709/1449 [4:25:36<4:33:42, 22.19s/it] 49%|████▉     | 710/1449 [4:25:58<4:31:08, 22.01s/it]                                                      {'loss': 0.9166, 'grad_norm': 3.2397847175598145, 'learning_rate': 1.1161769024678204e-06, 'num_tokens': 4242096.0, 'mean_token_accuracy': 0.7271782904863358, 'epoch': 0.49}
 49%|████▉     | 710/1449 [4:25:58<4:31:08, 22.01s/it] 49%|████▉     | 711/1449 [4:26:19<4:28:19, 21.81s/it]                                                      {'loss': 1.1038, 'grad_norm': 3.1148369312286377, 'learning_rate': 1.1139089276023918e-06, 'num_tokens': 4249176.0, 'mean_token_accuracy': 0.692519273608923, 'epoch': 0.49}
 49%|████▉     | 711/1449 [4:26:19<4:28:19, 21.81s/it] 49%|████▉     | 712/1449 [4:26:40<4:27:12, 21.75s/it]                                                      {'loss': 1.1311, 'grad_norm': 3.4611635208129883, 'learning_rate': 1.1116403589639546e-06, 'num_tokens': 4255067.0, 'mean_token_accuracy': 0.706825390458107, 'epoch': 0.49}
 49%|████▉     | 712/1449 [4:26:40<4:27:12, 21.75s/it] 49%|████▉     | 713/1449 [4:27:02<4:25:28, 21.64s/it]                                                      {'loss': 0.9368, 'grad_norm': 3.0883750915527344, 'learning_rate': 1.1093712083778746e-06, 'num_tokens': 4261896.0, 'mean_token_accuracy': 0.7431870475411415, 'epoch': 0.49}
 49%|████▉     | 713/1449 [4:27:02<4:25:28, 21.64s/it] 49%|████▉     | 714/1449 [4:27:23<4:25:01, 21.64s/it]                                                      {'loss': 1.0344, 'grad_norm': 3.5532546043395996, 'learning_rate': 1.107101487672552e-06, 'num_tokens': 4267357.0, 'mean_token_accuracy': 0.7225172072649002, 'epoch': 0.49}
 49%|████▉     | 714/1449 [4:27:23<4:25:01, 21.64s/it] 49%|████▉     | 715/1449 [4:27:45<4:23:56, 21.58s/it]                                                      {'loss': 0.9971, 'grad_norm': 3.4028007984161377, 'learning_rate': 1.1048312086793593e-06, 'num_tokens': 4273198.0, 'mean_token_accuracy': 0.7176928445696831, 'epoch': 0.49}
 49%|████▉     | 715/1449 [4:27:45<4:23:56, 21.58s/it] 49%|████▉     | 716/1449 [4:28:06<4:23:26, 21.56s/it]                                                      {'loss': 1.02, 'grad_norm': 3.561411142349243, 'learning_rate': 1.102560383232578e-06, 'num_tokens': 4279328.0, 'mean_token_accuracy': 0.7251664102077484, 'epoch': 0.49}
 49%|████▉     | 716/1449 [4:28:06<4:23:26, 21.56s/it] 49%|████▉     | 717/1449 [4:28:28<4:22:58, 21.56s/it]                                                      {'loss': 1.0299, 'grad_norm': 3.229811191558838, 'learning_rate': 1.1002890231693394e-06, 'num_tokens': 4285322.0, 'mean_token_accuracy': 0.7074423618614674, 'epoch': 0.49}
 49%|████▉     | 717/1449 [4:28:28<4:22:58, 21.56s/it] 50%|████▉     | 718/1449 [4:28:49<4:22:16, 21.53s/it]                                                      {'loss': 1.03, 'grad_norm': 3.6088385581970215, 'learning_rate': 1.0980171403295609e-06, 'num_tokens': 4290908.0, 'mean_token_accuracy': 0.7001565136015415, 'epoch': 0.5}
 50%|████▉     | 718/1449 [4:28:49<4:22:16, 21.53s/it] 50%|████▉     | 719/1449 [4:29:11<4:21:53, 21.53s/it]                                                      {'loss': 1.0111, 'grad_norm': 3.3741700649261475, 'learning_rate': 1.0957447465558843e-06, 'num_tokens': 4297114.0, 'mean_token_accuracy': 0.7195848673582077, 'epoch': 0.5}
 50%|████▉     | 719/1449 [4:29:11<4:21:53, 21.53s/it] 50%|████▉     | 720/1449 [4:29:32<4:21:04, 21.49s/it]                                                      {'loss': 1.0781, 'grad_norm': 3.2802839279174805, 'learning_rate': 1.093471853693616e-06, 'num_tokens': 4303251.0, 'mean_token_accuracy': 0.696406040340662, 'epoch': 0.5}
 50%|████▉     | 720/1449 [4:29:32<4:21:04, 21.49s/it] 50%|████▉     | 721/1449 [4:29:54<4:21:09, 21.52s/it]                                                      {'loss': 1.0141, 'grad_norm': 3.332711696624756, 'learning_rate': 1.0911984735906635e-06, 'num_tokens': 4309337.0, 'mean_token_accuracy': 0.7219920381903648, 'epoch': 0.5}
 50%|████▉     | 721/1449 [4:29:54<4:21:09, 21.52s/it] 50%|████▉     | 722/1449 [4:30:15<4:20:11, 21.47s/it]                                                      {'loss': 1.0052, 'grad_norm': 3.2297894954681396, 'learning_rate': 1.088924618097474e-06, 'num_tokens': 4316317.0, 'mean_token_accuracy': 0.7218555398285389, 'epoch': 0.5}
 50%|████▉     | 722/1449 [4:30:15<4:20:11, 21.47s/it] 50%|████▉     | 723/1449 [4:30:37<4:19:43, 21.46s/it]                                                      {'loss': 0.9841, 'grad_norm': 3.6681406497955322, 'learning_rate': 1.0866502990669727e-06, 'num_tokens': 4322085.0, 'mean_token_accuracy': 0.7212777137756348, 'epoch': 0.5}
 50%|████▉     | 723/1449 [4:30:37<4:19:43, 21.46s/it] 50%|████▉     | 724/1449 [4:30:58<4:19:36, 21.48s/it]                                                      {'loss': 1.0175, 'grad_norm': 3.6124656200408936, 'learning_rate': 1.0843755283545018e-06, 'num_tokens': 4327748.0, 'mean_token_accuracy': 0.7168882638216019, 'epoch': 0.5}
 50%|████▉     | 724/1449 [4:30:58<4:19:36, 21.48s/it] 50%|█████     | 725/1449 [4:31:20<4:19:18, 21.49s/it]                                                      {'loss': 1.1048, 'grad_norm': 3.280557155609131, 'learning_rate': 1.082100317817757e-06, 'num_tokens': 4334051.0, 'mean_token_accuracy': 0.702066782861948, 'epoch': 0.5}
 50%|█████     | 725/1449 [4:31:20<4:19:18, 21.49s/it] 50%|█████     | 726/1449 [4:31:41<4:18:54, 21.49s/it]                                                      {'loss': 0.9855, 'grad_norm': 3.5688822269439697, 'learning_rate': 1.079824679316727e-06, 'num_tokens': 4340280.0, 'mean_token_accuracy': 0.7217674180865288, 'epoch': 0.5}
 50%|█████     | 726/1449 [4:31:41<4:18:54, 21.49s/it] 50%|█████     | 727/1449 [4:32:03<4:18:42, 21.50s/it]                                                      {'loss': 0.9327, 'grad_norm': 3.1543421745300293, 'learning_rate': 1.077548624713632e-06, 'num_tokens': 4346116.0, 'mean_token_accuracy': 0.7376730926334858, 'epoch': 0.5}
 50%|█████     | 727/1449 [4:32:03<4:18:42, 21.50s/it] 50%|█████     | 728/1449 [4:32:24<4:18:25, 21.51s/it]                                                      {'loss': 1.0, 'grad_norm': 3.111818313598633, 'learning_rate': 1.07527216587286e-06, 'num_tokens': 4351974.0, 'mean_token_accuracy': 0.7164282687008381, 'epoch': 0.5}
 50%|█████     | 728/1449 [4:32:24<4:18:25, 21.51s/it] 50%|█████     | 729/1449 [4:32:46<4:17:50, 21.49s/it]                                                      {'loss': 1.133, 'grad_norm': 3.8499181270599365, 'learning_rate': 1.0729953146609075e-06, 'num_tokens': 4357996.0, 'mean_token_accuracy': 0.6859979182481766, 'epoch': 0.5}
 50%|█████     | 729/1449 [4:32:46<4:17:50, 21.49s/it] 50%|█████     | 730/1449 [4:33:07<4:17:38, 21.50s/it]                                                      {'loss': 0.9852, 'grad_norm': 3.5789754390716553, 'learning_rate': 1.070718082946315e-06, 'num_tokens': 4364046.0, 'mean_token_accuracy': 0.7288060039281845, 'epoch': 0.5}
 50%|█████     | 730/1449 [4:33:07<4:17:38, 21.50s/it] 50%|█████     | 731/1449 [4:33:29<4:18:27, 21.60s/it]                                                      {'loss': 1.0857, 'grad_norm': 3.738776206970215, 'learning_rate': 1.0684404825996077e-06, 'num_tokens': 4369922.0, 'mean_token_accuracy': 0.7113425098359585, 'epoch': 0.5}
 50%|█████     | 731/1449 [4:33:29<4:18:27, 21.60s/it] 51%|█████     | 732/1449 [4:33:50<4:17:04, 21.51s/it]                                                      {'loss': 0.9672, 'grad_norm': 3.193185806274414, 'learning_rate': 1.0661625254932317e-06, 'num_tokens': 4376364.0, 'mean_token_accuracy': 0.7240120470523834, 'epoch': 0.5}
 51%|█████     | 732/1449 [4:33:50<4:17:04, 21.51s/it] 51%|█████     | 733/1449 [4:34:12<4:17:17, 21.56s/it]                                                      {'loss': 1.0037, 'grad_norm': 3.8458192348480225, 'learning_rate': 1.0638842235014921e-06, 'num_tokens': 4382317.0, 'mean_token_accuracy': 0.7138093076646328, 'epoch': 0.51}
 51%|█████     | 733/1449 [4:34:12<4:17:17, 21.56s/it] 51%|█████     | 734/1449 [4:34:34<4:16:18, 21.51s/it]                                                      {'loss': 0.9982, 'grad_norm': 3.593580722808838, 'learning_rate': 1.0616055885004932e-06, 'num_tokens': 4387980.0, 'mean_token_accuracy': 0.7176815494894981, 'epoch': 0.51}
 51%|█████     | 734/1449 [4:34:34<4:16:18, 21.51s/it] 51%|█████     | 735/1449 [4:34:55<4:15:42, 21.49s/it]                                                      {'loss': 1.01, 'grad_norm': 3.2815046310424805, 'learning_rate': 1.0593266323680748e-06, 'num_tokens': 4394221.0, 'mean_token_accuracy': 0.7174154594540596, 'epoch': 0.51}
 51%|█████     | 735/1449 [4:34:55<4:15:42, 21.49s/it] 51%|█████     | 736/1449 [4:35:16<4:14:52, 21.45s/it]                                                      {'loss': 1.0237, 'grad_norm': 3.4202239513397217, 'learning_rate': 1.0570473669837497e-06, 'num_tokens': 4400437.0, 'mean_token_accuracy': 0.7160050272941589, 'epoch': 0.51}
 51%|█████     | 736/1449 [4:35:16<4:14:52, 21.45s/it] 51%|█████     | 737/1449 [4:35:38<4:15:26, 21.53s/it]                                                      {'loss': 0.9728, 'grad_norm': 3.3370168209075928, 'learning_rate': 1.0547678042286434e-06, 'num_tokens': 4406343.0, 'mean_token_accuracy': 0.7320451103150845, 'epoch': 0.51}
 51%|█████     | 737/1449 [4:35:38<4:15:26, 21.53s/it] 51%|█████     | 738/1449 [4:35:59<4:14:13, 21.45s/it]                                                      {'loss': 1.1039, 'grad_norm': 3.5300047397613525, 'learning_rate': 1.0524879559854325e-06, 'num_tokens': 4412013.0, 'mean_token_accuracy': 0.6847533024847507, 'epoch': 0.51}
 51%|█████     | 738/1449 [4:35:59<4:14:13, 21.45s/it] 51%|█████     | 739/1449 [4:36:21<4:14:40, 21.52s/it]                                                      {'loss': 0.9858, 'grad_norm': 3.8026161193847656, 'learning_rate': 1.0502078341382796e-06, 'num_tokens': 4417483.0, 'mean_token_accuracy': 0.7198884822428226, 'epoch': 0.51}
 51%|█████     | 739/1449 [4:36:21<4:14:40, 21.52s/it] 51%|█████     | 740/1449 [4:36:42<4:13:49, 21.48s/it]                                                      {'loss': 0.9482, 'grad_norm': 3.1394131183624268, 'learning_rate': 1.0479274505727755e-06, 'num_tokens': 4424152.0, 'mean_token_accuracy': 0.7299960814416409, 'epoch': 0.51}
 51%|█████     | 740/1449 [4:36:42<4:13:49, 21.48s/it] 51%|█████     | 741/1449 [4:37:04<4:13:17, 21.47s/it]                                                      {'loss': 1.0725, 'grad_norm': 3.888404130935669, 'learning_rate': 1.0456468171758738e-06, 'num_tokens': 4429720.0, 'mean_token_accuracy': 0.7055849507451057, 'epoch': 0.51}
 51%|█████     | 741/1449 [4:37:04<4:13:17, 21.47s/it] 51%|█████     | 742/1449 [4:37:25<4:13:10, 21.49s/it]                                                      {'loss': 1.0439, 'grad_norm': 3.8159432411193848, 'learning_rate': 1.0433659458358314e-06, 'num_tokens': 4435417.0, 'mean_token_accuracy': 0.7209336832165718, 'epoch': 0.51}
 51%|█████     | 742/1449 [4:37:25<4:13:10, 21.49s/it] 51%|█████▏    | 743/1449 [4:37:47<4:12:56, 21.50s/it]                                                      {'loss': 1.0639, 'grad_norm': 3.0956456661224365, 'learning_rate': 1.0410848484421452e-06, 'num_tokens': 4441439.0, 'mean_token_accuracy': 0.7073160707950592, 'epoch': 0.51}
 51%|█████▏    | 743/1449 [4:37:47<4:12:56, 21.50s/it] 51%|█████▏    | 744/1449 [4:38:08<4:12:23, 21.48s/it]                                                      {'loss': 1.144, 'grad_norm': 3.158696174621582, 'learning_rate': 1.0388035368854906e-06, 'num_tokens': 4447430.0, 'mean_token_accuracy': 0.6877851076424122, 'epoch': 0.51}
 51%|█████▏    | 744/1449 [4:38:08<4:12:23, 21.48s/it] 51%|█████▏    | 745/1449 [4:38:30<4:12:22, 21.51s/it]                                                      {'loss': 0.9364, 'grad_norm': 3.8175933361053467, 'learning_rate': 1.036522023057659e-06, 'num_tokens': 4453500.0, 'mean_token_accuracy': 0.72575443983078, 'epoch': 0.51}
 51%|█████▏    | 745/1449 [4:38:30<4:12:22, 21.51s/it] 51%|█████▏    | 746/1449 [4:38:51<4:12:05, 21.52s/it]                                                      {'loss': 1.0595, 'grad_norm': 3.29931378364563, 'learning_rate': 1.034240318851496e-06, 'num_tokens': 4459611.0, 'mean_token_accuracy': 0.7026497721672058, 'epoch': 0.51}
 51%|█████▏    | 746/1449 [4:38:51<4:12:05, 21.52s/it] 52%|█████▏    | 747/1449 [4:39:13<4:11:24, 21.49s/it]                                                      {'loss': 1.0497, 'grad_norm': 3.4818711280822754, 'learning_rate': 1.0319584361608406e-06, 'num_tokens': 4466360.0, 'mean_token_accuracy': 0.7068937346339226, 'epoch': 0.52}
 52%|█████▏    | 747/1449 [4:39:13<4:11:24, 21.49s/it] 52%|█████▏    | 748/1449 [4:39:34<4:11:19, 21.51s/it]                                                      {'loss': 0.9032, 'grad_norm': 3.6967313289642334, 'learning_rate': 1.0296763868804613e-06, 'num_tokens': 4471807.0, 'mean_token_accuracy': 0.742023404687643, 'epoch': 0.52}
 52%|█████▏    | 748/1449 [4:39:34<4:11:19, 21.51s/it] 52%|█████▏    | 749/1449 [4:39:56<4:11:03, 21.52s/it]                                                      {'loss': 0.9926, 'grad_norm': 3.667414426803589, 'learning_rate': 1.0273941829059949e-06, 'num_tokens': 4476813.0, 'mean_token_accuracy': 0.7187790647149086, 'epoch': 0.52}
 52%|█████▏    | 749/1449 [4:39:56<4:11:03, 21.52s/it] 52%|█████▏    | 750/1449 [4:40:17<4:09:54, 21.45s/it]                                                      {'loss': 1.0546, 'grad_norm': 3.854557752609253, 'learning_rate': 1.0251118361338853e-06, 'num_tokens': 4482200.0, 'mean_token_accuracy': 0.709619153290987, 'epoch': 0.52}
 52%|█████▏    | 750/1449 [4:40:17<4:09:54, 21.45s/it][INFO|trainer.py:3966] 2025-06-06 04:49:43,690 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750
[INFO|configuration_utils.py:423] 2025-06-06 04:49:43,695 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/config.json
[INFO|configuration_utils.py:908] 2025-06-06 04:49:43,697 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 04:49:52,448 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 04:49:52,451 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 04:49:52,453 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/special_tokens_map.json
[2025-06-06 04:49:52,648] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step750 is about to be saved!
[2025-06-06 04:49:52,654] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/global_step750/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 04:49:52,654] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/global_step750/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 04:49:52,669] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/global_step750/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 04:49:52,670] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/global_step750/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 04:50:13,677] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/global_step750/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 04:50:13,682] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-750/global_step750/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 04:50:13,967] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step750 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 04:50:24,426 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 04:50:24,428 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 52%|█████▏    | 751/1449 [4:41:21<6:38:46, 34.28s/it]                                                      {'loss': 0.9279, 'grad_norm': 3.8782880306243896, 'learning_rate': 1.0228293584613201e-06, 'num_tokens': 4487951.0, 'mean_token_accuracy': 0.7327095195651054, 'epoch': 0.52}
 52%|█████▏    | 751/1449 [4:41:21<6:38:46, 34.28s/it] 52%|█████▏    | 752/1449 [4:41:43<5:53:27, 30.43s/it]                                                      {'loss': 1.0003, 'grad_norm': 3.4430031776428223, 'learning_rate': 1.0205467617861702e-06, 'num_tokens': 4493628.0, 'mean_token_accuracy': 0.7092058174312115, 'epoch': 0.52}
 52%|█████▏    | 752/1449 [4:41:43<5:53:27, 30.43s/it] 52%|█████▏    | 753/1449 [4:42:05<5:23:02, 27.85s/it]                                                      {'loss': 1.0816, 'grad_norm': 3.2379016876220703, 'learning_rate': 1.0182640580069248e-06, 'num_tokens': 4499752.0, 'mean_token_accuracy': 0.6998829878866673, 'epoch': 0.52}
 52%|█████▏    | 753/1449 [4:42:05<5:23:02, 27.85s/it] 52%|█████▏    | 754/1449 [4:42:26<5:00:59, 25.99s/it]                                                      {'loss': 1.007, 'grad_norm': 3.5730531215667725, 'learning_rate': 1.015981259022634e-06, 'num_tokens': 4505372.0, 'mean_token_accuracy': 0.7215473689138889, 'epoch': 0.52}
 52%|█████▏    | 754/1449 [4:42:26<5:00:59, 25.99s/it] 52%|█████▏    | 755/1449 [4:42:48<4:44:52, 24.63s/it]                                                      {'loss': 1.0556, 'grad_norm': 4.207425117492676, 'learning_rate': 1.0136983767328423e-06, 'num_tokens': 4511208.0, 'mean_token_accuracy': 0.7083900570869446, 'epoch': 0.52}
 52%|█████▏    | 755/1449 [4:42:48<4:44:52, 24.63s/it] 52%|█████▏    | 756/1449 [4:43:09<4:34:08, 23.74s/it]                                                      {'loss': 0.9908, 'grad_norm': 3.4227333068847656, 'learning_rate': 1.011415423037529e-06, 'num_tokens': 4517109.0, 'mean_token_accuracy': 0.7263819500803947, 'epoch': 0.52}
 52%|█████▏    | 756/1449 [4:43:09<4:34:08, 23.74s/it] 52%|█████▏    | 757/1449 [4:43:31<4:26:46, 23.13s/it]                                                      {'loss': 0.9678, 'grad_norm': 3.8521523475646973, 'learning_rate': 1.0091324098370457e-06, 'num_tokens': 4522495.0, 'mean_token_accuracy': 0.7345421425998211, 'epoch': 0.52}
 52%|█████▏    | 757/1449 [4:43:31<4:26:46, 23.13s/it] 52%|█████▏    | 758/1449 [4:43:53<4:20:34, 22.63s/it]                                                      {'loss': 0.9969, 'grad_norm': 3.573031187057495, 'learning_rate': 1.006849349032055e-06, 'num_tokens': 4528764.0, 'mean_token_accuracy': 0.7271616347134113, 'epoch': 0.52}
 52%|█████▏    | 758/1449 [4:43:53<4:20:34, 22.63s/it] 52%|█████▏    | 759/1449 [4:44:14<4:17:23, 22.38s/it]                                                      {'loss': 1.073, 'grad_norm': 3.21372127532959, 'learning_rate': 1.0045662525234656e-06, 'num_tokens': 4535109.0, 'mean_token_accuracy': 0.7077716626226902, 'epoch': 0.52}
 52%|█████▏    | 759/1449 [4:44:14<4:17:23, 22.38s/it] 52%|█████▏    | 760/1449 [4:44:36<4:13:42, 22.09s/it]                                                      {'loss': 0.9937, 'grad_norm': 3.4717602729797363, 'learning_rate': 1.0022831322123737e-06, 'num_tokens': 4540762.0, 'mean_token_accuracy': 0.7219321429729462, 'epoch': 0.52}
 52%|█████▏    | 760/1449 [4:44:36<4:13:42, 22.09s/it] 53%|█████▎    | 761/1449 [4:44:58<4:11:59, 21.98s/it]                                                      {'loss': 1.0663, 'grad_norm': 3.110875129699707, 'learning_rate': 1e-06, 'num_tokens': 4547517.0, 'mean_token_accuracy': 0.7071377448737621, 'epoch': 0.52}
 53%|█████▎    | 761/1449 [4:44:58<4:11:59, 21.98s/it] 53%|█████▎    | 762/1449 [4:45:19<4:09:47, 21.82s/it]                                                      {'loss': 0.9378, 'grad_norm': 3.4261929988861084, 'learning_rate': 9.977168677876264e-07, 'num_tokens': 4553319.0, 'mean_token_accuracy': 0.7294586561620235, 'epoch': 0.53}
 53%|█████▎    | 762/1449 [4:45:19<4:09:47, 21.82s/it] 53%|█████▎    | 763/1449 [4:45:41<4:08:49, 21.76s/it]                                                      {'loss': 1.003, 'grad_norm': 3.804842710494995, 'learning_rate': 9.954337474765345e-07, 'num_tokens': 4558524.0, 'mean_token_accuracy': 0.7084438838064671, 'epoch': 0.53}
 53%|█████▎    | 763/1449 [4:45:41<4:08:49, 21.76s/it] 53%|█████▎    | 764/1449 [4:46:02<4:07:18, 21.66s/it]                                                      {'loss': 1.1208, 'grad_norm': 3.2222959995269775, 'learning_rate': 9.931506509679454e-07, 'num_tokens': 4565270.0, 'mean_token_accuracy': 0.7074560262262821, 'epoch': 0.53}
 53%|█████▎    | 764/1449 [4:46:02<4:07:18, 21.66s/it] 53%|█████▎    | 765/1449 [4:46:24<4:07:23, 21.70s/it]                                                      {'loss': 1.2037, 'grad_norm': 3.981501579284668, 'learning_rate': 9.908675901629542e-07, 'num_tokens': 4570579.0, 'mean_token_accuracy': 0.6944463662803173, 'epoch': 0.53}
 53%|█████▎    | 765/1449 [4:46:24<4:07:23, 21.70s/it] 53%|█████▎    | 766/1449 [4:46:45<4:06:28, 21.65s/it]                                                      {'loss': 1.0522, 'grad_norm': 3.523674964904785, 'learning_rate': 9.885845769624714e-07, 'num_tokens': 4576507.0, 'mean_token_accuracy': 0.7106326408684254, 'epoch': 0.53}
 53%|█████▎    | 766/1449 [4:46:45<4:06:28, 21.65s/it] 53%|█████▎    | 767/1449 [4:47:07<4:05:53, 21.63s/it]                                                      {'loss': 1.1199, 'grad_norm': 3.270531415939331, 'learning_rate': 9.863016232671578e-07, 'num_tokens': 4583163.0, 'mean_token_accuracy': 0.703350380063057, 'epoch': 0.53}
 53%|█████▎    | 767/1449 [4:47:07<4:05:53, 21.63s/it] 53%|█████▎    | 768/1449 [4:47:29<4:05:17, 21.61s/it]                                                      {'loss': 1.1532, 'grad_norm': 2.9850573539733887, 'learning_rate': 9.840187409773664e-07, 'num_tokens': 4590316.0, 'mean_token_accuracy': 0.696269229054451, 'epoch': 0.53}
 53%|█████▎    | 768/1449 [4:47:29<4:05:17, 21.61s/it] 53%|█████▎    | 769/1449 [4:47:50<4:04:15, 21.55s/it]                                                      {'loss': 1.0466, 'grad_norm': 3.2291529178619385, 'learning_rate': 9.81735941993075e-07, 'num_tokens': 4596731.0, 'mean_token_accuracy': 0.7075739614665508, 'epoch': 0.53}
 53%|█████▎    | 769/1449 [4:47:50<4:04:15, 21.55s/it] 53%|█████▎    | 770/1449 [4:48:12<4:04:04, 21.57s/it]                                                      {'loss': 1.1158, 'grad_norm': 3.9012956619262695, 'learning_rate': 9.794532382138304e-07, 'num_tokens': 4602001.0, 'mean_token_accuracy': 0.699971716850996, 'epoch': 0.53}
 53%|█████▎    | 770/1449 [4:48:12<4:04:04, 21.57s/it] 53%|█████▎    | 771/1449 [4:48:33<4:04:23, 21.63s/it]                                                      {'loss': 0.9959, 'grad_norm': 3.7909395694732666, 'learning_rate': 9.7717064153868e-07, 'num_tokens': 4607497.0, 'mean_token_accuracy': 0.7208481840789318, 'epoch': 0.53}
 53%|█████▎    | 771/1449 [4:48:33<4:04:23, 21.63s/it] 53%|█████▎    | 772/1449 [4:48:55<4:02:41, 21.51s/it]                                                      {'loss': 1.0242, 'grad_norm': 3.7412943840026855, 'learning_rate': 9.74888163866115e-07, 'num_tokens': 4613369.0, 'mean_token_accuracy': 0.7247177511453629, 'epoch': 0.53}
 53%|█████▎    | 772/1449 [4:48:55<4:02:41, 21.51s/it] 53%|█████▎    | 773/1449 [4:49:16<4:03:16, 21.59s/it]                                                      {'loss': 1.0376, 'grad_norm': 3.1711573600769043, 'learning_rate': 9.72605817094005e-07, 'num_tokens': 4619689.0, 'mean_token_accuracy': 0.716491349041462, 'epoch': 0.53}
 53%|█████▎    | 773/1449 [4:49:16<4:03:16, 21.59s/it] 53%|█████▎    | 774/1449 [4:49:38<4:02:23, 21.55s/it]                                                      {'loss': 1.0707, 'grad_norm': 3.4600868225097656, 'learning_rate': 9.70323613119539e-07, 'num_tokens': 4625846.0, 'mean_token_accuracy': 0.7074090018868446, 'epoch': 0.53}
 53%|█████▎    | 774/1449 [4:49:38<4:02:23, 21.55s/it] 53%|█████▎    | 775/1449 [4:49:59<4:02:10, 21.56s/it]                                                      {'loss': 1.0087, 'grad_norm': 3.1508681774139404, 'learning_rate': 9.680415638391593e-07, 'num_tokens': 4632706.0, 'mean_token_accuracy': 0.7223948054015636, 'epoch': 0.53}
 53%|█████▎    | 775/1449 [4:49:59<4:02:10, 21.56s/it] 54%|█████▎    | 776/1449 [4:50:21<4:01:52, 21.56s/it]                                                      {'loss': 1.0696, 'grad_norm': 3.272867202758789, 'learning_rate': 9.65759681148504e-07, 'num_tokens': 4638396.0, 'mean_token_accuracy': 0.7061784863471985, 'epoch': 0.54}
 54%|█████▎    | 776/1449 [4:50:21<4:01:52, 21.56s/it] 54%|█████▎    | 777/1449 [4:50:43<4:01:53, 21.60s/it]                                                      {'loss': 1.1514, 'grad_norm': 3.5338807106018066, 'learning_rate': 9.63477976942341e-07, 'num_tokens': 4644832.0, 'mean_token_accuracy': 0.6955254040658474, 'epoch': 0.54}
 54%|█████▎    | 777/1449 [4:50:43<4:01:53, 21.60s/it] 54%|█████▎    | 778/1449 [4:51:04<4:00:53, 21.54s/it]                                                      {'loss': 1.1102, 'grad_norm': 3.788691997528076, 'learning_rate': 9.611964631145093e-07, 'num_tokens': 4650504.0, 'mean_token_accuracy': 0.70375557243824, 'epoch': 0.54}
 54%|█████▎    | 778/1449 [4:51:04<4:00:53, 21.54s/it] 54%|█████▍    | 779/1449 [4:51:26<4:00:46, 21.56s/it]                                                      {'loss': 1.0148, 'grad_norm': 3.525697708129883, 'learning_rate': 9.589151515578547e-07, 'num_tokens': 4655931.0, 'mean_token_accuracy': 0.7245139218866825, 'epoch': 0.54}
 54%|█████▍    | 779/1449 [4:51:26<4:00:46, 21.56s/it] 54%|█████▍    | 780/1449 [4:51:47<3:59:51, 21.51s/it]                                                      {'loss': 1.0247, 'grad_norm': 3.405303478240967, 'learning_rate': 9.566340541641687e-07, 'num_tokens': 4662101.0, 'mean_token_accuracy': 0.7153971120715141, 'epoch': 0.54}
 54%|█████▍    | 780/1449 [4:51:47<3:59:51, 21.51s/it] 54%|█████▍    | 781/1449 [4:52:09<3:59:48, 21.54s/it]                                                      {'loss': 1.128, 'grad_norm': 3.226581335067749, 'learning_rate': 9.543531828241261e-07, 'num_tokens': 4668987.0, 'mean_token_accuracy': 0.6982902884483337, 'epoch': 0.54}
 54%|█████▍    | 781/1449 [4:52:09<3:59:48, 21.54s/it] 54%|█████▍    | 782/1449 [4:52:30<3:59:35, 21.55s/it]                                                      {'loss': 1.0132, 'grad_norm': 4.072930335998535, 'learning_rate': 9.520725494272248e-07, 'num_tokens': 4674235.0, 'mean_token_accuracy': 0.7160987742245197, 'epoch': 0.54}
 54%|█████▍    | 782/1449 [4:52:30<3:59:35, 21.55s/it] 54%|█████▍    | 783/1449 [4:52:52<3:58:47, 21.51s/it]                                                      {'loss': 0.9459, 'grad_norm': 3.9625964164733887, 'learning_rate': 9.497921658617201e-07, 'num_tokens': 4679788.0, 'mean_token_accuracy': 0.735706701874733, 'epoch': 0.54}
 54%|█████▍    | 783/1449 [4:52:52<3:58:47, 21.51s/it] 54%|█████▍    | 784/1449 [4:53:13<3:58:42, 21.54s/it]                                                      {'loss': 1.0779, 'grad_norm': 3.358503818511963, 'learning_rate': 9.475120440145676e-07, 'num_tokens': 4685186.0, 'mean_token_accuracy': 0.69620481133461, 'epoch': 0.54}
 54%|█████▍    | 784/1449 [4:53:13<3:58:42, 21.54s/it] 54%|█████▍    | 785/1449 [4:53:35<3:58:36, 21.56s/it]                                                      {'loss': 0.9633, 'grad_norm': 4.068179607391357, 'learning_rate': 9.452321957713562e-07, 'num_tokens': 4690855.0, 'mean_token_accuracy': 0.7405562438070774, 'epoch': 0.54}
 54%|█████▍    | 785/1449 [4:53:35<3:58:36, 21.56s/it] 54%|█████▍    | 786/1449 [4:53:56<3:57:41, 21.51s/it]                                                      {'loss': 1.0635, 'grad_norm': 2.9970438480377197, 'learning_rate': 9.429526330162505e-07, 'num_tokens': 4698861.0, 'mean_token_accuracy': 0.7044991925358772, 'epoch': 0.54}
 54%|█████▍    | 786/1449 [4:53:56<3:57:41, 21.51s/it] 54%|█████▍    | 787/1449 [4:54:18<3:57:41, 21.54s/it]                                                      {'loss': 1.1281, 'grad_norm': 3.746178388595581, 'learning_rate': 9.406733676319251e-07, 'num_tokens': 4704707.0, 'mean_token_accuracy': 0.7043005377054214, 'epoch': 0.54}
 54%|█████▍    | 787/1449 [4:54:18<3:57:41, 21.54s/it] 54%|█████▍    | 788/1449 [4:54:40<3:58:02, 21.61s/it]                                                      {'loss': 1.115, 'grad_norm': 3.4685940742492676, 'learning_rate': 9.383944114995067e-07, 'num_tokens': 4710891.0, 'mean_token_accuracy': 0.6996464468538761, 'epoch': 0.54}
 54%|█████▍    | 788/1449 [4:54:40<3:58:02, 21.61s/it] 54%|█████▍    | 789/1449 [4:55:01<3:56:31, 21.50s/it]                                                      {'loss': 1.0823, 'grad_norm': 3.832538604736328, 'learning_rate': 9.361157764985077e-07, 'num_tokens': 4716788.0, 'mean_token_accuracy': 0.7128748632967472, 'epoch': 0.54}
 54%|█████▍    | 789/1449 [4:55:01<3:56:31, 21.50s/it] 55%|█████▍    | 790/1449 [4:55:23<3:56:52, 21.57s/it]                                                      {'loss': 1.0484, 'grad_norm': 4.159022808074951, 'learning_rate': 9.338374745067685e-07, 'num_tokens': 4722275.0, 'mean_token_accuracy': 0.7036442048847675, 'epoch': 0.54}
 55%|█████▍    | 790/1449 [4:55:23<3:56:52, 21.57s/it] 55%|█████▍    | 791/1449 [4:55:44<3:56:11, 21.54s/it]                                                      {'loss': 0.9898, 'grad_norm': 3.4435064792633057, 'learning_rate': 9.315595174003922e-07, 'num_tokens': 4727829.0, 'mean_token_accuracy': 0.7159509174525738, 'epoch': 0.55}
 55%|█████▍    | 791/1449 [4:55:44<3:56:11, 21.54s/it] 55%|█████▍    | 792/1449 [4:56:06<3:55:56, 21.55s/it]                                                      {'loss': 1.1495, 'grad_norm': 4.468599319458008, 'learning_rate': 9.292819170536849e-07, 'num_tokens': 4733270.0, 'mean_token_accuracy': 0.6865103915333748, 'epoch': 0.55}
 55%|█████▍    | 792/1449 [4:56:06<3:55:56, 21.55s/it] 55%|█████▍    | 793/1449 [4:56:27<3:55:46, 21.57s/it]                                                      {'loss': 1.0084, 'grad_norm': 3.5444793701171875, 'learning_rate': 9.270046853390924e-07, 'num_tokens': 4739320.0, 'mean_token_accuracy': 0.7171276472508907, 'epoch': 0.55}
 55%|█████▍    | 793/1449 [4:56:27<3:55:46, 21.57s/it] 55%|█████▍    | 794/1449 [4:56:49<3:55:37, 21.58s/it]                                                      {'loss': 1.1098, 'grad_norm': 3.4084556102752686, 'learning_rate': 9.247278341271398e-07, 'num_tokens': 4745256.0, 'mean_token_accuracy': 0.7129718437790871, 'epoch': 0.55}
 55%|█████▍    | 794/1449 [4:56:49<3:55:37, 21.58s/it] 55%|█████▍    | 795/1449 [4:57:10<3:54:42, 21.53s/it]                                                      {'loss': 1.0624, 'grad_norm': 2.9752376079559326, 'learning_rate': 9.224513752863677e-07, 'num_tokens': 4752237.0, 'mean_token_accuracy': 0.7097066305577755, 'epoch': 0.55}
 55%|█████▍    | 795/1449 [4:57:10<3:54:42, 21.53s/it] 55%|█████▍    | 796/1449 [4:57:32<3:54:28, 21.54s/it]                                                      {'loss': 1.026, 'grad_norm': 4.099944591522217, 'learning_rate': 9.201753206832727e-07, 'num_tokens': 4757747.0, 'mean_token_accuracy': 0.705748125910759, 'epoch': 0.55}
 55%|█████▍    | 796/1449 [4:57:32<3:54:28, 21.54s/it] 55%|█████▌    | 797/1449 [4:57:53<3:53:42, 21.51s/it]                                                      {'loss': 1.0703, 'grad_norm': 3.7197813987731934, 'learning_rate': 9.178996821822429e-07, 'num_tokens': 4763974.0, 'mean_token_accuracy': 0.7040262706577778, 'epoch': 0.55}
 55%|█████▌    | 797/1449 [4:57:53<3:53:42, 21.51s/it] 55%|█████▌    | 798/1449 [4:58:15<3:54:06, 21.58s/it]                                                      {'loss': 1.0419, 'grad_norm': 3.449946641921997, 'learning_rate': 9.156244716454983e-07, 'num_tokens': 4769339.0, 'mean_token_accuracy': 0.6981574036180973, 'epoch': 0.55}
 55%|█████▌    | 798/1449 [4:58:15<3:54:06, 21.58s/it] 55%|█████▌    | 799/1449 [4:58:36<3:53:14, 21.53s/it]                                                      {'loss': 1.0412, 'grad_norm': 3.7006659507751465, 'learning_rate': 9.13349700933027e-07, 'num_tokens': 4774774.0, 'mean_token_accuracy': 0.7066081203520298, 'epoch': 0.55}
 55%|█████▌    | 799/1449 [4:58:36<3:53:14, 21.53s/it] 55%|█████▌    | 800/1449 [4:58:58<3:53:04, 21.55s/it]                                                      {'loss': 1.0672, 'grad_norm': 3.682447671890259, 'learning_rate': 9.110753819025261e-07, 'num_tokens': 4780297.0, 'mean_token_accuracy': 0.7111897729337215, 'epoch': 0.55}
 55%|█████▌    | 800/1449 [4:58:58<3:53:04, 21.55s/it][INFO|trainer.py:3966] 2025-06-06 05:08:24,477 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800
[INFO|configuration_utils.py:423] 2025-06-06 05:08:24,487 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/config.json
[INFO|configuration_utils.py:908] 2025-06-06 05:08:24,489 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 05:08:31,653 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 05:08:31,656 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 05:08:31,658 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/special_tokens_map.json
[2025-06-06 05:08:31,852] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step800 is about to be saved!
[2025-06-06 05:08:31,858] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/global_step800/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 05:08:31,859] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/global_step800/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 05:08:31,873] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/global_step800/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 05:08:31,874] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/global_step800/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 05:08:54,647] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/global_step800/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 05:08:54,652] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-800/global_step800/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 05:08:55,116] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step800 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 05:09:06,595 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 05:09:06,597 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 55%|█████▌    | 801/1449 [5:00:03<6:14:11, 34.65s/it]                                                      {'loss': 0.975, 'grad_norm': 3.2121520042419434, 'learning_rate': 9.088015264093364e-07, 'num_tokens': 4786685.0, 'mean_token_accuracy': 0.7329926304519176, 'epoch': 0.55}
 55%|█████▌    | 801/1449 [5:00:03<6:14:11, 34.65s/it] 55%|█████▌    | 802/1449 [5:00:25<5:32:57, 30.88s/it]                                                      {'loss': 1.1512, 'grad_norm': 3.4511260986328125, 'learning_rate': 9.06528146306384e-07, 'num_tokens': 4792265.0, 'mean_token_accuracy': 0.6839835159480572, 'epoch': 0.55}
 55%|█████▌    | 802/1449 [5:00:25<5:32:57, 30.88s/it] 55%|█████▌    | 803/1449 [5:00:47<5:01:34, 28.01s/it]                                                      {'loss': 0.9686, 'grad_norm': 3.524055242538452, 'learning_rate': 9.042552534441157e-07, 'num_tokens': 4798725.0, 'mean_token_accuracy': 0.7312662377953529, 'epoch': 0.55}
 55%|█████▌    | 803/1449 [5:00:47<5:01:34, 28.01s/it] 55%|█████▌    | 804/1449 [5:01:08<4:41:13, 26.16s/it]                                                      {'loss': 0.945, 'grad_norm': 3.47706937789917, 'learning_rate': 9.019828596704393e-07, 'num_tokens': 4804848.0, 'mean_token_accuracy': 0.7504865974187851, 'epoch': 0.55}
 55%|█████▌    | 804/1449 [5:01:08<4:41:13, 26.16s/it] 56%|█████▌    | 805/1449 [5:01:30<4:25:27, 24.73s/it]                                                      {'loss': 0.9792, 'grad_norm': 3.4532036781311035, 'learning_rate': 8.997109768306607e-07, 'num_tokens': 4810927.0, 'mean_token_accuracy': 0.7274915277957916, 'epoch': 0.56}
 56%|█████▌    | 805/1449 [5:01:30<4:25:27, 24.73s/it] 56%|█████▌    | 806/1449 [5:01:52<4:15:13, 23.82s/it]                                                      {'loss': 1.2003, 'grad_norm': 3.654487133026123, 'learning_rate': 8.97439616767422e-07, 'num_tokens': 4816163.0, 'mean_token_accuracy': 0.6949116289615631, 'epoch': 0.56}
 56%|█████▌    | 806/1449 [5:01:52<4:15:13, 23.82s/it] 56%|█████▌    | 807/1449 [5:02:13<4:08:01, 23.18s/it]                                                      {'loss': 1.0003, 'grad_norm': 3.805889129638672, 'learning_rate': 8.95168791320641e-07, 'num_tokens': 4822899.0, 'mean_token_accuracy': 0.7103509604930878, 'epoch': 0.56}
 56%|█████▌    | 807/1449 [5:02:13<4:08:01, 23.18s/it] 56%|█████▌    | 808/1449 [5:02:35<4:01:53, 22.64s/it]                                                      {'loss': 1.0808, 'grad_norm': 3.3829429149627686, 'learning_rate': 8.92898512327448e-07, 'num_tokens': 4829304.0, 'mean_token_accuracy': 0.7062009759247303, 'epoch': 0.56}
 56%|█████▌    | 808/1449 [5:02:35<4:01:53, 22.64s/it] 56%|█████▌    | 809/1449 [5:02:57<3:59:05, 22.41s/it]                                                      {'loss': 1.0037, 'grad_norm': 3.230682849884033, 'learning_rate': 8.906287916221258e-07, 'num_tokens': 4835477.0, 'mean_token_accuracy': 0.7267835810780525, 'epoch': 0.56}
 56%|█████▌    | 809/1449 [5:02:57<3:59:05, 22.41s/it] 56%|█████▌    | 810/1449 [5:03:18<3:55:51, 22.15s/it]                                                      {'loss': 1.1064, 'grad_norm': 3.4882965087890625, 'learning_rate': 8.883596410360455e-07, 'num_tokens': 4841626.0, 'mean_token_accuracy': 0.6936474926769733, 'epoch': 0.56}
 56%|█████▌    | 810/1449 [5:03:18<3:55:51, 22.15s/it] 56%|█████▌    | 811/1449 [5:03:40<3:53:30, 21.96s/it]                                                      {'loss': 0.9501, 'grad_norm': 3.4716787338256836, 'learning_rate': 8.860910723976082e-07, 'num_tokens': 4847946.0, 'mean_token_accuracy': 0.7307980805635452, 'epoch': 0.56}
 56%|█████▌    | 811/1449 [5:03:40<3:53:30, 21.96s/it] 56%|█████▌    | 812/1449 [5:04:01<3:52:14, 21.87s/it]                                                      {'loss': 1.0436, 'grad_norm': 3.4743142127990723, 'learning_rate': 8.838230975321796e-07, 'num_tokens': 4853760.0, 'mean_token_accuracy': 0.7091316133737564, 'epoch': 0.56}
 56%|█████▌    | 812/1449 [5:04:01<3:52:14, 21.87s/it] 56%|█████▌    | 813/1449 [5:04:23<3:50:43, 21.77s/it]                                                      {'loss': 1.0964, 'grad_norm': 3.214053153991699, 'learning_rate': 8.815557282620318e-07, 'num_tokens': 4859960.0, 'mean_token_accuracy': 0.7031820677220821, 'epoch': 0.56}
 56%|█████▌    | 813/1449 [5:04:23<3:50:43, 21.77s/it] 56%|█████▌    | 814/1449 [5:04:44<3:48:54, 21.63s/it]                                                      {'loss': 0.9626, 'grad_norm': 3.356566905975342, 'learning_rate': 8.792889764062787e-07, 'num_tokens': 4866234.0, 'mean_token_accuracy': 0.7227293141186237, 'epoch': 0.56}
 56%|█████▌    | 814/1449 [5:04:44<3:48:54, 21.63s/it] 56%|█████▌    | 815/1449 [5:05:05<3:47:53, 21.57s/it]                                                      {'loss': 0.9536, 'grad_norm': 2.910860776901245, 'learning_rate': 8.770228537808176e-07, 'num_tokens': 4873334.0, 'mean_token_accuracy': 0.721637349575758, 'epoch': 0.56}
 56%|█████▌    | 815/1449 [5:05:05<3:47:53, 21.57s/it] 56%|█████▋    | 816/1449 [5:05:26<3:45:41, 21.39s/it]                                                      {'loss': 1.0453, 'grad_norm': 2.9322874546051025, 'learning_rate': 8.747573721982635e-07, 'num_tokens': 4880513.0, 'mean_token_accuracy': 0.7174979038536549, 'epoch': 0.56}
 56%|█████▋    | 816/1449 [5:05:26<3:45:41, 21.39s/it] 56%|█████▋    | 817/1449 [5:05:48<3:45:11, 21.38s/it]                                                      {'loss': 1.0374, 'grad_norm': 3.2478902339935303, 'learning_rate': 8.724925434678923e-07, 'num_tokens': 4886718.0, 'mean_token_accuracy': 0.7237821854650974, 'epoch': 0.56}
 56%|█████▋    | 817/1449 [5:05:48<3:45:11, 21.38s/it] 56%|█████▋    | 818/1449 [5:06:09<3:43:29, 21.25s/it]                                                      {'loss': 0.891, 'grad_norm': 3.6766467094421387, 'learning_rate': 8.702283793955747e-07, 'num_tokens': 4893285.0, 'mean_token_accuracy': 0.7485577538609505, 'epoch': 0.56}
 56%|█████▋    | 818/1449 [5:06:09<3:43:29, 21.25s/it] 57%|█████▋    | 819/1449 [5:06:30<3:42:43, 21.21s/it]                                                      {'loss': 0.9943, 'grad_norm': 3.1692748069763184, 'learning_rate': 8.679648917837182e-07, 'num_tokens': 4899895.0, 'mean_token_accuracy': 0.7080108933150768, 'epoch': 0.56}
 57%|█████▋    | 819/1449 [5:06:30<3:42:43, 21.21s/it] 57%|█████▋    | 820/1449 [5:06:51<3:43:18, 21.30s/it]                                                      {'loss': 1.0441, 'grad_norm': 3.5958263874053955, 'learning_rate': 8.657020924312029e-07, 'num_tokens': 4905699.0, 'mean_token_accuracy': 0.7094029001891613, 'epoch': 0.57}
 57%|█████▋    | 820/1449 [5:06:51<3:43:18, 21.30s/it] 57%|█████▋    | 821/1449 [5:07:13<3:45:15, 21.52s/it]                                                      {'loss': 1.0437, 'grad_norm': 3.5239624977111816, 'learning_rate': 8.634399931333225e-07, 'num_tokens': 4911631.0, 'mean_token_accuracy': 0.7130836024880409, 'epoch': 0.57}
 57%|█████▋    | 821/1449 [5:07:13<3:45:15, 21.52s/it] 57%|█████▋    | 822/1449 [5:07:35<3:44:51, 21.52s/it]                                                      {'loss': 1.1389, 'grad_norm': 3.734363079071045, 'learning_rate': 8.611786056817202e-07, 'num_tokens': 4916876.0, 'mean_token_accuracy': 0.6801838241517544, 'epoch': 0.57}
 57%|█████▋    | 822/1449 [5:07:35<3:44:51, 21.52s/it] 57%|█████▋    | 823/1449 [5:07:57<3:45:33, 21.62s/it]                                                      {'loss': 1.0235, 'grad_norm': 3.5059521198272705, 'learning_rate': 8.5891794186433e-07, 'num_tokens': 4922620.0, 'mean_token_accuracy': 0.7206244878470898, 'epoch': 0.57}
 57%|█████▋    | 823/1449 [5:07:57<3:45:33, 21.62s/it] 57%|█████▋    | 824/1449 [5:08:19<3:46:38, 21.76s/it]                                                      {'loss': 1.0876, 'grad_norm': 3.372201919555664, 'learning_rate': 8.566580134653123e-07, 'num_tokens': 4928509.0, 'mean_token_accuracy': 0.6901323162019253, 'epoch': 0.57}
 57%|█████▋    | 824/1449 [5:08:19<3:46:38, 21.76s/it] 57%|█████▋    | 825/1449 [5:08:40<3:45:01, 21.64s/it]                                                      {'loss': 0.9865, 'grad_norm': 3.1623408794403076, 'learning_rate': 8.543988322649953e-07, 'num_tokens': 4934253.0, 'mean_token_accuracy': 0.7317086569964886, 'epoch': 0.57}
 57%|█████▋    | 825/1449 [5:08:40<3:45:01, 21.64s/it] 57%|█████▋    | 826/1449 [5:09:02<3:45:47, 21.75s/it]                                                      {'loss': 0.9673, 'grad_norm': 3.6316099166870117, 'learning_rate': 8.521404100398111e-07, 'num_tokens': 4940400.0, 'mean_token_accuracy': 0.7340017594397068, 'epoch': 0.57}
 57%|█████▋    | 826/1449 [5:09:02<3:45:47, 21.75s/it] 57%|█████▋    | 827/1449 [5:09:24<3:44:03, 21.61s/it]                                                      {'loss': 1.0381, 'grad_norm': 3.5268609523773193, 'learning_rate': 8.498827585622367e-07, 'num_tokens': 4946922.0, 'mean_token_accuracy': 0.7079925015568733, 'epoch': 0.57}
 57%|█████▋    | 827/1449 [5:09:24<3:44:03, 21.61s/it] 57%|█████▋    | 828/1449 [5:09:45<3:44:38, 21.70s/it]                                                      {'loss': 1.0653, 'grad_norm': 3.648951292037964, 'learning_rate': 8.476258896007301e-07, 'num_tokens': 4952680.0, 'mean_token_accuracy': 0.7014210224151611, 'epoch': 0.57}
 57%|█████▋    | 828/1449 [5:09:45<3:44:38, 21.70s/it] 57%|█████▋    | 829/1449 [5:10:07<3:44:30, 21.73s/it]                                                      {'loss': 0.8366, 'grad_norm': 3.249375820159912, 'learning_rate': 8.453698149196719e-07, 'num_tokens': 4959545.0, 'mean_token_accuracy': 0.7423016205430031, 'epoch': 0.57}
 57%|█████▋    | 829/1449 [5:10:07<3:44:30, 21.73s/it] 57%|█████▋    | 830/1449 [5:10:29<3:43:35, 21.67s/it]                                                      {'loss': 1.0553, 'grad_norm': 3.5920886993408203, 'learning_rate': 8.431145462793007e-07, 'num_tokens': 4965870.0, 'mean_token_accuracy': 0.7091087512671947, 'epoch': 0.57}
 57%|█████▋    | 830/1449 [5:10:29<3:43:35, 21.67s/it] 57%|█████▋    | 831/1449 [5:10:51<3:43:38, 21.71s/it]                                                      {'loss': 1.0619, 'grad_norm': 4.265944957733154, 'learning_rate': 8.408600954356547e-07, 'num_tokens': 4971290.0, 'mean_token_accuracy': 0.7115179523825645, 'epoch': 0.57}
 57%|█████▋    | 831/1449 [5:10:51<3:43:38, 21.71s/it] 57%|█████▋    | 832/1449 [5:11:12<3:43:42, 21.75s/it]                                                      {'loss': 0.9535, 'grad_norm': 3.2927634716033936, 'learning_rate': 8.386064741405079e-07, 'num_tokens': 4977851.0, 'mean_token_accuracy': 0.7269014418125153, 'epoch': 0.57}
 57%|█████▋    | 832/1449 [5:11:12<3:43:42, 21.75s/it] 57%|█████▋    | 833/1449 [5:11:34<3:42:33, 21.68s/it]                                                      {'loss': 0.9619, 'grad_norm': 3.5688915252685547, 'learning_rate': 8.36353694141312e-07, 'num_tokens': 4983957.0, 'mean_token_accuracy': 0.7333286739885807, 'epoch': 0.57}
 57%|█████▋    | 833/1449 [5:11:34<3:42:33, 21.68s/it] 58%|█████▊    | 834/1449 [5:11:56<3:43:09, 21.77s/it]                                                      {'loss': 0.9688, 'grad_norm': 3.1763296127319336, 'learning_rate': 8.34101767181131e-07, 'num_tokens': 4990067.0, 'mean_token_accuracy': 0.7205061949789524, 'epoch': 0.58}
 58%|█████▊    | 834/1449 [5:11:56<3:43:09, 21.77s/it] 58%|█████▊    | 835/1449 [5:12:18<3:42:24, 21.73s/it]                                                      {'loss': 1.0736, 'grad_norm': 3.598121166229248, 'learning_rate': 8.318507049985843e-07, 'num_tokens': 4995137.0, 'mean_token_accuracy': 0.699977558106184, 'epoch': 0.58}
 58%|█████▊    | 835/1449 [5:12:18<3:42:24, 21.73s/it] 58%|█████▊    | 836/1449 [5:12:39<3:41:44, 21.70s/it]                                                      {'loss': 1.0276, 'grad_norm': 2.9731523990631104, 'learning_rate': 8.296005193277821e-07, 'num_tokens': 5002419.0, 'mean_token_accuracy': 0.7094782721251249, 'epoch': 0.58}
 58%|█████▊    | 836/1449 [5:12:39<3:41:44, 21.70s/it] 58%|█████▊    | 837/1449 [5:13:01<3:41:21, 21.70s/it]                                                      {'loss': 1.0433, 'grad_norm': 3.8810744285583496, 'learning_rate': 8.273512218982666e-07, 'num_tokens': 5008085.0, 'mean_token_accuracy': 0.7134302407503128, 'epoch': 0.58}
 58%|█████▊    | 837/1449 [5:13:01<3:41:21, 21.70s/it] 58%|█████▊    | 838/1449 [5:13:23<3:41:59, 21.80s/it]                                                      {'loss': 1.007, 'grad_norm': 3.381500005722046, 'learning_rate': 8.251028244349487e-07, 'num_tokens': 5014569.0, 'mean_token_accuracy': 0.7168306186795235, 'epoch': 0.58}
 58%|█████▊    | 838/1449 [5:13:23<3:41:59, 21.80s/it] 58%|█████▊    | 839/1449 [5:13:45<3:41:13, 21.76s/it]                                                      {'loss': 0.9717, 'grad_norm': 3.6311728954315186, 'learning_rate': 8.228553386580495e-07, 'num_tokens': 5020024.0, 'mean_token_accuracy': 0.7153274714946747, 'epoch': 0.58}
 58%|█████▊    | 839/1449 [5:13:45<3:41:13, 21.76s/it] 58%|█████▊    | 840/1449 [5:14:06<3:40:30, 21.73s/it]                                                      {'loss': 1.0282, 'grad_norm': 3.459665060043335, 'learning_rate': 8.20608776283036e-07, 'num_tokens': 5026379.0, 'mean_token_accuracy': 0.7122281603515148, 'epoch': 0.58}
 58%|█████▊    | 840/1449 [5:14:06<3:40:30, 21.73s/it] 58%|█████▊    | 841/1449 [5:14:28<3:39:58, 21.71s/it]                                                      {'loss': 0.9349, 'grad_norm': 2.92984938621521, 'learning_rate': 8.183631490205635e-07, 'num_tokens': 5033135.0, 'mean_token_accuracy': 0.7307069823145866, 'epoch': 0.58}
 58%|█████▊    | 841/1449 [5:14:28<3:39:58, 21.71s/it] 58%|█████▊    | 842/1449 [5:14:50<3:39:27, 21.69s/it]                                                      {'loss': 1.1161, 'grad_norm': 3.6964032649993896, 'learning_rate': 8.161184685764117e-07, 'num_tokens': 5038491.0, 'mean_token_accuracy': 0.6934953965246677, 'epoch': 0.58}
 58%|█████▊    | 842/1449 [5:14:50<3:39:27, 21.69s/it] 58%|█████▊    | 843/1449 [5:15:12<3:39:57, 21.78s/it]                                                      {'loss': 1.1259, 'grad_norm': 3.2030887603759766, 'learning_rate': 8.138747466514258e-07, 'num_tokens': 5044704.0, 'mean_token_accuracy': 0.6885475665330887, 'epoch': 0.58}
 58%|█████▊    | 843/1449 [5:15:12<3:39:57, 21.78s/it] 58%|█████▊    | 844/1449 [5:15:33<3:39:17, 21.75s/it]                                                      {'loss': 1.0076, 'grad_norm': 3.4322075843811035, 'learning_rate': 8.116319949414532e-07, 'num_tokens': 5050247.0, 'mean_token_accuracy': 0.7168536223471165, 'epoch': 0.58}
 58%|█████▊    | 844/1449 [5:15:33<3:39:17, 21.75s/it] 58%|█████▊    | 845/1449 [5:15:55<3:38:38, 21.72s/it]                                                      {'loss': 1.0842, 'grad_norm': 3.287376642227173, 'learning_rate': 8.093902251372852e-07, 'num_tokens': 5055918.0, 'mean_token_accuracy': 0.7021745033562183, 'epoch': 0.58}
 58%|█████▊    | 845/1449 [5:15:55<3:38:38, 21.72s/it] 58%|█████▊    | 846/1449 [5:16:17<3:39:10, 21.81s/it]                                                      {'loss': 1.0999, 'grad_norm': 4.027110576629639, 'learning_rate': 8.071494489245935e-07, 'num_tokens': 5061764.0, 'mean_token_accuracy': 0.7049361206591129, 'epoch': 0.58}
 58%|█████▊    | 846/1449 [5:16:17<3:39:10, 21.81s/it] 58%|█████▊    | 847/1449 [5:16:38<3:37:42, 21.70s/it]                                                      {'loss': 1.0624, 'grad_norm': 3.863877296447754, 'learning_rate': 8.049096779838717e-07, 'num_tokens': 5067031.0, 'mean_token_accuracy': 0.7189139612019062, 'epoch': 0.58}
 58%|█████▊    | 847/1449 [5:16:38<3:37:42, 21.70s/it] 59%|█████▊    | 848/1449 [5:17:00<3:38:14, 21.79s/it]                                                      {'loss': 1.1327, 'grad_norm': 3.973008394241333, 'learning_rate': 8.026709239903727e-07, 'num_tokens': 5072853.0, 'mean_token_accuracy': 0.6986468285322189, 'epoch': 0.58}
 59%|█████▊    | 848/1449 [5:17:00<3:38:14, 21.79s/it] 59%|█████▊    | 849/1449 [5:17:22<3:38:19, 21.83s/it]                                                      {'loss': 1.0143, 'grad_norm': 3.3370022773742676, 'learning_rate': 8.004331986140474e-07, 'num_tokens': 5079152.0, 'mean_token_accuracy': 0.7273895740509033, 'epoch': 0.59}
 59%|█████▊    | 849/1449 [5:17:22<3:38:19, 21.83s/it] 59%|█████▊    | 850/1449 [5:17:44<3:36:35, 21.70s/it]                                                      {'loss': 0.9645, 'grad_norm': 3.645310640335083, 'learning_rate': 7.981965135194867e-07, 'num_tokens': 5084815.0, 'mean_token_accuracy': 0.7289611883461475, 'epoch': 0.59}
 59%|█████▊    | 850/1449 [5:17:44<3:36:35, 21.70s/it][INFO|trainer.py:3966] 2025-06-06 05:27:10,097 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850
[INFO|configuration_utils.py:423] 2025-06-06 05:27:10,102 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/config.json
[INFO|configuration_utils.py:908] 2025-06-06 05:27:10,104 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 05:27:17,483 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 05:27:17,486 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 05:27:17,488 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/special_tokens_map.json
[2025-06-06 05:27:17,699] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step850 is about to be saved!
[2025-06-06 05:27:17,705] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/global_step850/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 05:27:17,706] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/global_step850/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 05:27:17,720] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/global_step850/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 05:27:17,721] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/global_step850/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 05:27:40,269] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/global_step850/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 05:27:40,273] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-850/global_step850/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 05:27:40,625] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step850 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 05:27:51,725 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 05:27:51,727 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 59%|█████▊    | 851/1449 [5:18:49<5:45:41, 34.68s/it]                                                      {'loss': 1.0733, 'grad_norm': 3.416585922241211, 'learning_rate': 7.959608803658574e-07, 'num_tokens': 5090915.0, 'mean_token_accuracy': 0.6954747438430786, 'epoch': 0.59}
 59%|█████▊    | 851/1449 [5:18:49<5:45:41, 34.68s/it] 59%|█████▉    | 852/1449 [5:19:10<5:05:33, 30.71s/it]                                                      {'loss': 1.0555, 'grad_norm': 3.545187473297119, 'learning_rate': 7.937263108068436e-07, 'num_tokens': 5096787.0, 'mean_token_accuracy': 0.7082682400941849, 'epoch': 0.59}
 59%|█████▉    | 852/1449 [5:19:10<5:05:33, 30.71s/it] 59%|█████▉    | 853/1449 [5:19:32<4:38:36, 28.05s/it]                                                      {'loss': 1.1072, 'grad_norm': 3.69045090675354, 'learning_rate': 7.914928164905843e-07, 'num_tokens': 5102274.0, 'mean_token_accuracy': 0.6977633573114872, 'epoch': 0.59}
 59%|█████▉    | 853/1449 [5:19:32<4:38:36, 28.05s/it] 59%|█████▉    | 854/1449 [5:19:53<4:18:09, 26.03s/it]                                                      {'loss': 1.1106, 'grad_norm': 3.487652063369751, 'learning_rate': 7.892604090596151e-07, 'num_tokens': 5108239.0, 'mean_token_accuracy': 0.7029536180198193, 'epoch': 0.59}
 59%|█████▉    | 854/1449 [5:19:53<4:18:09, 26.03s/it] 59%|█████▉    | 855/1449 [5:20:15<4:04:44, 24.72s/it]                                                      {'loss': 1.0227, 'grad_norm': 3.2516636848449707, 'learning_rate': 7.87029100150804e-07, 'num_tokens': 5114006.0, 'mean_token_accuracy': 0.7165812216699123, 'epoch': 0.59}
 59%|█████▉    | 855/1449 [5:20:15<4:04:44, 24.72s/it] 59%|█████▉    | 856/1449 [5:20:36<3:54:45, 23.75s/it]                                                      {'loss': 1.0021, 'grad_norm': 3.5052950382232666, 'learning_rate': 7.84798901395295e-07, 'num_tokens': 5119830.0, 'mean_token_accuracy': 0.7158146686851978, 'epoch': 0.59}
 59%|█████▉    | 856/1449 [5:20:36<3:54:45, 23.75s/it] 59%|█████▉    | 857/1449 [5:20:58<3:47:43, 23.08s/it]                                                      {'loss': 1.0175, 'grad_norm': 3.1725516319274902, 'learning_rate': 7.825698244184431e-07, 'num_tokens': 5125996.0, 'mean_token_accuracy': 0.7228530533611774, 'epoch': 0.59}
 59%|█████▉    | 857/1449 [5:20:58<3:47:43, 23.08s/it] 59%|█████▉    | 858/1449 [5:21:19<3:42:41, 22.61s/it]                                                      {'loss': 0.9797, 'grad_norm': 3.4635250568389893, 'learning_rate': 7.803418808397573e-07, 'num_tokens': 5132072.0, 'mean_token_accuracy': 0.7240561544895172, 'epoch': 0.59}
 59%|█████▉    | 858/1449 [5:21:19<3:42:41, 22.61s/it] 59%|█████▉    | 859/1449 [5:21:41<3:39:06, 22.28s/it]                                                      {'loss': 1.1272, 'grad_norm': 4.048422336578369, 'learning_rate': 7.781150822728372e-07, 'num_tokens': 5137684.0, 'mean_token_accuracy': 0.6923038698732853, 'epoch': 0.59}
 59%|█████▉    | 859/1449 [5:21:41<3:39:06, 22.28s/it] 59%|█████▉    | 860/1449 [5:22:03<3:36:58, 22.10s/it]                                                      {'loss': 1.1093, 'grad_norm': 3.6118931770324707, 'learning_rate': 7.758894403253158e-07, 'num_tokens': 5143224.0, 'mean_token_accuracy': 0.7062496617436409, 'epoch': 0.59}
 59%|█████▉    | 860/1449 [5:22:03<3:36:58, 22.10s/it] 59%|█████▉    | 861/1449 [5:22:24<3:34:57, 21.93s/it]                                                      {'loss': 0.9892, 'grad_norm': 3.3351998329162598, 'learning_rate': 7.736649665987943e-07, 'num_tokens': 5149896.0, 'mean_token_accuracy': 0.7274544425308704, 'epoch': 0.59}
 59%|█████▉    | 861/1449 [5:22:24<3:34:57, 21.93s/it] 59%|█████▉    | 862/1449 [5:22:46<3:33:20, 21.81s/it]                                                      {'loss': 1.037, 'grad_norm': 3.3208720684051514, 'learning_rate': 7.71441672688787e-07, 'num_tokens': 5155350.0, 'mean_token_accuracy': 0.7069095112383366, 'epoch': 0.59}
 59%|█████▉    | 862/1449 [5:22:46<3:33:20, 21.81s/it] 60%|█████▉    | 863/1449 [5:23:07<3:32:09, 21.72s/it]                                                      {'loss': 1.0715, 'grad_norm': 3.841428518295288, 'learning_rate': 7.69219570184656e-07, 'num_tokens': 5161531.0, 'mean_token_accuracy': 0.7063210569322109, 'epoch': 0.6}
 60%|█████▉    | 863/1449 [5:23:07<3:32:09, 21.72s/it] 60%|█████▉    | 864/1449 [5:23:29<3:31:09, 21.66s/it]                                                      {'loss': 0.9285, 'grad_norm': 3.4363410472869873, 'learning_rate': 7.669986706695548e-07, 'num_tokens': 5167312.0, 'mean_token_accuracy': 0.7360760644078255, 'epoch': 0.6}
 60%|█████▉    | 864/1449 [5:23:29<3:31:09, 21.66s/it] 60%|█████▉    | 865/1449 [5:23:50<3:30:24, 21.62s/it]                                                      {'loss': 0.9534, 'grad_norm': 2.924346923828125, 'learning_rate': 7.647789857203643e-07, 'num_tokens': 5175311.0, 'mean_token_accuracy': 0.7271508388221264, 'epoch': 0.6}
 60%|█████▉    | 865/1449 [5:23:50<3:30:24, 21.62s/it] 60%|█████▉    | 866/1449 [5:24:12<3:30:04, 21.62s/it]                                                      {'loss': 1.0358, 'grad_norm': 2.963480234146118, 'learning_rate': 7.625605269076359e-07, 'num_tokens': 5182118.0, 'mean_token_accuracy': 0.723001342266798, 'epoch': 0.6}
 60%|█████▉    | 866/1449 [5:24:12<3:30:04, 21.62s/it] 60%|█████▉    | 867/1449 [5:24:33<3:29:18, 21.58s/it]                                                      {'loss': 0.9443, 'grad_norm': 3.4225003719329834, 'learning_rate': 7.603433057955279e-07, 'num_tokens': 5188122.0, 'mean_token_accuracy': 0.7440735884010792, 'epoch': 0.6}
 60%|█████▉    | 867/1449 [5:24:33<3:29:18, 21.58s/it] 60%|█████▉    | 868/1449 [5:24:55<3:28:39, 21.55s/it]                                                      {'loss': 1.0493, 'grad_norm': 3.5398521423339844, 'learning_rate': 7.581273339417484e-07, 'num_tokens': 5194969.0, 'mean_token_accuracy': 0.7029586844146252, 'epoch': 0.6}
 60%|█████▉    | 868/1449 [5:24:55<3:28:39, 21.55s/it] 60%|█████▉    | 869/1449 [5:25:16<3:28:09, 21.53s/it]                                                      {'loss': 1.0126, 'grad_norm': 3.5789682865142822, 'learning_rate': 7.559126228974921e-07, 'num_tokens': 5201005.0, 'mean_token_accuracy': 0.7149725407361984, 'epoch': 0.6}
 60%|█████▉    | 869/1449 [5:25:16<3:28:09, 21.53s/it] 60%|██████    | 870/1449 [5:25:38<3:27:36, 21.51s/it]                                                      {'loss': 0.9986, 'grad_norm': 3.2702929973602295, 'learning_rate': 7.536991842073829e-07, 'num_tokens': 5207130.0, 'mean_token_accuracy': 0.7156467661261559, 'epoch': 0.6}
 60%|██████    | 870/1449 [5:25:38<3:27:36, 21.51s/it] 60%|██████    | 871/1449 [5:25:59<3:27:42, 21.56s/it]                                                      {'loss': 0.9916, 'grad_norm': 3.801851272583008, 'learning_rate': 7.514870294094109e-07, 'num_tokens': 5212387.0, 'mean_token_accuracy': 0.7254361473023891, 'epoch': 0.6}
 60%|██████    | 871/1449 [5:25:59<3:27:42, 21.56s/it] 60%|██████    | 872/1449 [5:26:21<3:27:15, 21.55s/it]                                                      {'loss': 1.0619, 'grad_norm': 3.514671802520752, 'learning_rate': 7.492761700348746e-07, 'num_tokens': 5218293.0, 'mean_token_accuracy': 0.7027498967945576, 'epoch': 0.6}
 60%|██████    | 872/1449 [5:26:21<3:27:15, 21.55s/it] 60%|██████    | 873/1449 [5:26:42<3:26:44, 21.54s/it]                                                      {'loss': 1.031, 'grad_norm': 3.8006248474121094, 'learning_rate': 7.470666176083191e-07, 'num_tokens': 5224151.0, 'mean_token_accuracy': 0.7178756222128868, 'epoch': 0.6}
 60%|██████    | 873/1449 [5:26:42<3:26:44, 21.54s/it] 60%|██████    | 874/1449 [5:27:04<3:26:19, 21.53s/it]                                                      {'loss': 1.14, 'grad_norm': 3.517354965209961, 'learning_rate': 7.448583836474781e-07, 'num_tokens': 5230063.0, 'mean_token_accuracy': 0.694267887622118, 'epoch': 0.6}
 60%|██████    | 874/1449 [5:27:04<3:26:19, 21.53s/it] 60%|██████    | 875/1449 [5:27:26<3:25:54, 21.52s/it]                                                      {'loss': 0.9495, 'grad_norm': 3.7306692600250244, 'learning_rate': 7.426514796632107e-07, 'num_tokens': 5235611.0, 'mean_token_accuracy': 0.7219914719462395, 'epoch': 0.6}
 60%|██████    | 875/1449 [5:27:26<3:25:54, 21.52s/it] 60%|██████    | 876/1449 [5:27:47<3:25:29, 21.52s/it]                                                      {'loss': 1.0397, 'grad_norm': 3.980858325958252, 'learning_rate': 7.404459171594448e-07, 'num_tokens': 5241299.0, 'mean_token_accuracy': 0.717892974615097, 'epoch': 0.6}
 60%|██████    | 876/1449 [5:27:47<3:25:29, 21.52s/it] 61%|██████    | 877/1449 [5:28:09<3:25:37, 21.57s/it]                                                      {'loss': 1.1124, 'grad_norm': 3.4319252967834473, 'learning_rate': 7.382417076331146e-07, 'num_tokens': 5246848.0, 'mean_token_accuracy': 0.6966452859342098, 'epoch': 0.6}
 61%|██████    | 877/1449 [5:28:09<3:25:37, 21.57s/it] 61%|██████    | 878/1449 [5:28:30<3:25:08, 21.56s/it]                                                      {'loss': 0.9599, 'grad_norm': 3.511636734008789, 'learning_rate': 7.360388625741024e-07, 'num_tokens': 5252755.0, 'mean_token_accuracy': 0.7311005033552647, 'epoch': 0.61}
 61%|██████    | 878/1449 [5:28:30<3:25:08, 21.56s/it] 61%|██████    | 879/1449 [5:28:52<3:24:41, 21.55s/it]                                                      {'loss': 0.9713, 'grad_norm': 3.2703685760498047, 'learning_rate': 7.338373934651768e-07, 'num_tokens': 5259021.0, 'mean_token_accuracy': 0.7303823567926884, 'epoch': 0.61}
 61%|██████    | 879/1449 [5:28:52<3:24:41, 21.55s/it] 61%|██████    | 880/1449 [5:29:14<3:26:02, 21.73s/it]                                                      {'loss': 1.0433, 'grad_norm': 3.3937315940856934, 'learning_rate': 7.316373117819355e-07, 'num_tokens': 5265127.0, 'mean_token_accuracy': 0.713333249092102, 'epoch': 0.61}
 61%|██████    | 880/1449 [5:29:14<3:26:02, 21.73s/it] 61%|██████    | 881/1449 [5:29:35<3:25:04, 21.66s/it]                                                      {'loss': 1.0401, 'grad_norm': 3.6873066425323486, 'learning_rate': 7.294386289927424e-07, 'num_tokens': 5270644.0, 'mean_token_accuracy': 0.7119240164756775, 'epoch': 0.61}
 61%|██████    | 881/1449 [5:29:35<3:25:04, 21.66s/it] 61%|██████    | 882/1449 [5:29:57<3:24:47, 21.67s/it]                                                      {'loss': 0.9498, 'grad_norm': 2.8145275115966797, 'learning_rate': 7.27241356558671e-07, 'num_tokens': 5277291.0, 'mean_token_accuracy': 0.728447150439024, 'epoch': 0.61}
 61%|██████    | 882/1449 [5:29:57<3:24:47, 21.67s/it] 61%|██████    | 883/1449 [5:30:19<3:24:03, 21.63s/it]                                                      {'loss': 1.0157, 'grad_norm': 3.5856783390045166, 'learning_rate': 7.250455059334417e-07, 'num_tokens': 5283099.0, 'mean_token_accuracy': 0.7162979170680046, 'epoch': 0.61}
 61%|██████    | 883/1449 [5:30:19<3:24:03, 21.63s/it] 61%|██████    | 884/1449 [5:30:40<3:23:17, 21.59s/it]                                                      {'loss': 1.0145, 'grad_norm': 3.240548610687256, 'learning_rate': 7.228510885633641e-07, 'num_tokens': 5289355.0, 'mean_token_accuracy': 0.7055910266935825, 'epoch': 0.61}
 61%|██████    | 884/1449 [5:30:40<3:23:17, 21.59s/it] 61%|██████    | 885/1449 [5:31:02<3:22:47, 21.57s/it]                                                      {'loss': 1.052, 'grad_norm': 3.6090035438537598, 'learning_rate': 7.206581158872759e-07, 'num_tokens': 5295810.0, 'mean_token_accuracy': 0.7120331227779388, 'epoch': 0.61}
 61%|██████    | 885/1449 [5:31:02<3:22:47, 21.57s/it] 61%|██████    | 886/1449 [5:31:23<3:22:16, 21.56s/it]                                                      {'loss': 1.1841, 'grad_norm': 3.464000940322876, 'learning_rate': 7.184665993364857e-07, 'num_tokens': 5301137.0, 'mean_token_accuracy': 0.677845910191536, 'epoch': 0.61}
 61%|██████    | 886/1449 [5:31:23<3:22:16, 21.56s/it] 61%|██████    | 887/1449 [5:31:45<3:22:15, 21.59s/it]                                                      {'loss': 0.9896, 'grad_norm': 3.562060832977295, 'learning_rate': 7.162765503347097e-07, 'num_tokens': 5306618.0, 'mean_token_accuracy': 0.7265640236437321, 'epoch': 0.61}
 61%|██████    | 887/1449 [5:31:45<3:22:15, 21.59s/it] 61%|██████▏   | 888/1449 [5:32:06<3:21:36, 21.56s/it]                                                      {'loss': 1.1259, 'grad_norm': 3.300363779067993, 'learning_rate': 7.140879802980162e-07, 'num_tokens': 5313371.0, 'mean_token_accuracy': 0.6970806829631329, 'epoch': 0.61}
 61%|██████▏   | 888/1449 [5:32:06<3:21:36, 21.56s/it] 61%|██████▏   | 889/1449 [5:32:28<3:21:07, 21.55s/it]                                                      {'loss': 1.0737, 'grad_norm': 3.3550713062286377, 'learning_rate': 7.119009006347624e-07, 'num_tokens': 5320052.0, 'mean_token_accuracy': 0.6997292041778564, 'epoch': 0.61}
 61%|██████▏   | 889/1449 [5:32:28<3:21:07, 21.55s/it] 61%|██████▏   | 890/1449 [5:32:49<3:20:39, 21.54s/it]                                                      {'loss': 1.1243, 'grad_norm': 4.245448589324951, 'learning_rate': 7.097153227455378e-07, 'num_tokens': 5324970.0, 'mean_token_accuracy': 0.6958612091839314, 'epoch': 0.61}
 61%|██████▏   | 890/1449 [5:32:49<3:20:39, 21.54s/it] 61%|██████▏   | 891/1449 [5:33:11<3:20:12, 21.53s/it]                                                      {'loss': 1.0095, 'grad_norm': 3.4977805614471436, 'learning_rate': 7.075312580231026e-07, 'num_tokens': 5331998.0, 'mean_token_accuracy': 0.7184108085930347, 'epoch': 0.61}
 61%|██████▏   | 891/1449 [5:33:11<3:20:12, 21.53s/it] 62%|██████▏   | 892/1449 [5:33:32<3:19:42, 21.51s/it]                                                      {'loss': 0.884, 'grad_norm': 3.5334508419036865, 'learning_rate': 7.053487178523303e-07, 'num_tokens': 5338158.0, 'mean_token_accuracy': 0.7403943948447704, 'epoch': 0.62}
 62%|██████▏   | 892/1449 [5:33:32<3:19:42, 21.51s/it] 62%|██████▏   | 893/1449 [5:33:54<3:19:50, 21.57s/it]                                                      {'loss': 1.0671, 'grad_norm': 3.43699049949646, 'learning_rate': 7.03167713610147e-07, 'num_tokens': 5344083.0, 'mean_token_accuracy': 0.7090213671326637, 'epoch': 0.62}
 62%|██████▏   | 893/1449 [5:33:54<3:19:50, 21.57s/it] 62%|██████▏   | 894/1449 [5:34:16<3:19:18, 21.55s/it]                                                      {'loss': 1.0258, 'grad_norm': 3.3554282188415527, 'learning_rate': 7.009882566654719e-07, 'num_tokens': 5349769.0, 'mean_token_accuracy': 0.7179202325642109, 'epoch': 0.62}
 62%|██████▏   | 894/1449 [5:34:16<3:19:18, 21.55s/it] 62%|██████▏   | 895/1449 [5:34:37<3:18:54, 21.54s/it]                                                      {'loss': 0.979, 'grad_norm': 3.0134477615356445, 'learning_rate': 6.988103583791599e-07, 'num_tokens': 5356809.0, 'mean_token_accuracy': 0.7292562164366245, 'epoch': 0.62}
 62%|██████▏   | 895/1449 [5:34:37<3:18:54, 21.54s/it] 62%|██████▏   | 896/1449 [5:34:59<3:18:27, 21.53s/it]                                                      {'loss': 0.9985, 'grad_norm': 3.724482774734497, 'learning_rate': 6.966340301039393e-07, 'num_tokens': 5362416.0, 'mean_token_accuracy': 0.7186233215034008, 'epoch': 0.62}
 62%|██████▏   | 896/1449 [5:34:59<3:18:27, 21.53s/it] 62%|██████▏   | 897/1449 [5:35:20<3:18:04, 21.53s/it]                                                      {'loss': 1.0153, 'grad_norm': 3.184234380722046, 'learning_rate': 6.944592831843565e-07, 'num_tokens': 5368621.0, 'mean_token_accuracy': 0.7155909910798073, 'epoch': 0.62}
 62%|██████▏   | 897/1449 [5:35:20<3:18:04, 21.53s/it] 62%|██████▏   | 898/1449 [5:35:42<3:18:07, 21.58s/it]                                                      {'loss': 0.9861, 'grad_norm': 3.5715572834014893, 'learning_rate': 6.922861289567128e-07, 'num_tokens': 5374931.0, 'mean_token_accuracy': 0.7214839048683643, 'epoch': 0.62}
 62%|██████▏   | 898/1449 [5:35:42<3:18:07, 21.58s/it] 62%|██████▏   | 899/1449 [5:36:03<3:17:35, 21.56s/it]                                                      {'loss': 1.1191, 'grad_norm': 3.868975877761841, 'learning_rate': 6.901145787490087e-07, 'num_tokens': 5380604.0, 'mean_token_accuracy': 0.6883001625537872, 'epoch': 0.62}
 62%|██████▏   | 899/1449 [5:36:03<3:17:35, 21.56s/it] 62%|██████▏   | 900/1449 [5:36:25<3:17:05, 21.54s/it]                                                      {'loss': 1.0069, 'grad_norm': 3.6244566440582275, 'learning_rate': 6.879446438808821e-07, 'num_tokens': 5386002.0, 'mean_token_accuracy': 0.7222384735941887, 'epoch': 0.62}
 62%|██████▏   | 900/1449 [5:36:25<3:17:05, 21.54s/it][INFO|trainer.py:3966] 2025-06-06 05:45:51,185 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900
[INFO|configuration_utils.py:423] 2025-06-06 05:45:51,190 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/config.json
[INFO|configuration_utils.py:908] 2025-06-06 05:45:51,192 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 05:45:58,069 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 05:45:58,074 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 05:45:58,076 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/special_tokens_map.json
[2025-06-06 05:45:58,271] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step900 is about to be saved!
[2025-06-06 05:45:58,277] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/global_step900/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 05:45:58,278] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/global_step900/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 05:45:58,292] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/global_step900/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 05:45:58,293] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/global_step900/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 05:46:21,357] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/global_step900/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 05:46:21,361] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-900/global_step900/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 05:46:21,796] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step900 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 05:46:33,341 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 05:46:33,343 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 62%|██████▏   | 901/1449 [5:37:31<5:18:27, 34.87s/it]                                                      {'loss': 1.0828, 'grad_norm': 3.7254772186279297, 'learning_rate': 6.857763356635525e-07, 'num_tokens': 5391871.0, 'mean_token_accuracy': 0.6974237412214279, 'epoch': 0.62}
 62%|██████▏   | 901/1449 [5:37:31<5:18:27, 34.87s/it] 62%|██████▏   | 902/1449 [5:37:53<4:42:52, 31.03s/it]                                                      {'loss': 1.0424, 'grad_norm': 3.243394374847412, 'learning_rate': 6.836096653997579e-07, 'num_tokens': 5397723.0, 'mean_token_accuracy': 0.6934651993215084, 'epoch': 0.62}
 62%|██████▏   | 902/1449 [5:37:53<4:42:52, 31.03s/it] 62%|██████▏   | 903/1449 [5:38:14<4:16:36, 28.20s/it]                                                      {'loss': 1.3293, 'grad_norm': 3.572274923324585, 'learning_rate': 6.814446443837001e-07, 'num_tokens': 5403928.0, 'mean_token_accuracy': 0.6646565049886703, 'epoch': 0.62}
 62%|██████▏   | 903/1449 [5:38:14<4:16:36, 28.20s/it] 62%|██████▏   | 904/1449 [5:38:36<3:58:42, 26.28s/it]                                                      {'loss': 1.0748, 'grad_norm': 3.4074103832244873, 'learning_rate': 6.792812839009827e-07, 'num_tokens': 5409714.0, 'mean_token_accuracy': 0.7045865803956985, 'epoch': 0.62}
 62%|██████▏   | 904/1449 [5:38:36<3:58:42, 26.28s/it] 62%|██████▏   | 905/1449 [5:38:58<3:45:04, 24.82s/it]                                                      {'loss': 0.9827, 'grad_norm': 3.1745293140411377, 'learning_rate': 6.77119595228554e-07, 'num_tokens': 5415848.0, 'mean_token_accuracy': 0.729170523583889, 'epoch': 0.62}
 62%|██████▏   | 905/1449 [5:38:58<3:45:04, 24.82s/it] 63%|██████▎   | 906/1449 [5:39:19<3:36:19, 23.90s/it]                                                      {'loss': 1.0935, 'grad_norm': 3.712427854537964, 'learning_rate': 6.749595896346469e-07, 'num_tokens': 5421017.0, 'mean_token_accuracy': 0.7037299200892448, 'epoch': 0.62}
 63%|██████▎   | 906/1449 [5:39:19<3:36:19, 23.90s/it] 63%|██████▎   | 907/1449 [5:39:41<3:30:06, 23.26s/it]                                                      {'loss': 1.0653, 'grad_norm': 3.840571880340576, 'learning_rate': 6.728012783787223e-07, 'num_tokens': 5426681.0, 'mean_token_accuracy': 0.7125856541097164, 'epoch': 0.63}
 63%|██████▎   | 907/1449 [5:39:41<3:30:06, 23.26s/it] 63%|██████▎   | 908/1449 [5:40:03<3:24:49, 22.72s/it]                                                      {'loss': 0.9858, 'grad_norm': 3.523499011993408, 'learning_rate': 6.706446727114074e-07, 'num_tokens': 5432997.0, 'mean_token_accuracy': 0.7272432632744312, 'epoch': 0.63}
 63%|██████▎   | 908/1449 [5:40:03<3:24:49, 22.72s/it] 63%|██████▎   | 909/1449 [5:40:24<3:22:05, 22.45s/it]                                                      {'loss': 1.0154, 'grad_norm': 2.835174083709717, 'learning_rate': 6.684897838744402e-07, 'num_tokens': 5440555.0, 'mean_token_accuracy': 0.7244457714259624, 'epoch': 0.63}
 63%|██████▎   | 909/1449 [5:40:24<3:22:05, 22.45s/it] 63%|██████▎   | 910/1449 [5:40:46<3:20:17, 22.30s/it]                                                      {'loss': 1.1313, 'grad_norm': 4.201659202575684, 'learning_rate': 6.663366231006081e-07, 'num_tokens': 5446085.0, 'mean_token_accuracy': 0.6906962096691132, 'epoch': 0.63}
 63%|██████▎   | 910/1449 [5:40:46<3:20:17, 22.30s/it] 63%|██████▎   | 911/1449 [5:41:08<3:17:29, 22.03s/it]                                                      {'loss': 0.9639, 'grad_norm': 3.5109782218933105, 'learning_rate': 6.641852016136915e-07, 'num_tokens': 5452297.0, 'mean_token_accuracy': 0.728106003254652, 'epoch': 0.63}
 63%|██████▎   | 911/1449 [5:41:08<3:17:29, 22.03s/it] 63%|██████▎   | 912/1449 [5:41:30<3:17:12, 22.03s/it]                                                      {'loss': 0.9772, 'grad_norm': 3.014021635055542, 'learning_rate': 6.620355306284036e-07, 'num_tokens': 5458763.0, 'mean_token_accuracy': 0.7277221195399761, 'epoch': 0.63}
 63%|██████▎   | 912/1449 [5:41:30<3:17:12, 22.03s/it] 63%|██████▎   | 913/1449 [5:41:52<3:16:07, 21.96s/it]                                                      {'loss': 1.0776, 'grad_norm': 3.575005531311035, 'learning_rate': 6.598876213503339e-07, 'num_tokens': 5465179.0, 'mean_token_accuracy': 0.7098912484943867, 'epoch': 0.63}
 63%|██████▎   | 913/1449 [5:41:52<3:16:07, 21.96s/it] 63%|██████▎   | 914/1449 [5:42:13<3:14:47, 21.85s/it]                                                      {'loss': 0.9528, 'grad_norm': 3.2096142768859863, 'learning_rate': 6.577414849758873e-07, 'num_tokens': 5472138.0, 'mean_token_accuracy': 0.7298728860914707, 'epoch': 0.63}
 63%|██████▎   | 914/1449 [5:42:13<3:14:47, 21.85s/it] 63%|██████▎   | 915/1449 [5:42:35<3:15:06, 21.92s/it]                                                      {'loss': 0.9312, 'grad_norm': 3.2900924682617188, 'learning_rate': 6.555971326922286e-07, 'num_tokens': 5478195.0, 'mean_token_accuracy': 0.7280156686902046, 'epoch': 0.63}
 63%|██████▎   | 915/1449 [5:42:35<3:15:06, 21.92s/it] 63%|██████▎   | 916/1449 [5:42:57<3:14:01, 21.84s/it]                                                      {'loss': 0.9304, 'grad_norm': 2.8609302043914795, 'learning_rate': 6.534545756772212e-07, 'num_tokens': 5485115.0, 'mean_token_accuracy': 0.7446306683123112, 'epoch': 0.63}
 63%|██████▎   | 916/1449 [5:42:57<3:14:01, 21.84s/it] 63%|██████▎   | 917/1449 [5:43:19<3:13:39, 21.84s/it]                                                      {'loss': 1.0763, 'grad_norm': 3.6594016551971436, 'learning_rate': 6.513138250993714e-07, 'num_tokens': 5490699.0, 'mean_token_accuracy': 0.7042000070214272, 'epoch': 0.63}
 63%|██████▎   | 917/1449 [5:43:19<3:13:39, 21.84s/it] 63%|██████▎   | 918/1449 [5:43:41<3:13:04, 21.82s/it]                                                      {'loss': 1.0987, 'grad_norm': 3.7903449535369873, 'learning_rate': 6.491748921177682e-07, 'num_tokens': 5496339.0, 'mean_token_accuracy': 0.6970390751957893, 'epoch': 0.63}
 63%|██████▎   | 918/1449 [5:43:41<3:13:04, 21.82s/it] 63%|██████▎   | 919/1449 [5:44:02<3:12:32, 21.80s/it]                                                      {'loss': 1.165, 'grad_norm': 3.9461095333099365, 'learning_rate': 6.47037787882027e-07, 'num_tokens': 5502321.0, 'mean_token_accuracy': 0.6943311952054501, 'epoch': 0.63}
 63%|██████▎   | 919/1449 [5:44:02<3:12:32, 21.80s/it] 63%|██████▎   | 920/1449 [5:44:24<3:12:28, 21.83s/it]                                                      {'loss': 1.0759, 'grad_norm': 4.007108688354492, 'learning_rate': 6.449025235322292e-07, 'num_tokens': 5507751.0, 'mean_token_accuracy': 0.7026679925620556, 'epoch': 0.63}
 63%|██████▎   | 920/1449 [5:44:24<3:12:28, 21.83s/it] 64%|██████▎   | 921/1449 [5:44:46<3:12:16, 21.85s/it]                                                      {'loss': 1.0459, 'grad_norm': 3.184138298034668, 'learning_rate': 6.427691101988672e-07, 'num_tokens': 5514217.0, 'mean_token_accuracy': 0.711623914539814, 'epoch': 0.64}
 64%|██████▎   | 921/1449 [5:44:46<3:12:16, 21.85s/it] 64%|██████▎   | 922/1449 [5:45:08<3:11:10, 21.77s/it]                                                      {'loss': 0.9548, 'grad_norm': 3.737276315689087, 'learning_rate': 6.406375590027828e-07, 'num_tokens': 5519847.0, 'mean_token_accuracy': 0.7307113036513329, 'epoch': 0.64}
 64%|██████▎   | 922/1449 [5:45:08<3:11:10, 21.77s/it] 64%|██████▎   | 923/1449 [5:45:29<3:10:36, 21.74s/it]                                                      {'loss': 1.0961, 'grad_norm': 3.7255702018737793, 'learning_rate': 6.385078810551123e-07, 'num_tokens': 5524651.0, 'mean_token_accuracy': 0.7036696411669254, 'epoch': 0.64}
 64%|██████▎   | 923/1449 [5:45:29<3:10:36, 21.74s/it] 64%|██████▍   | 924/1449 [5:45:51<3:11:09, 21.85s/it]                                                      {'loss': 1.0167, 'grad_norm': 3.2987725734710693, 'learning_rate': 6.363800874572265e-07, 'num_tokens': 5531209.0, 'mean_token_accuracy': 0.7223797775804996, 'epoch': 0.64}
 64%|██████▍   | 924/1449 [5:45:51<3:11:09, 21.85s/it] 64%|██████▍   | 925/1449 [5:46:13<3:09:38, 21.71s/it]                                                      {'loss': 1.132, 'grad_norm': 3.7018115520477295, 'learning_rate': 6.342541893006745e-07, 'num_tokens': 5537140.0, 'mean_token_accuracy': 0.6976920440793037, 'epoch': 0.64}
 64%|██████▍   | 925/1449 [5:46:13<3:09:38, 21.71s/it] 64%|██████▍   | 926/1449 [5:46:35<3:10:21, 21.84s/it]                                                      {'loss': 1.1041, 'grad_norm': 3.4369468688964844, 'learning_rate': 6.321301976671237e-07, 'num_tokens': 5542763.0, 'mean_token_accuracy': 0.6884878501296043, 'epoch': 0.64}
 64%|██████▍   | 926/1449 [5:46:35<3:10:21, 21.84s/it] 64%|██████▍   | 927/1449 [5:46:57<3:10:19, 21.88s/it]                                                      {'loss': 1.0955, 'grad_norm': 3.878023147583008, 'learning_rate': 6.300081236283053e-07, 'num_tokens': 5548481.0, 'mean_token_accuracy': 0.7026113569736481, 'epoch': 0.64}
 64%|██████▍   | 927/1449 [5:46:57<3:10:19, 21.88s/it] 64%|██████▍   | 928/1449 [5:47:19<3:09:05, 21.78s/it]                                                      {'loss': 0.9745, 'grad_norm': 3.047449827194214, 'learning_rate': 6.278879782459524e-07, 'num_tokens': 5555198.0, 'mean_token_accuracy': 0.7326638400554657, 'epoch': 0.64}
 64%|██████▍   | 928/1449 [5:47:19<3:09:05, 21.78s/it] 64%|██████▍   | 929/1449 [5:47:40<3:08:59, 21.81s/it]                                                      {'loss': 1.0155, 'grad_norm': 3.928379535675049, 'learning_rate': 6.257697725717468e-07, 'num_tokens': 5560175.0, 'mean_token_accuracy': 0.7126304693520069, 'epoch': 0.64}
 64%|██████▍   | 929/1449 [5:47:40<3:08:59, 21.81s/it] 64%|██████▍   | 930/1449 [5:48:02<3:08:50, 21.83s/it]                                                      {'loss': 1.0744, 'grad_norm': 3.5878217220306396, 'learning_rate': 6.236535176472575e-07, 'num_tokens': 5566283.0, 'mean_token_accuracy': 0.710814081132412, 'epoch': 0.64}
 64%|██████▍   | 930/1449 [5:48:02<3:08:50, 21.83s/it] 64%|██████▍   | 931/1449 [5:48:24<3:07:58, 21.77s/it]                                                      {'loss': 0.917, 'grad_norm': 3.585986375808716, 'learning_rate': 6.21539224503886e-07, 'num_tokens': 5571888.0, 'mean_token_accuracy': 0.7345751076936722, 'epoch': 0.64}
 64%|██████▍   | 931/1449 [5:48:24<3:07:58, 21.77s/it] 64%|██████▍   | 932/1449 [5:48:46<3:07:54, 21.81s/it]                                                      {'loss': 1.0417, 'grad_norm': 4.006794452667236, 'learning_rate': 6.194269041628062e-07, 'num_tokens': 5577518.0, 'mean_token_accuracy': 0.7071143463253975, 'epoch': 0.64}
 64%|██████▍   | 932/1449 [5:48:46<3:07:54, 21.81s/it] 64%|██████▍   | 933/1449 [5:49:07<3:06:55, 21.74s/it]                                                      {'loss': 1.0403, 'grad_norm': 3.520940065383911, 'learning_rate': 6.173165676349102e-07, 'num_tokens': 5582792.0, 'mean_token_accuracy': 0.7069974057376385, 'epoch': 0.64}
 64%|██████▍   | 933/1449 [5:49:07<3:06:55, 21.74s/it] 64%|██████▍   | 934/1449 [5:49:29<3:07:06, 21.80s/it]                                                      {'loss': 1.0605, 'grad_norm': 3.3321456909179688, 'learning_rate': 6.152082259207479e-07, 'num_tokens': 5588467.0, 'mean_token_accuracy': 0.7064742632210255, 'epoch': 0.64}
 64%|██████▍   | 934/1449 [5:49:29<3:07:06, 21.80s/it] 65%|██████▍   | 935/1449 [5:49:51<3:06:57, 21.82s/it]                                                      {'loss': 0.9992, 'grad_norm': 3.6141011714935303, 'learning_rate': 6.131018900104706e-07, 'num_tokens': 5594090.0, 'mean_token_accuracy': 0.7222415916621685, 'epoch': 0.64}
 65%|██████▍   | 935/1449 [5:49:51<3:06:57, 21.82s/it] 65%|██████▍   | 936/1449 [5:50:13<3:05:54, 21.74s/it]                                                      {'loss': 1.0099, 'grad_norm': 3.5394134521484375, 'learning_rate': 6.109975708837752e-07, 'num_tokens': 5600225.0, 'mean_token_accuracy': 0.7198272719979286, 'epoch': 0.65}
 65%|██████▍   | 936/1449 [5:50:13<3:05:54, 21.74s/it] 65%|██████▍   | 937/1449 [5:50:35<3:06:21, 21.84s/it]                                                      {'loss': 1.04, 'grad_norm': 3.4938647747039795, 'learning_rate': 6.088952795098441e-07, 'num_tokens': 5606214.0, 'mean_token_accuracy': 0.7017294354736805, 'epoch': 0.65}
 65%|██████▍   | 937/1449 [5:50:35<3:06:21, 21.84s/it] 65%|██████▍   | 938/1449 [5:50:57<3:05:44, 21.81s/it]                                                      {'loss': 0.9323, 'grad_norm': 3.3604915142059326, 'learning_rate': 6.067950268472912e-07, 'num_tokens': 5611604.0, 'mean_token_accuracy': 0.7251953445374966, 'epoch': 0.65}
 65%|██████▍   | 938/1449 [5:50:57<3:05:44, 21.81s/it] 65%|██████▍   | 939/1449 [5:51:18<3:05:16, 21.80s/it]                                                      {'loss': 1.082, 'grad_norm': 3.541837453842163, 'learning_rate': 6.046968238441019e-07, 'num_tokens': 5617584.0, 'mean_token_accuracy': 0.7050667330622673, 'epoch': 0.65}
 65%|██████▍   | 939/1449 [5:51:18<3:05:16, 21.80s/it] 65%|██████▍   | 940/1449 [5:51:40<3:04:42, 21.77s/it]                                                      {'loss': 0.9028, 'grad_norm': 4.182946681976318, 'learning_rate': 6.026006814375786e-07, 'num_tokens': 5623049.0, 'mean_token_accuracy': 0.7411306351423264, 'epoch': 0.65}
 65%|██████▍   | 940/1449 [5:51:40<3:04:42, 21.77s/it] 65%|██████▍   | 941/1449 [5:52:02<3:04:40, 21.81s/it]                                                      {'loss': 0.9927, 'grad_norm': 3.606173276901245, 'learning_rate': 6.005066105542808e-07, 'num_tokens': 5628916.0, 'mean_token_accuracy': 0.7304500676691532, 'epoch': 0.65}
 65%|██████▍   | 941/1449 [5:52:02<3:04:40, 21.81s/it] 65%|██████▌   | 942/1449 [5:52:24<3:04:09, 21.79s/it]                                                      {'loss': 1.0467, 'grad_norm': 3.5651614665985107, 'learning_rate': 5.984146221099719e-07, 'num_tokens': 5635016.0, 'mean_token_accuracy': 0.693960003554821, 'epoch': 0.65}
 65%|██████▌   | 942/1449 [5:52:24<3:04:09, 21.79s/it] 65%|██████▌   | 943/1449 [5:52:45<3:03:21, 21.74s/it]                                                      {'loss': 0.9565, 'grad_norm': 3.4775593280792236, 'learning_rate': 5.963247270095584e-07, 'num_tokens': 5641090.0, 'mean_token_accuracy': 0.7315143123269081, 'epoch': 0.65}
 65%|██████▌   | 943/1449 [5:52:45<3:03:21, 21.74s/it] 65%|██████▌   | 944/1449 [5:53:07<3:03:36, 21.81s/it]                                                      {'loss': 1.0624, 'grad_norm': 3.904428482055664, 'learning_rate': 5.942369361470354e-07, 'num_tokens': 5646562.0, 'mean_token_accuracy': 0.7133014425635338, 'epoch': 0.65}
 65%|██████▌   | 944/1449 [5:53:07<3:03:36, 21.81s/it] 65%|██████▌   | 945/1449 [5:53:29<3:01:55, 21.66s/it]                                                      {'loss': 1.0709, 'grad_norm': 3.729384660720825, 'learning_rate': 5.921512604054289e-07, 'num_tokens': 5652476.0, 'mean_token_accuracy': 0.706474244594574, 'epoch': 0.65}
 65%|██████▌   | 945/1449 [5:53:29<3:01:55, 21.66s/it] 65%|██████▌   | 946/1449 [5:53:51<3:02:23, 21.76s/it]                                                      {'loss': 1.077, 'grad_norm': 3.4159584045410156, 'learning_rate': 5.900677106567407e-07, 'num_tokens': 5658220.0, 'mean_token_accuracy': 0.7034823186695576, 'epoch': 0.65}
 65%|██████▌   | 946/1449 [5:53:51<3:02:23, 21.76s/it] 65%|██████▌   | 947/1449 [5:54:12<3:01:13, 21.66s/it]                                                      {'loss': 0.9844, 'grad_norm': 3.355156421661377, 'learning_rate': 5.879862977618885e-07, 'num_tokens': 5664473.0, 'mean_token_accuracy': 0.7315087132155895, 'epoch': 0.65}
 65%|██████▌   | 947/1449 [5:54:12<3:01:13, 21.66s/it] 65%|██████▌   | 948/1449 [5:54:34<3:01:08, 21.69s/it]                                                      {'loss': 0.9726, 'grad_norm': 3.498133897781372, 'learning_rate': 5.859070325706533e-07, 'num_tokens': 5669884.0, 'mean_token_accuracy': 0.733025286346674, 'epoch': 0.65}
 65%|██████▌   | 948/1449 [5:54:34<3:01:08, 21.69s/it] 65%|██████▌   | 949/1449 [5:54:56<3:00:52, 21.70s/it]                                                      {'loss': 1.1112, 'grad_norm': 3.5068600177764893, 'learning_rate': 5.838299259216186e-07, 'num_tokens': 5676415.0, 'mean_token_accuracy': 0.7090375162661076, 'epoch': 0.65}
 65%|██████▌   | 949/1449 [5:54:56<3:00:52, 21.70s/it] 66%|██████▌   | 950/1449 [5:55:17<2:59:28, 21.58s/it]                                                      {'loss': 0.998, 'grad_norm': 3.2182936668395996, 'learning_rate': 5.817549886421183e-07, 'num_tokens': 5683206.0, 'mean_token_accuracy': 0.72128651663661, 'epoch': 0.66}
 66%|██████▌   | 950/1449 [5:55:17<2:59:28, 21.58s/it][INFO|trainer.py:3966] 2025-06-06 06:04:43,233 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950
[INFO|configuration_utils.py:423] 2025-06-06 06:04:43,239 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/config.json
[INFO|configuration_utils.py:908] 2025-06-06 06:04:43,241 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 06:04:50,270 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 06:04:50,274 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 06:04:50,276 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/special_tokens_map.json
[2025-06-06 06:04:50,474] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step950 is about to be saved!
[2025-06-06 06:04:50,481] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/global_step950/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 06:04:50,481] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/global_step950/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 06:04:50,495] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/global_step950/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 06:04:50,496] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/global_step950/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 06:05:12,011] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/global_step950/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 06:05:12,018] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-950/global_step950/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 06:05:12,892] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step950 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 06:05:23,975 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 06:05:23,977 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 66%|██████▌   | 951/1449 [5:56:21<4:45:09, 34.36s/it]                                                      {'loss': 0.9858, 'grad_norm': 3.644831895828247, 'learning_rate': 5.796822315481757e-07, 'num_tokens': 5688870.0, 'mean_token_accuracy': 0.7252893671393394, 'epoch': 0.66}
 66%|██████▌   | 951/1449 [5:56:21<4:45:09, 34.36s/it] 66%|██████▌   | 952/1449 [5:56:43<4:13:21, 30.59s/it]                                                      {'loss': 1.0426, 'grad_norm': 4.078766822814941, 'learning_rate': 5.776116654444518e-07, 'num_tokens': 5694259.0, 'mean_token_accuracy': 0.712343767285347, 'epoch': 0.66}
 66%|██████▌   | 952/1449 [5:56:43<4:13:21, 30.59s/it] 66%|██████▌   | 953/1449 [5:57:05<3:51:34, 28.01s/it]                                                      {'loss': 1.0953, 'grad_norm': 4.0655903816223145, 'learning_rate': 5.755433011241851e-07, 'num_tokens': 5700249.0, 'mean_token_accuracy': 0.7114071920514107, 'epoch': 0.66}
 66%|██████▌   | 953/1449 [5:57:05<3:51:34, 28.01s/it] 66%|██████▌   | 954/1449 [5:57:27<3:35:40, 26.14s/it]                                                      {'loss': 1.0708, 'grad_norm': 3.5777461528778076, 'learning_rate': 5.73477149369137e-07, 'num_tokens': 5706342.0, 'mean_token_accuracy': 0.7016364969313145, 'epoch': 0.66}
 66%|██████▌   | 954/1449 [5:57:27<3:35:40, 26.14s/it] 66%|██████▌   | 955/1449 [5:57:48<3:23:35, 24.73s/it]                                                      {'loss': 1.0137, 'grad_norm': 3.968315601348877, 'learning_rate': 5.714132209495354e-07, 'num_tokens': 5712631.0, 'mean_token_accuracy': 0.7024688869714737, 'epoch': 0.66}
 66%|██████▌   | 955/1449 [5:57:48<3:23:35, 24.73s/it] 66%|██████▌   | 956/1449 [5:58:10<3:16:21, 23.90s/it]                                                      {'loss': 1.0619, 'grad_norm': 4.076403617858887, 'learning_rate': 5.693515266240197e-07, 'num_tokens': 5717932.0, 'mean_token_accuracy': 0.7196700312197208, 'epoch': 0.66}
 66%|██████▌   | 956/1449 [5:58:10<3:16:21, 23.90s/it] 66%|██████▌   | 957/1449 [5:58:32<3:10:32, 23.24s/it]                                                      {'loss': 1.0443, 'grad_norm': 3.1150217056274414, 'learning_rate': 5.672920771395821e-07, 'num_tokens': 5724712.0, 'mean_token_accuracy': 0.7189685627818108, 'epoch': 0.66}
 66%|██████▌   | 957/1449 [5:58:32<3:10:32, 23.24s/it] 66%|██████▌   | 958/1449 [5:58:53<3:06:25, 22.78s/it]                                                      {'loss': 1.0241, 'grad_norm': 3.830190896987915, 'learning_rate': 5.652348832315148e-07, 'num_tokens': 5730100.0, 'mean_token_accuracy': 0.7108799815177917, 'epoch': 0.66}
 66%|██████▌   | 958/1449 [5:58:53<3:06:25, 22.78s/it] 66%|██████▌   | 959/1449 [5:59:15<3:04:08, 22.55s/it]                                                      {'loss': 1.1877, 'grad_norm': 3.128606081008911, 'learning_rate': 5.631799556233505e-07, 'num_tokens': 5736855.0, 'mean_token_accuracy': 0.6913596838712692, 'epoch': 0.66}
 66%|██████▌   | 959/1449 [5:59:15<3:04:08, 22.55s/it] 66%|██████▋   | 960/1449 [5:59:37<3:01:33, 22.28s/it]                                                      {'loss': 1.0771, 'grad_norm': 3.216766595840454, 'learning_rate': 5.611273050268099e-07, 'num_tokens': 5743386.0, 'mean_token_accuracy': 0.7014980241656303, 'epoch': 0.66}
 66%|██████▋   | 960/1449 [5:59:37<3:01:33, 22.28s/it] 66%|██████▋   | 961/1449 [5:59:59<2:59:59, 22.13s/it]                                                      {'loss': 1.1583, 'grad_norm': 3.4499008655548096, 'learning_rate': 5.590769421417434e-07, 'num_tokens': 5748983.0, 'mean_token_accuracy': 0.6933249160647392, 'epoch': 0.66}
 66%|██████▋   | 961/1449 [5:59:59<2:59:59, 22.13s/it] 66%|██████▋   | 962/1449 [6:00:20<2:58:33, 22.00s/it]                                                      {'loss': 1.0849, 'grad_norm': 3.449991226196289, 'learning_rate': 5.57028877656077e-07, 'num_tokens': 5754850.0, 'mean_token_accuracy': 0.7077731713652611, 'epoch': 0.66}
 66%|██████▋   | 962/1449 [6:00:20<2:58:33, 22.00s/it] 66%|██████▋   | 963/1449 [6:00:43<2:58:18, 22.01s/it]                                                      {'loss': 0.9676, 'grad_norm': 3.4366519451141357, 'learning_rate': 5.549831222457548e-07, 'num_tokens': 5760409.0, 'mean_token_accuracy': 0.715414721518755, 'epoch': 0.66}
 66%|██████▋   | 963/1449 [6:00:43<2:58:18, 22.01s/it] 67%|██████▋   | 964/1449 [6:01:04<2:57:25, 21.95s/it]                                                      {'loss': 0.9554, 'grad_norm': 3.297855854034424, 'learning_rate': 5.529396865746856e-07, 'num_tokens': 5766548.0, 'mean_token_accuracy': 0.7258891984820366, 'epoch': 0.66}
 67%|██████▋   | 964/1449 [6:01:04<2:57:25, 21.95s/it] 67%|██████▋   | 965/1449 [6:01:26<2:56:28, 21.88s/it]                                                      {'loss': 0.9821, 'grad_norm': 3.845508098602295, 'learning_rate': 5.508985812946849e-07, 'num_tokens': 5771973.0, 'mean_token_accuracy': 0.7222661711275578, 'epoch': 0.67}
 67%|██████▋   | 965/1449 [6:01:26<2:56:28, 21.88s/it] 67%|██████▋   | 966/1449 [6:01:48<2:56:35, 21.94s/it]                                                      {'loss': 0.9493, 'grad_norm': 3.388132095336914, 'learning_rate': 5.488598170454217e-07, 'num_tokens': 5778798.0, 'mean_token_accuracy': 0.7354578301310539, 'epoch': 0.67}
 67%|██████▋   | 966/1449 [6:01:48<2:56:35, 21.94s/it] 67%|██████▋   | 967/1449 [6:02:10<2:55:04, 21.79s/it]                                                      {'loss': 1.1175, 'grad_norm': 3.5547571182250977, 'learning_rate': 5.468234044543614e-07, 'num_tokens': 5784569.0, 'mean_token_accuracy': 0.7041770704090595, 'epoch': 0.67}
 67%|██████▋   | 967/1449 [6:02:10<2:55:04, 21.79s/it] 67%|██████▋   | 968/1449 [6:02:32<2:55:13, 21.86s/it]                                                      {'loss': 0.9856, 'grad_norm': 3.869051694869995, 'learning_rate': 5.447893541367104e-07, 'num_tokens': 5790256.0, 'mean_token_accuracy': 0.7159852720797062, 'epoch': 0.67}
 67%|██████▋   | 968/1449 [6:02:32<2:55:13, 21.86s/it] 67%|██████▋   | 969/1449 [6:02:53<2:54:16, 21.78s/it]                                                      {'loss': 0.9472, 'grad_norm': 3.308603286743164, 'learning_rate': 5.427576766953614e-07, 'num_tokens': 5797097.0, 'mean_token_accuracy': 0.7273647785186768, 'epoch': 0.67}
 67%|██████▋   | 969/1449 [6:02:53<2:54:16, 21.78s/it] 67%|██████▋   | 970/1449 [6:03:15<2:54:10, 21.82s/it]                                                      {'loss': 1.0192, 'grad_norm': 3.789133310317993, 'learning_rate': 5.407283827208395e-07, 'num_tokens': 5803188.0, 'mean_token_accuracy': 0.7239384725689888, 'epoch': 0.67}
 67%|██████▋   | 970/1449 [6:03:15<2:54:10, 21.82s/it] 67%|██████▋   | 971/1449 [6:03:37<2:54:19, 21.88s/it]                                                      {'loss': 0.9303, 'grad_norm': 3.422144651412964, 'learning_rate': 5.387014827912433e-07, 'num_tokens': 5809297.0, 'mean_token_accuracy': 0.7336886823177338, 'epoch': 0.67}
 67%|██████▋   | 971/1449 [6:03:37<2:54:19, 21.88s/it] 67%|██████▋   | 972/1449 [6:03:59<2:52:49, 21.74s/it]                                                      {'loss': 1.0691, 'grad_norm': 4.109076023101807, 'learning_rate': 5.366769874721941e-07, 'num_tokens': 5815067.0, 'mean_token_accuracy': 0.7108262628316879, 'epoch': 0.67}
 67%|██████▋   | 972/1449 [6:03:59<2:52:49, 21.74s/it] 67%|██████▋   | 973/1449 [6:04:21<2:53:02, 21.81s/it]                                                      {'loss': 1.0988, 'grad_norm': 3.5406816005706787, 'learning_rate': 5.346549073167765e-07, 'num_tokens': 5820801.0, 'mean_token_accuracy': 0.7007119432091713, 'epoch': 0.67}
 67%|██████▋   | 973/1449 [6:04:21<2:53:02, 21.81s/it] 67%|██████▋   | 974/1449 [6:04:42<2:52:19, 21.77s/it]                                                      {'loss': 1.1195, 'grad_norm': 3.381645917892456, 'learning_rate': 5.326352528654877e-07, 'num_tokens': 5826803.0, 'mean_token_accuracy': 0.6788305453956127, 'epoch': 0.67}
 67%|██████▋   | 974/1449 [6:04:42<2:52:19, 21.77s/it] 67%|██████▋   | 975/1449 [6:05:04<2:51:54, 21.76s/it]                                                      {'loss': 1.1663, 'grad_norm': 3.364786386489868, 'learning_rate': 5.306180346461786e-07, 'num_tokens': 5833091.0, 'mean_token_accuracy': 0.694816030561924, 'epoch': 0.67}
 67%|██████▋   | 975/1449 [6:05:04<2:51:54, 21.76s/it] 67%|██████▋   | 976/1449 [6:05:26<2:52:06, 21.83s/it]                                                      {'loss': 0.9868, 'grad_norm': 3.763737440109253, 'learning_rate': 5.286032631740023e-07, 'num_tokens': 5839229.0, 'mean_token_accuracy': 0.7239932678639889, 'epoch': 0.67}
 67%|██████▋   | 976/1449 [6:05:26<2:52:06, 21.83s/it] 67%|██████▋   | 977/1449 [6:05:48<2:51:22, 21.79s/it]                                                      {'loss': 0.9719, 'grad_norm': 3.4771907329559326, 'learning_rate': 5.265909489513567e-07, 'num_tokens': 5845407.0, 'mean_token_accuracy': 0.7334368750452995, 'epoch': 0.67}
 67%|██████▋   | 977/1449 [6:05:48<2:51:22, 21.79s/it] 67%|██████▋   | 978/1449 [6:06:09<2:50:53, 21.77s/it]                                                      {'loss': 1.0159, 'grad_norm': 3.49328875541687, 'learning_rate': 5.245811024678308e-07, 'num_tokens': 5850940.0, 'mean_token_accuracy': 0.719349130988121, 'epoch': 0.67}
 67%|██████▋   | 978/1449 [6:06:09<2:50:53, 21.77s/it] 68%|██████▊   | 979/1449 [6:06:31<2:50:17, 21.74s/it]                                                      {'loss': 1.0361, 'grad_norm': 3.2721521854400635, 'learning_rate': 5.225737342001509e-07, 'num_tokens': 5857482.0, 'mean_token_accuracy': 0.7252333499491215, 'epoch': 0.68}
 68%|██████▊   | 979/1449 [6:06:31<2:50:17, 21.74s/it] 68%|██████▊   | 980/1449 [6:06:53<2:50:36, 21.83s/it]                                                      {'loss': 1.1418, 'grad_norm': 3.4991517066955566, 'learning_rate': 5.205688546121245e-07, 'num_tokens': 5863480.0, 'mean_token_accuracy': 0.6810578927397728, 'epoch': 0.68}
 68%|██████▊   | 980/1449 [6:06:53<2:50:36, 21.83s/it] 68%|██████▊   | 981/1449 [6:07:15<2:50:06, 21.81s/it]                                                      {'loss': 1.0056, 'grad_norm': 3.360532760620117, 'learning_rate': 5.185664741545861e-07, 'num_tokens': 5869246.0, 'mean_token_accuracy': 0.731757078319788, 'epoch': 0.68}
 68%|██████▊   | 981/1449 [6:07:15<2:50:06, 21.81s/it] 68%|██████▊   | 982/1449 [6:07:36<2:49:29, 21.78s/it]                                                      {'loss': 0.9813, 'grad_norm': 3.5988783836364746, 'learning_rate': 5.165666032653431e-07, 'num_tokens': 5874509.0, 'mean_token_accuracy': 0.7230642959475517, 'epoch': 0.68}
 68%|██████▊   | 982/1449 [6:07:36<2:49:29, 21.78s/it] 68%|██████▊   | 983/1449 [6:07:59<2:49:53, 21.87s/it]                                                      {'loss': 0.9611, 'grad_norm': 3.1960198879241943, 'learning_rate': 5.145692523691222e-07, 'num_tokens': 5881564.0, 'mean_token_accuracy': 0.7189679779112339, 'epoch': 0.68}
 68%|██████▊   | 983/1449 [6:07:59<2:49:53, 21.87s/it] 68%|██████▊   | 984/1449 [6:08:20<2:48:36, 21.76s/it]                                                      {'loss': 1.0535, 'grad_norm': 3.3468151092529297, 'learning_rate': 5.125744318775124e-07, 'num_tokens': 5887783.0, 'mean_token_accuracy': 0.7106473706662655, 'epoch': 0.68}
 68%|██████▊   | 984/1449 [6:08:20<2:48:36, 21.76s/it] 68%|██████▊   | 985/1449 [6:08:42<2:48:47, 21.83s/it]                                                      {'loss': 1.0569, 'grad_norm': 3.6449038982391357, 'learning_rate': 5.105821521889147e-07, 'num_tokens': 5893503.0, 'mean_token_accuracy': 0.7062726244330406, 'epoch': 0.68}
 68%|██████▊   | 985/1449 [6:08:42<2:48:47, 21.83s/it] 68%|██████▊   | 986/1449 [6:09:04<2:48:03, 21.78s/it]                                                      {'loss': 1.0255, 'grad_norm': 3.4250619411468506, 'learning_rate': 5.085924236884833e-07, 'num_tokens': 5899756.0, 'mean_token_accuracy': 0.7181635312736034, 'epoch': 0.68}
 68%|██████▊   | 986/1449 [6:09:04<2:48:03, 21.78s/it] 68%|██████▊   | 987/1449 [6:09:25<2:47:24, 21.74s/it]                                                      {'loss': 0.9332, 'grad_norm': 2.964202404022217, 'learning_rate': 5.066052567480758e-07, 'num_tokens': 5906194.0, 'mean_token_accuracy': 0.7296223863959312, 'epoch': 0.68}
 68%|██████▊   | 987/1449 [6:09:25<2:47:24, 21.74s/it] 68%|██████▊   | 988/1449 [6:09:47<2:47:35, 21.81s/it]                                                      {'loss': 1.1175, 'grad_norm': 3.484044075012207, 'learning_rate': 5.046206617261955e-07, 'num_tokens': 5912126.0, 'mean_token_accuracy': 0.70285265147686, 'epoch': 0.68}
 68%|██████▊   | 988/1449 [6:09:47<2:47:35, 21.81s/it] 68%|██████▊   | 989/1449 [6:10:09<2:46:19, 21.70s/it]                                                      {'loss': 0.9301, 'grad_norm': 3.161259174346924, 'learning_rate': 5.026386489679407e-07, 'num_tokens': 5918806.0, 'mean_token_accuracy': 0.7318845763802528, 'epoch': 0.68}
 68%|██████▊   | 989/1449 [6:10:09<2:46:19, 21.70s/it] 68%|██████▊   | 990/1449 [6:10:31<2:46:27, 21.76s/it]                                                      {'loss': 1.0404, 'grad_norm': 3.6553752422332764, 'learning_rate': 5.006592288049476e-07, 'num_tokens': 5924583.0, 'mean_token_accuracy': 0.716110460460186, 'epoch': 0.68}
 68%|██████▊   | 990/1449 [6:10:31<2:46:27, 21.76s/it] 68%|██████▊   | 991/1449 [6:10:53<2:46:24, 21.80s/it]                                                      {'loss': 1.2663, 'grad_norm': 3.757512092590332, 'learning_rate': 4.986824115553392e-07, 'num_tokens': 5930670.0, 'mean_token_accuracy': 0.675707995891571, 'epoch': 0.68}
 68%|██████▊   | 991/1449 [6:10:53<2:46:24, 21.80s/it] 68%|██████▊   | 992/1449 [6:11:14<2:44:54, 21.65s/it]                                                      {'loss': 0.9518, 'grad_norm': 3.443032741546631, 'learning_rate': 4.967082075236692e-07, 'num_tokens': 5936850.0, 'mean_token_accuracy': 0.7332442253828049, 'epoch': 0.68}
 68%|██████▊   | 992/1449 [6:11:14<2:44:54, 21.65s/it] 69%|██████▊   | 993/1449 [6:11:36<2:45:09, 21.73s/it]                                                      {'loss': 1.0916, 'grad_norm': 3.7008066177368164, 'learning_rate': 4.947366270008707e-07, 'num_tokens': 5942281.0, 'mean_token_accuracy': 0.6977130025625229, 'epoch': 0.68}
 69%|██████▊   | 993/1449 [6:11:36<2:45:09, 21.73s/it] 69%|██████▊   | 994/1449 [6:11:57<2:44:32, 21.70s/it]                                                      {'loss': 0.963, 'grad_norm': 3.8726704120635986, 'learning_rate': 4.927676802642e-07, 'num_tokens': 5948025.0, 'mean_token_accuracy': 0.7255582809448242, 'epoch': 0.69}
 69%|██████▊   | 994/1449 [6:11:57<2:44:32, 21.70s/it] 69%|██████▊   | 995/1449 [6:12:19<2:44:00, 21.68s/it]                                                      {'loss': 1.0498, 'grad_norm': 3.525128126144409, 'learning_rate': 4.908013775771849e-07, 'num_tokens': 5953693.0, 'mean_token_accuracy': 0.7054212465882301, 'epoch': 0.69}
 69%|██████▊   | 995/1449 [6:12:19<2:44:00, 21.68s/it] 69%|██████▊   | 996/1449 [6:12:41<2:43:48, 21.70s/it]                                                      {'loss': 0.9169, 'grad_norm': 3.392524480819702, 'learning_rate': 4.8883772918957e-07, 'num_tokens': 5960087.0, 'mean_token_accuracy': 0.735650148242712, 'epoch': 0.69}
 69%|██████▊   | 996/1449 [6:12:41<2:43:48, 21.70s/it] 69%|██████▉   | 997/1449 [6:13:02<2:43:22, 21.69s/it]                                                      {'loss': 1.0352, 'grad_norm': 3.2714269161224365, 'learning_rate': 4.868767453372649e-07, 'num_tokens': 5966326.0, 'mean_token_accuracy': 0.7198192626237869, 'epoch': 0.69}
 69%|██████▉   | 997/1449 [6:13:02<2:43:22, 21.69s/it] 69%|██████▉   | 998/1449 [6:13:24<2:43:06, 21.70s/it]                                                      {'loss': 1.0815, 'grad_norm': 3.074678421020508, 'learning_rate': 4.849184362422884e-07, 'num_tokens': 5972633.0, 'mean_token_accuracy': 0.7049673050642014, 'epoch': 0.69}
 69%|██████▉   | 998/1449 [6:13:24<2:43:06, 21.70s/it] 69%|██████▉   | 999/1449 [6:13:46<2:42:29, 21.67s/it]                                                      {'loss': 1.026, 'grad_norm': 3.650712013244629, 'learning_rate': 4.829628121127183e-07, 'num_tokens': 5978801.0, 'mean_token_accuracy': 0.7025434300303459, 'epoch': 0.69}
 69%|██████▉   | 999/1449 [6:13:46<2:42:29, 21.67s/it] 69%|██████▉   | 1000/1449 [6:14:07<2:42:04, 21.66s/it]                                                       {'loss': 1.1265, 'grad_norm': 3.4141974449157715, 'learning_rate': 4.810098831426346e-07, 'num_tokens': 5984440.0, 'mean_token_accuracy': 0.696241982281208, 'epoch': 0.69}
 69%|██████▉   | 1000/1449 [6:14:07<2:42:04, 21.66s/it][INFO|trainer.py:3966] 2025-06-06 06:23:33,876 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000
[INFO|configuration_utils.py:423] 2025-06-06 06:23:33,881 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/config.json
[INFO|configuration_utils.py:908] 2025-06-06 06:23:33,883 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 06:23:41,545 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 06:23:41,549 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 06:23:41,551 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/special_tokens_map.json
[2025-06-06 06:23:41,758] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step1000 is about to be saved!
[2025-06-06 06:23:41,764] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 06:23:41,764] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 06:23:41,779] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 06:23:41,780] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 06:24:03,326] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 06:24:03,331] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 06:24:03,592] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 06:24:14,451 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 06:24:14,453 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 69%|██████▉   | 1001/1449 [6:15:11<4:15:29, 34.22s/it]                                                       {'loss': 1.0822, 'grad_norm': 3.8145389556884766, 'learning_rate': 4.790596595120698e-07, 'num_tokens': 5989768.0, 'mean_token_accuracy': 0.6994358785450459, 'epoch': 0.69}
 69%|██████▉   | 1001/1449 [6:15:11<4:15:29, 34.22s/it] 69%|██████▉   | 1002/1449 [6:15:33<3:47:29, 30.54s/it]                                                       {'loss': 1.0432, 'grad_norm': 3.273563861846924, 'learning_rate': 4.771121513869529e-07, 'num_tokens': 5995911.0, 'mean_token_accuracy': 0.71052111312747, 'epoch': 0.69}
 69%|██████▉   | 1002/1449 [6:15:33<3:47:29, 30.54s/it] 69%|██████▉   | 1003/1449 [6:15:54<3:26:36, 27.79s/it]                                                       {'loss': 1.0897, 'grad_norm': 3.267622709274292, 'learning_rate': 4.751673689190595e-07, 'num_tokens': 6002031.0, 'mean_token_accuracy': 0.6908435821533203, 'epoch': 0.69}
 69%|██████▉   | 1003/1449 [6:15:54<3:26:36, 27.79s/it] 69%|██████▉   | 1004/1449 [6:16:16<3:12:46, 25.99s/it]                                                       {'loss': 1.0268, 'grad_norm': 4.061853408813477, 'learning_rate': 4.732253222459552e-07, 'num_tokens': 6007868.0, 'mean_token_accuracy': 0.7089186273515224, 'epoch': 0.69}
 69%|██████▉   | 1004/1449 [6:16:16<3:12:46, 25.99s/it] 69%|██████▉   | 1005/1449 [6:16:37<3:02:02, 24.60s/it]                                                       {'loss': 0.9313, 'grad_norm': 3.3119020462036133, 'learning_rate': 4.7128602149094654e-07, 'num_tokens': 6014302.0, 'mean_token_accuracy': 0.7266474850475788, 'epoch': 0.69}
 69%|██████▉   | 1005/1449 [6:16:37<3:02:02, 24.60s/it] 69%|██████▉   | 1006/1449 [6:16:59<2:55:31, 23.77s/it]                                                       {'loss': 1.187, 'grad_norm': 2.951084613800049, 'learning_rate': 4.693494767630252e-07, 'num_tokens': 6021392.0, 'mean_token_accuracy': 0.6925610899925232, 'epoch': 0.69}
 69%|██████▉   | 1006/1449 [6:16:59<2:55:31, 23.77s/it] 69%|██████▉   | 1007/1449 [6:17:21<2:49:55, 23.07s/it]                                                       {'loss': 1.1411, 'grad_norm': 3.8736846446990967, 'learning_rate': 4.674156981568168e-07, 'num_tokens': 6027637.0, 'mean_token_accuracy': 0.6906316168606281, 'epoch': 0.69}
 69%|██████▉   | 1007/1449 [6:17:21<2:49:55, 23.07s/it] 70%|██████▉   | 1008/1449 [6:17:42<2:45:56, 22.58s/it]                                                       {'loss': 1.0449, 'grad_norm': 3.5825791358947754, 'learning_rate': 4.654846957525279e-07, 'num_tokens': 6033110.0, 'mean_token_accuracy': 0.7060763388872147, 'epoch': 0.7}
 70%|██████▉   | 1008/1449 [6:17:42<2:45:56, 22.58s/it] 70%|██████▉   | 1009/1449 [6:18:04<2:43:30, 22.30s/it]                                                       {'loss': 1.0933, 'grad_norm': 3.094942331314087, 'learning_rate': 4.635564796158945e-07, 'num_tokens': 6039361.0, 'mean_token_accuracy': 0.7009414024651051, 'epoch': 0.7}
 70%|██████▉   | 1009/1449 [6:18:04<2:43:30, 22.30s/it] 70%|██████▉   | 1010/1449 [6:18:25<2:41:47, 22.11s/it]                                                       {'loss': 1.0285, 'grad_norm': 4.0609965324401855, 'learning_rate': 4.6163105979812687e-07, 'num_tokens': 6045013.0, 'mean_token_accuracy': 0.7197959572076797, 'epoch': 0.7}
 70%|██████▉   | 1010/1449 [6:18:25<2:41:47, 22.11s/it] 70%|██████▉   | 1011/1449 [6:18:47<2:39:57, 21.91s/it]                                                       {'loss': 1.0719, 'grad_norm': 3.3686134815216064, 'learning_rate': 4.597084463358609e-07, 'num_tokens': 6050867.0, 'mean_token_accuracy': 0.7138217613101006, 'epoch': 0.7}
 70%|██████▉   | 1011/1449 [6:18:47<2:39:57, 21.91s/it] 70%|██████▉   | 1012/1449 [6:19:09<2:39:00, 21.83s/it]                                                       {'loss': 1.1041, 'grad_norm': 3.6496198177337646, 'learning_rate': 4.5778864925110206e-07, 'num_tokens': 6056544.0, 'mean_token_accuracy': 0.7052540294826031, 'epoch': 0.7}
 70%|██████▉   | 1012/1449 [6:19:09<2:39:00, 21.83s/it] 70%|██████▉   | 1013/1449 [6:19:30<2:38:11, 21.77s/it]                                                       {'loss': 1.0558, 'grad_norm': 3.4433069229125977, 'learning_rate': 4.5587167855117637e-07, 'num_tokens': 6062187.0, 'mean_token_accuracy': 0.7177809402346611, 'epoch': 0.7}
 70%|██████▉   | 1013/1449 [6:19:30<2:38:11, 21.77s/it] 70%|██████▉   | 1014/1449 [6:19:52<2:37:09, 21.68s/it]                                                       {'loss': 1.127, 'grad_norm': 3.5587007999420166, 'learning_rate': 4.5395754422867513e-07, 'num_tokens': 6068726.0, 'mean_token_accuracy': 0.7047792226076126, 'epoch': 0.7}
 70%|██████▉   | 1014/1449 [6:19:52<2:37:09, 21.68s/it] 70%|███████   | 1015/1449 [6:20:13<2:36:45, 21.67s/it]                                                       {'loss': 1.0261, 'grad_norm': 3.1554064750671387, 'learning_rate': 4.520462562614062e-07, 'num_tokens': 6074781.0, 'mean_token_accuracy': 0.7218958400189877, 'epoch': 0.7}
 70%|███████   | 1015/1449 [6:20:13<2:36:45, 21.67s/it] 70%|███████   | 1016/1449 [6:20:35<2:36:23, 21.67s/it]                                                       {'loss': 1.1177, 'grad_norm': 3.948740243911743, 'learning_rate': 4.501378246123387e-07, 'num_tokens': 6080287.0, 'mean_token_accuracy': 0.6909686028957367, 'epoch': 0.7}
 70%|███████   | 1016/1449 [6:20:35<2:36:23, 21.67s/it] 70%|███████   | 1017/1449 [6:20:56<2:35:07, 21.55s/it]                                                       {'loss': 0.9895, 'grad_norm': 3.793219804763794, 'learning_rate': 4.48232259229554e-07, 'num_tokens': 6085923.0, 'mean_token_accuracy': 0.7227618023753166, 'epoch': 0.7}
 70%|███████   | 1017/1449 [6:20:56<2:35:07, 21.55s/it] 70%|███████   | 1018/1449 [6:21:18<2:35:21, 21.63s/it]                                                       {'loss': 0.9718, 'grad_norm': 3.835627317428589, 'learning_rate': 4.4632957004619144e-07, 'num_tokens': 6091497.0, 'mean_token_accuracy': 0.7274651750922203, 'epoch': 0.7}
 70%|███████   | 1018/1449 [6:21:18<2:35:21, 21.63s/it] 70%|███████   | 1019/1449 [6:21:40<2:34:41, 21.59s/it]                                                       {'loss': 1.0182, 'grad_norm': 3.132798671722412, 'learning_rate': 4.4442976698039803e-07, 'num_tokens': 6097671.0, 'mean_token_accuracy': 0.7086582221090794, 'epoch': 0.7}
 70%|███████   | 1019/1449 [6:21:40<2:34:41, 21.59s/it] 70%|███████   | 1020/1449 [6:22:01<2:34:24, 21.60s/it]                                                       {'loss': 0.971, 'grad_norm': 4.132318496704102, 'learning_rate': 4.425328599352758e-07, 'num_tokens': 6102737.0, 'mean_token_accuracy': 0.7182192765176296, 'epoch': 0.7}
 70%|███████   | 1020/1449 [6:22:01<2:34:24, 21.60s/it] 70%|███████   | 1021/1449 [6:22:23<2:33:41, 21.55s/it]                                                       {'loss': 1.0077, 'grad_norm': 3.3079283237457275, 'learning_rate': 4.406388587988318e-07, 'num_tokens': 6108391.0, 'mean_token_accuracy': 0.727101307362318, 'epoch': 0.7}
 70%|███████   | 1021/1449 [6:22:23<2:33:41, 21.55s/it] 71%|███████   | 1022/1449 [6:22:44<2:33:07, 21.52s/it]                                                       {'loss': 1.0123, 'grad_norm': 3.641587257385254, 'learning_rate': 4.3874777344392457e-07, 'num_tokens': 6113897.0, 'mean_token_accuracy': 0.7142392843961716, 'epoch': 0.7}
 71%|███████   | 1022/1449 [6:22:44<2:33:07, 21.52s/it] 71%|███████   | 1023/1449 [6:23:05<2:32:37, 21.50s/it]                                                       {'loss': 1.0828, 'grad_norm': 4.179116249084473, 'learning_rate': 4.368596137282133e-07, 'num_tokens': 6119456.0, 'mean_token_accuracy': 0.701872481033206, 'epoch': 0.71}
 71%|███████   | 1023/1449 [6:23:05<2:32:37, 21.50s/it] 71%|███████   | 1024/1449 [6:23:27<2:32:52, 21.58s/it]                                                       {'loss': 1.0083, 'grad_norm': 3.413856029510498, 'learning_rate': 4.349743894941081e-07, 'num_tokens': 6125441.0, 'mean_token_accuracy': 0.7266809456050396, 'epoch': 0.71}
 71%|███████   | 1024/1449 [6:23:27<2:32:52, 21.58s/it] 71%|███████   | 1025/1449 [6:23:48<2:31:45, 21.47s/it]                                                       {'loss': 0.9478, 'grad_norm': 3.3160438537597656, 'learning_rate': 4.3309211056871544e-07, 'num_tokens': 6131618.0, 'mean_token_accuracy': 0.7288504280149937, 'epoch': 0.71}
 71%|███████   | 1025/1449 [6:23:48<2:31:45, 21.47s/it] 71%|███████   | 1026/1449 [6:24:10<2:31:43, 21.52s/it]                                                       {'loss': 1.1035, 'grad_norm': 3.9736084938049316, 'learning_rate': 4.312127867637906e-07, 'num_tokens': 6137058.0, 'mean_token_accuracy': 0.7007420286536217, 'epoch': 0.71}
 71%|███████   | 1026/1449 [6:24:10<2:31:43, 21.52s/it] 71%|███████   | 1027/1449 [6:24:32<2:31:35, 21.55s/it]                                                       {'loss': 1.0506, 'grad_norm': 3.407505989074707, 'learning_rate': 4.293364278756829e-07, 'num_tokens': 6143073.0, 'mean_token_accuracy': 0.7023101300001144, 'epoch': 0.71}
 71%|███████   | 1027/1449 [6:24:32<2:31:35, 21.55s/it] 71%|███████   | 1028/1449 [6:24:53<2:30:54, 21.51s/it]                                                       {'loss': 1.0146, 'grad_norm': 3.1162400245666504, 'learning_rate': 4.274630436852883e-07, 'num_tokens': 6149935.0, 'mean_token_accuracy': 0.7218023054301739, 'epoch': 0.71}
 71%|███████   | 1028/1449 [6:24:53<2:30:54, 21.51s/it] 71%|███████   | 1029/1449 [6:25:15<2:30:44, 21.53s/it]                                                       {'loss': 0.963, 'grad_norm': 3.5580198764801025, 'learning_rate': 4.255926439579948e-07, 'num_tokens': 6155898.0, 'mean_token_accuracy': 0.7349609658122063, 'epoch': 0.71}
 71%|███████   | 1029/1449 [6:25:15<2:30:44, 21.53s/it] 71%|███████   | 1030/1449 [6:25:36<2:30:32, 21.56s/it]                                                       {'loss': 1.0577, 'grad_norm': 3.404350757598877, 'learning_rate': 4.237252384436348e-07, 'num_tokens': 6161746.0, 'mean_token_accuracy': 0.7132603041827679, 'epoch': 0.71}
 71%|███████   | 1030/1449 [6:25:36<2:30:32, 21.56s/it] 71%|███████   | 1031/1449 [6:25:58<2:29:51, 21.51s/it]                                                       {'loss': 1.109, 'grad_norm': 3.4642117023468018, 'learning_rate': 4.2186083687643135e-07, 'num_tokens': 6167691.0, 'mean_token_accuracy': 0.7066536992788315, 'epoch': 0.71}
 71%|███████   | 1031/1449 [6:25:58<2:29:51, 21.51s/it] 71%|███████   | 1032/1449 [6:26:19<2:29:21, 21.49s/it]                                                       {'loss': 1.032, 'grad_norm': 3.3582584857940674, 'learning_rate': 4.1999944897495045e-07, 'num_tokens': 6173482.0, 'mean_token_accuracy': 0.712134562432766, 'epoch': 0.71}
 71%|███████   | 1032/1449 [6:26:19<2:29:21, 21.49s/it] 71%|███████▏  | 1033/1449 [6:26:41<2:29:37, 21.58s/it]                                                       {'loss': 1.0841, 'grad_norm': 3.5476431846618652, 'learning_rate': 4.181410844420473e-07, 'num_tokens': 6179122.0, 'mean_token_accuracy': 0.6994013525545597, 'epoch': 0.71}
 71%|███████▏  | 1033/1449 [6:26:41<2:29:37, 21.58s/it] 71%|███████▏  | 1034/1449 [6:27:02<2:28:36, 21.49s/it]                                                       {'loss': 0.976, 'grad_norm': 3.5815815925598145, 'learning_rate': 4.1628575296481783e-07, 'num_tokens': 6184553.0, 'mean_token_accuracy': 0.7195789515972137, 'epoch': 0.71}
 71%|███████▏  | 1034/1449 [6:27:02<2:28:36, 21.49s/it] 71%|███████▏  | 1035/1449 [6:27:24<2:28:33, 21.53s/it]                                                       {'loss': 1.0351, 'grad_norm': 3.6895081996917725, 'learning_rate': 4.1443346421454715e-07, 'num_tokens': 6190845.0, 'mean_token_accuracy': 0.7108501046895981, 'epoch': 0.71}
 71%|███████▏  | 1035/1449 [6:27:24<2:28:33, 21.53s/it] 71%|███████▏  | 1036/1449 [6:27:46<2:28:34, 21.58s/it]                                                       {'loss': 1.0264, 'grad_norm': 3.479807138442993, 'learning_rate': 4.1258422784666056e-07, 'num_tokens': 6197006.0, 'mean_token_accuracy': 0.7135160267353058, 'epoch': 0.71}
 71%|███████▏  | 1036/1449 [6:27:46<2:28:34, 21.58s/it] 72%|███████▏  | 1037/1449 [6:28:07<2:27:53, 21.54s/it]                                                       {'loss': 0.9399, 'grad_norm': 3.2926666736602783, 'learning_rate': 4.107380535006709e-07, 'num_tokens': 6203312.0, 'mean_token_accuracy': 0.7442234456539154, 'epoch': 0.72}
 72%|███████▏  | 1037/1449 [6:28:07<2:27:53, 21.54s/it] 72%|███████▏  | 1038/1449 [6:28:29<2:27:44, 21.57s/it]                                                       {'loss': 0.9701, 'grad_norm': 3.624011993408203, 'learning_rate': 4.0889495080013095e-07, 'num_tokens': 6209089.0, 'mean_token_accuracy': 0.7322524376213551, 'epoch': 0.72}
 72%|███████▏  | 1038/1449 [6:28:29<2:27:44, 21.57s/it] 72%|███████▏  | 1039/1449 [6:28:50<2:27:11, 21.54s/it]                                                       {'loss': 1.0588, 'grad_norm': 3.514256000518799, 'learning_rate': 4.0705492935258034e-07, 'num_tokens': 6214719.0, 'mean_token_accuracy': 0.7112230397760868, 'epoch': 0.72}
 72%|███████▏  | 1039/1449 [6:28:50<2:27:11, 21.54s/it] 72%|███████▏  | 1040/1449 [6:29:12<2:27:05, 21.58s/it]                                                       {'loss': 0.9704, 'grad_norm': 3.765329599380493, 'learning_rate': 4.052179987494988e-07, 'num_tokens': 6220953.0, 'mean_token_accuracy': 0.7264142520725727, 'epoch': 0.72}
 72%|███████▏  | 1040/1449 [6:29:12<2:27:05, 21.58s/it] 72%|███████▏  | 1041/1449 [6:29:33<2:26:57, 21.61s/it]                                                       {'loss': 0.9302, 'grad_norm': 3.212778091430664, 'learning_rate': 4.033841685662529e-07, 'num_tokens': 6227127.0, 'mean_token_accuracy': 0.7323035858571529, 'epoch': 0.72}
 72%|███████▏  | 1041/1449 [6:29:33<2:26:57, 21.61s/it] 72%|███████▏  | 1042/1449 [6:29:55<2:26:17, 21.57s/it]                                                       {'loss': 1.0702, 'grad_norm': 3.468797206878662, 'learning_rate': 4.0155344836204883e-07, 'num_tokens': 6232929.0, 'mean_token_accuracy': 0.7075485549867153, 'epoch': 0.72}
 72%|███████▏  | 1042/1449 [6:29:55<2:26:17, 21.57s/it] 72%|███████▏  | 1043/1449 [6:30:17<2:26:06, 21.59s/it]                                                       {'loss': 0.9574, 'grad_norm': 3.30854868888855, 'learning_rate': 3.997258476798804e-07, 'num_tokens': 6238656.0, 'mean_token_accuracy': 0.7304014749825001, 'epoch': 0.72}
 72%|███████▏  | 1043/1449 [6:30:17<2:26:06, 21.59s/it] 72%|███████▏  | 1044/1449 [6:30:38<2:25:28, 21.55s/it]                                                       {'loss': 0.9274, 'grad_norm': 3.833160638809204, 'learning_rate': 3.979013760464812e-07, 'num_tokens': 6243642.0, 'mean_token_accuracy': 0.7303554341197014, 'epoch': 0.72}
 72%|███████▏  | 1044/1449 [6:30:38<2:25:28, 21.55s/it] 72%|███████▏  | 1045/1449 [6:31:00<2:25:15, 21.57s/it]                                                       {'loss': 1.0587, 'grad_norm': 3.6103382110595703, 'learning_rate': 3.9608004297227336e-07, 'num_tokens': 6249344.0, 'mean_token_accuracy': 0.705539021641016, 'epoch': 0.72}
 72%|███████▏  | 1045/1449 [6:31:00<2:25:15, 21.57s/it] 72%|███████▏  | 1046/1449 [6:31:21<2:24:42, 21.54s/it]                                                       {'loss': 0.9342, 'grad_norm': 3.0693142414093018, 'learning_rate': 3.9426185795131895e-07, 'num_tokens': 6255848.0, 'mean_token_accuracy': 0.7367181852459908, 'epoch': 0.72}
 72%|███████▏  | 1046/1449 [6:31:21<2:24:42, 21.54s/it] 72%|███████▏  | 1047/1449 [6:31:43<2:24:32, 21.57s/it]                                                       {'loss': 1.0443, 'grad_norm': 3.3926610946655273, 'learning_rate': 3.9244683046126956e-07, 'num_tokens': 6261911.0, 'mean_token_accuracy': 0.7046766355633736, 'epoch': 0.72}
 72%|███████▏  | 1047/1449 [6:31:43<2:24:32, 21.57s/it] 72%|███████▏  | 1048/1449 [6:32:04<2:23:40, 21.50s/it]                                                       {'loss': 0.9116, 'grad_norm': 3.3821187019348145, 'learning_rate': 3.90634969963319e-07, 'num_tokens': 6267722.0, 'mean_token_accuracy': 0.733799371868372, 'epoch': 0.72}
 72%|███████▏  | 1048/1449 [6:32:04<2:23:40, 21.50s/it] 72%|███████▏  | 1049/1449 [6:32:26<2:24:03, 21.61s/it]                                                       {'loss': 1.008, 'grad_norm': 3.7065491676330566, 'learning_rate': 3.888262859021507e-07, 'num_tokens': 6273781.0, 'mean_token_accuracy': 0.7058166526257992, 'epoch': 0.72}
 72%|███████▏  | 1049/1449 [6:32:26<2:24:03, 21.61s/it] 72%|███████▏  | 1050/1449 [6:32:47<2:23:30, 21.58s/it]                                                       {'loss': 1.5364, 'grad_norm': 322.173828125, 'learning_rate': 3.87020787705892e-07, 'num_tokens': 6280143.0, 'mean_token_accuracy': 0.6802024766802788, 'epoch': 0.72}
 72%|███████▏  | 1050/1449 [6:32:47<2:23:30, 21.58s/it][INFO|trainer.py:3966] 2025-06-06 06:42:13,948 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050
[INFO|configuration_utils.py:423] 2025-06-06 06:42:13,954 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/config.json
[INFO|configuration_utils.py:908] 2025-06-06 06:42:13,956 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 06:42:22,301 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 06:42:22,305 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 06:42:22,307 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/special_tokens_map.json
[2025-06-06 06:42:22,499] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step1050 is about to be saved!
[2025-06-06 06:42:22,505] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/global_step1050/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 06:42:22,505] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/global_step1050/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 06:42:22,520] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/global_step1050/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 06:42:22,522] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/global_step1050/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 06:42:45,766] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/global_step1050/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 06:42:45,771] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1050/global_step1050/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 06:42:46,245] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1050 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 06:42:57,719 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 06:42:57,721 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 73%|███████▎  | 1051/1449 [6:33:55<3:54:48, 35.40s/it]                                                       {'loss': 0.954, 'grad_norm': 3.6022896766662598, 'learning_rate': 3.8521848478606146e-07, 'num_tokens': 6286256.0, 'mean_token_accuracy': 0.7244683504104614, 'epoch': 0.72}
 73%|███████▎  | 1051/1449 [6:33:55<3:54:48, 35.40s/it] 73%|███████▎  | 1052/1449 [6:34:17<3:26:35, 31.22s/it]                                                       {'loss': 1.1123, 'grad_norm': 3.0140326023101807, 'learning_rate': 3.834193865375235e-07, 'num_tokens': 6293073.0, 'mean_token_accuracy': 0.7074964269995689, 'epoch': 0.73}
 73%|███████▎  | 1052/1449 [6:34:17<3:26:35, 31.22s/it] 73%|███████▎  | 1053/1449 [6:34:39<3:08:11, 28.51s/it]                                                       {'loss': 0.9787, 'grad_norm': 3.67496919631958, 'learning_rate': 3.81623502338436e-07, 'num_tokens': 6298505.0, 'mean_token_accuracy': 0.7209553457796574, 'epoch': 0.73}
 73%|███████▎  | 1053/1449 [6:34:39<3:08:11, 28.51s/it] 73%|███████▎  | 1054/1449 [6:35:01<2:55:40, 26.68s/it]                                                       {'loss': 1.0367, 'grad_norm': 3.0793256759643555, 'learning_rate': 3.798308415502041e-07, 'num_tokens': 6304719.0, 'mean_token_accuracy': 0.7111512497067451, 'epoch': 0.73}
 73%|███████▎  | 1054/1449 [6:35:01<2:55:40, 26.68s/it] 73%|███████▎  | 1055/1449 [6:35:23<2:45:11, 25.16s/it]                                                       {'loss': 0.9629, 'grad_norm': 3.5713489055633545, 'learning_rate': 3.7804141351742925e-07, 'num_tokens': 6310899.0, 'mean_token_accuracy': 0.726298663765192, 'epoch': 0.73}
 73%|███████▎  | 1055/1449 [6:35:23<2:45:11, 25.16s/it] 73%|███████▎  | 1056/1449 [6:35:45<2:38:31, 24.20s/it]                                                       {'loss': 1.0832, 'grad_norm': 3.423100471496582, 'learning_rate': 3.7625522756786275e-07, 'num_tokens': 6316570.0, 'mean_token_accuracy': 0.705845445394516, 'epoch': 0.73}
 73%|███████▎  | 1056/1449 [6:35:45<2:38:31, 24.20s/it] 73%|███████▎  | 1057/1449 [6:36:07<2:33:38, 23.52s/it]                                                       {'loss': 1.064, 'grad_norm': 3.5558621883392334, 'learning_rate': 3.744722930123544e-07, 'num_tokens': 6322121.0, 'mean_token_accuracy': 0.7089137621223927, 'epoch': 0.73}
 73%|███████▎  | 1057/1449 [6:36:07<2:33:38, 23.52s/it] 73%|███████▎  | 1058/1449 [6:36:28<2:29:41, 22.97s/it]                                                       {'loss': 0.8862, 'grad_norm': 3.8197460174560547, 'learning_rate': 3.7269261914480696e-07, 'num_tokens': 6327790.0, 'mean_token_accuracy': 0.7485702261328697, 'epoch': 0.73}
 73%|███████▎  | 1058/1449 [6:36:28<2:29:41, 22.97s/it] 73%|███████▎  | 1059/1449 [6:36:51<2:27:41, 22.72s/it]                                                       {'loss': 0.9716, 'grad_norm': 3.466571092605591, 'learning_rate': 3.7091621524212524e-07, 'num_tokens': 6333778.0, 'mean_token_accuracy': 0.725026972591877, 'epoch': 0.73}
 73%|███████▎  | 1059/1449 [6:36:51<2:27:41, 22.72s/it] 73%|███████▎  | 1060/1449 [6:37:12<2:24:39, 22.31s/it]                                                       {'loss': 0.9885, 'grad_norm': 3.0577473640441895, 'learning_rate': 3.691430905641689e-07, 'num_tokens': 6340149.0, 'mean_token_accuracy': 0.7309637255966663, 'epoch': 0.73}
 73%|███████▎  | 1060/1449 [6:37:12<2:24:39, 22.31s/it] 73%|███████▎  | 1061/1449 [6:37:34<2:24:02, 22.27s/it]                                                       {'loss': 0.9951, 'grad_norm': 3.772925853729248, 'learning_rate': 3.673732543537037e-07, 'num_tokens': 6346050.0, 'mean_token_accuracy': 0.7301007136702538, 'epoch': 0.73}
 73%|███████▎  | 1061/1449 [6:37:34<2:24:02, 22.27s/it] 73%|███████▎  | 1062/1449 [6:37:56<2:22:45, 22.13s/it]                                                       {'loss': 1.1109, 'grad_norm': 3.422070026397705, 'learning_rate': 3.656067158363546e-07, 'num_tokens': 6352150.0, 'mean_token_accuracy': 0.694094829261303, 'epoch': 0.73}
 73%|███████▎  | 1062/1449 [6:37:56<2:22:45, 22.13s/it] 73%|███████▎  | 1063/1449 [6:38:18<2:21:35, 22.01s/it]                                                       {'loss': 0.922, 'grad_norm': 3.2769389152526855, 'learning_rate': 3.638434842205558e-07, 'num_tokens': 6358252.0, 'mean_token_accuracy': 0.7374825999140739, 'epoch': 0.73}
 73%|███████▎  | 1063/1449 [6:38:18<2:21:35, 22.01s/it] 73%|███████▎  | 1064/1449 [6:38:39<2:20:48, 21.94s/it]                                                       {'loss': 1.2215, 'grad_norm': 3.769294023513794, 'learning_rate': 3.6208356869750346e-07, 'num_tokens': 6364075.0, 'mean_token_accuracy': 0.6722602732479572, 'epoch': 0.73}
 73%|███████▎  | 1064/1449 [6:38:39<2:20:48, 21.94s/it] 73%|███████▎  | 1065/1449 [6:39:02<2:20:45, 21.99s/it]                                                       {'loss': 1.0609, 'grad_norm': 3.094663619995117, 'learning_rate': 3.603269784411089e-07, 'num_tokens': 6370607.0, 'mean_token_accuracy': 0.7125559486448765, 'epoch': 0.73}
 73%|███████▎  | 1065/1449 [6:39:02<2:20:45, 21.99s/it] 74%|███████▎  | 1066/1449 [6:39:23<2:19:30, 21.86s/it]                                                       {'loss': 1.0388, 'grad_norm': 3.9022116661071777, 'learning_rate': 3.585737226079488e-07, 'num_tokens': 6376271.0, 'mean_token_accuracy': 0.705492414534092, 'epoch': 0.74}
 74%|███████▎  | 1066/1449 [6:39:23<2:19:30, 21.86s/it] 74%|███████▎  | 1067/1449 [6:39:45<2:19:17, 21.88s/it]                                                       {'loss': 1.009, 'grad_norm': 4.12064790725708, 'learning_rate': 3.568238103372194e-07, 'num_tokens': 6381234.0, 'mean_token_accuracy': 0.7298150323331356, 'epoch': 0.74}
 74%|███████▎  | 1067/1449 [6:39:45<2:19:17, 21.88s/it] 74%|███████▎  | 1068/1449 [6:40:07<2:19:14, 21.93s/it]                                                       {'loss': 1.1697, 'grad_norm': 3.553004503250122, 'learning_rate': 3.550772507506871e-07, 'num_tokens': 6387090.0, 'mean_token_accuracy': 0.6877297721803188, 'epoch': 0.74}
 74%|███████▎  | 1068/1449 [6:40:07<2:19:14, 21.93s/it] 74%|███████▍  | 1069/1449 [6:40:29<2:18:14, 21.83s/it]                                                       {'loss': 1.16, 'grad_norm': 3.556492567062378, 'learning_rate': 3.5333405295264253e-07, 'num_tokens': 6393364.0, 'mean_token_accuracy': 0.7033465281128883, 'epoch': 0.74}
 74%|███████▍  | 1069/1449 [6:40:29<2:18:14, 21.83s/it] 74%|███████▍  | 1070/1449 [6:40:51<2:18:08, 21.87s/it]                                                       {'loss': 1.0544, 'grad_norm': 3.5857467651367188, 'learning_rate': 3.5159422602985147e-07, 'num_tokens': 6399606.0, 'mean_token_accuracy': 0.7167090848088264, 'epoch': 0.74}
 74%|███████▍  | 1070/1449 [6:40:51<2:18:08, 21.87s/it] 74%|███████▍  | 1071/1449 [6:41:12<2:17:33, 21.83s/it]                                                       {'loss': 1.0263, 'grad_norm': 3.3939507007598877, 'learning_rate': 3.498577790515095e-07, 'num_tokens': 6405476.0, 'mean_token_accuracy': 0.7204332053661346, 'epoch': 0.74}
 74%|███████▍  | 1071/1449 [6:41:12<2:17:33, 21.83s/it] 74%|███████▍  | 1072/1449 [6:41:34<2:17:05, 21.82s/it]                                                       {'loss': 1.0279, 'grad_norm': 4.286948204040527, 'learning_rate': 3.4812472106919253e-07, 'num_tokens': 6411904.0, 'mean_token_accuracy': 0.7146406881511211, 'epoch': 0.74}
 74%|███████▍  | 1072/1449 [6:41:34<2:17:05, 21.82s/it] 74%|███████▍  | 1073/1449 [6:41:56<2:17:25, 21.93s/it]                                                       {'loss': 0.9309, 'grad_norm': 3.9127418994903564, 'learning_rate': 3.4639506111681104e-07, 'num_tokens': 6417788.0, 'mean_token_accuracy': 0.7341950088739395, 'epoch': 0.74}
 74%|███████▍  | 1073/1449 [6:41:56<2:17:25, 21.93s/it] 74%|███████▍  | 1074/1449 [6:42:18<2:16:19, 21.81s/it]                                                       {'loss': 1.0939, 'grad_norm': 3.0662527084350586, 'learning_rate': 3.446688082105623e-07, 'num_tokens': 6424376.0, 'mean_token_accuracy': 0.6878667771816254, 'epoch': 0.74}
 74%|███████▍  | 1074/1449 [6:42:18<2:16:19, 21.81s/it] 74%|███████▍  | 1075/1449 [6:42:40<2:16:20, 21.87s/it]                                                       {'loss': 1.0602, 'grad_norm': 4.646355152130127, 'learning_rate': 3.429459713488846e-07, 'num_tokens': 6429825.0, 'mean_token_accuracy': 0.7091475687921047, 'epoch': 0.74}
 74%|███████▍  | 1075/1449 [6:42:40<2:16:20, 21.87s/it] 74%|███████▍  | 1076/1449 [6:43:02<2:16:24, 21.94s/it]                                                       {'loss': 1.0037, 'grad_norm': 3.1237106323242188, 'learning_rate': 3.41226559512408e-07, 'num_tokens': 6436133.0, 'mean_token_accuracy': 0.7165184393525124, 'epoch': 0.74}
 74%|███████▍  | 1076/1449 [6:43:02<2:16:24, 21.94s/it] 74%|███████▍  | 1077/1449 [6:43:23<2:14:40, 21.72s/it]                                                       {'loss': 1.0199, 'grad_norm': 3.4610838890075684, 'learning_rate': 3.3951058166391056e-07, 'num_tokens': 6442050.0, 'mean_token_accuracy': 0.7193081900477409, 'epoch': 0.74}
 74%|███████▍  | 1077/1449 [6:43:23<2:14:40, 21.72s/it] 74%|███████▍  | 1078/1449 [6:43:45<2:14:44, 21.79s/it]                                                       {'loss': 1.18, 'grad_norm': 3.4929211139678955, 'learning_rate': 3.377980467482683e-07, 'num_tokens': 6448015.0, 'mean_token_accuracy': 0.6828110106289387, 'epoch': 0.74}
 74%|███████▍  | 1078/1449 [6:43:45<2:14:44, 21.79s/it] 74%|███████▍  | 1079/1449 [6:44:07<2:14:04, 21.74s/it]                                                       {'loss': 1.1349, 'grad_norm': 3.871889114379883, 'learning_rate': 3.360889636924119e-07, 'num_tokens': 6453573.0, 'mean_token_accuracy': 0.7005064599215984, 'epoch': 0.74}
 74%|███████▍  | 1079/1449 [6:44:07<2:14:04, 21.74s/it] 75%|███████▍  | 1080/1449 [6:44:28<2:13:26, 21.70s/it]                                                       {'loss': 1.0249, 'grad_norm': 4.2183685302734375, 'learning_rate': 3.343833414052769e-07, 'num_tokens': 6459308.0, 'mean_token_accuracy': 0.7131634689867496, 'epoch': 0.74}
 75%|███████▍  | 1080/1449 [6:44:28<2:13:26, 21.70s/it] 75%|███████▍  | 1081/1449 [6:44:50<2:13:14, 21.72s/it]                                                       {'loss': 0.859, 'grad_norm': 2.5958662033081055, 'learning_rate': 3.3268118877776064e-07, 'num_tokens': 6467135.0, 'mean_token_accuracy': 0.7475908696651459, 'epoch': 0.75}
 75%|███████▍  | 1081/1449 [6:44:50<2:13:14, 21.72s/it] 75%|███████▍  | 1082/1449 [6:45:11<2:12:09, 21.61s/it]                                                       {'loss': 1.035, 'grad_norm': 3.92529034614563, 'learning_rate': 3.309825146826725e-07, 'num_tokens': 6473293.0, 'mean_token_accuracy': 0.7199164070188999, 'epoch': 0.75}
 75%|███████▍  | 1082/1449 [6:45:11<2:12:09, 21.61s/it] 75%|███████▍  | 1083/1449 [6:45:33<2:12:16, 21.68s/it]                                                       {'loss': 1.0027, 'grad_norm': 2.995305299758911, 'learning_rate': 3.292873279746906e-07, 'num_tokens': 6480855.0, 'mean_token_accuracy': 0.716485034674406, 'epoch': 0.75}
 75%|███████▍  | 1083/1449 [6:45:33<2:12:16, 21.68s/it] 75%|███████▍  | 1084/1449 [6:45:55<2:12:26, 21.77s/it]                                                       {'loss': 1.0056, 'grad_norm': 3.6070008277893066, 'learning_rate': 3.275956374903133e-07, 'num_tokens': 6486952.0, 'mean_token_accuracy': 0.7194861620664597, 'epoch': 0.75}
 75%|███████▍  | 1084/1449 [6:45:55<2:12:26, 21.77s/it] 75%|███████▍  | 1085/1449 [6:46:17<2:11:45, 21.72s/it]                                                       {'loss': 1.0976, 'grad_norm': 3.391767978668213, 'learning_rate': 3.2590745204781533e-07, 'num_tokens': 6492507.0, 'mean_token_accuracy': 0.6968253515660763, 'epoch': 0.75}
 75%|███████▍  | 1085/1449 [6:46:17<2:11:45, 21.72s/it] 75%|███████▍  | 1086/1449 [6:46:39<2:12:26, 21.89s/it]                                                       {'loss': 0.9305, 'grad_norm': 3.563145160675049, 'learning_rate': 3.242227804471999e-07, 'num_tokens': 6499222.0, 'mean_token_accuracy': 0.7401228696107864, 'epoch': 0.75}
 75%|███████▍  | 1086/1449 [6:46:39<2:12:26, 21.89s/it] 75%|███████▌  | 1087/1449 [6:47:01<2:12:16, 21.92s/it]                                                       {'loss': 1.0303, 'grad_norm': 3.7527990341186523, 'learning_rate': 3.225416314701537e-07, 'num_tokens': 6504826.0, 'mean_token_accuracy': 0.7135532535612583, 'epoch': 0.75}
 75%|███████▌  | 1087/1449 [6:47:01<2:12:16, 21.92s/it] 75%|███████▌  | 1088/1449 [6:47:23<2:11:12, 21.81s/it]                                                       {'loss': 1.1297, 'grad_norm': 3.548642873764038, 'learning_rate': 3.208640138800007e-07, 'num_tokens': 6510496.0, 'mean_token_accuracy': 0.6952202916145325, 'epoch': 0.75}
 75%|███████▌  | 1088/1449 [6:47:23<2:11:12, 21.81s/it] 75%|███████▌  | 1089/1449 [6:47:44<2:10:47, 21.80s/it]                                                       {'loss': 1.0406, 'grad_norm': 3.2106804847717285, 'learning_rate': 3.1918993642165805e-07, 'num_tokens': 6516436.0, 'mean_token_accuracy': 0.7112201042473316, 'epoch': 0.75}
 75%|███████▌  | 1089/1449 [6:47:44<2:10:47, 21.80s/it] 75%|███████▌  | 1090/1449 [6:48:06<2:09:35, 21.66s/it]                                                       {'loss': 1.0213, 'grad_norm': 3.9585227966308594, 'learning_rate': 3.1751940782158783e-07, 'num_tokens': 6522443.0, 'mean_token_accuracy': 0.7215753383934498, 'epoch': 0.75}
 75%|███████▌  | 1090/1449 [6:48:06<2:09:35, 21.66s/it] 75%|███████▌  | 1091/1449 [6:48:28<2:09:23, 21.69s/it]                                                       {'loss': 1.0645, 'grad_norm': 3.45741605758667, 'learning_rate': 3.158524367877543e-07, 'num_tokens': 6528602.0, 'mean_token_accuracy': 0.6972557827830315, 'epoch': 0.75}
 75%|███████▌  | 1091/1449 [6:48:28<2:09:23, 21.69s/it] 75%|███████▌  | 1092/1449 [6:48:49<2:09:10, 21.71s/it]                                                       {'loss': 1.0388, 'grad_norm': 3.479370355606079, 'learning_rate': 3.1418903200957567e-07, 'num_tokens': 6534697.0, 'mean_token_accuracy': 0.7103411629796028, 'epoch': 0.75}
 75%|███████▌  | 1092/1449 [6:48:49<2:09:10, 21.71s/it] 75%|███████▌  | 1093/1449 [6:49:11<2:08:30, 21.66s/it]                                                       {'loss': 0.941, 'grad_norm': 3.406508207321167, 'learning_rate': 3.1252920215788215e-07, 'num_tokens': 6540658.0, 'mean_token_accuracy': 0.7374489717185497, 'epoch': 0.75}
 75%|███████▌  | 1093/1449 [6:49:11<2:08:30, 21.66s/it] 76%|███████▌  | 1094/1449 [6:49:32<2:07:55, 21.62s/it]                                                       {'loss': 0.9762, 'grad_norm': 3.181532382965088, 'learning_rate': 3.1087295588486705e-07, 'num_tokens': 6546433.0, 'mean_token_accuracy': 0.7301816567778587, 'epoch': 0.75}
 76%|███████▌  | 1094/1449 [6:49:32<2:07:55, 21.62s/it] 76%|███████▌  | 1095/1449 [6:49:54<2:08:06, 21.71s/it]                                                       {'loss': 0.9777, 'grad_norm': 3.1388652324676514, 'learning_rate': 3.0922030182404526e-07, 'num_tokens': 6553346.0, 'mean_token_accuracy': 0.722909476608038, 'epoch': 0.76}
 76%|███████▌  | 1095/1449 [6:49:54<2:08:06, 21.71s/it] 76%|███████▌  | 1096/1449 [6:50:16<2:06:46, 21.55s/it]                                                       {'loss': 1.0537, 'grad_norm': 3.6049325466156006, 'learning_rate': 3.075712485902051e-07, 'num_tokens': 6559517.0, 'mean_token_accuracy': 0.705404844135046, 'epoch': 0.76}
 76%|███████▌  | 1096/1449 [6:50:16<2:06:46, 21.55s/it] 76%|███████▌  | 1097/1449 [6:50:37<2:07:01, 21.65s/it]                                                       {'loss': 1.0694, 'grad_norm': 4.04841947555542, 'learning_rate': 3.0592580477936604e-07, 'num_tokens': 6564698.0, 'mean_token_accuracy': 0.7137763798236847, 'epoch': 0.76}
 76%|███████▌  | 1097/1449 [6:50:37<2:07:01, 21.65s/it] 76%|███████▌  | 1098/1449 [6:50:59<2:06:28, 21.62s/it]                                                       {'loss': 1.0834, 'grad_norm': 3.5057051181793213, 'learning_rate': 3.0428397896873205e-07, 'num_tokens': 6570467.0, 'mean_token_accuracy': 0.7057585790753365, 'epoch': 0.76}
 76%|███████▌  | 1098/1449 [6:50:59<2:06:28, 21.62s/it] 76%|███████▌  | 1099/1449 [6:51:21<2:06:00, 21.60s/it]                                                       {'loss': 1.0319, 'grad_norm': 3.6411657333374023, 'learning_rate': 3.0264577971664765e-07, 'num_tokens': 6575891.0, 'mean_token_accuracy': 0.7161602713167667, 'epoch': 0.76}
 76%|███████▌  | 1099/1449 [6:51:21<2:06:00, 21.60s/it] 76%|███████▌  | 1100/1449 [6:51:42<2:05:50, 21.63s/it]                                                       {'loss': 1.1199, 'grad_norm': 3.753861904144287, 'learning_rate': 3.0101121556255294e-07, 'num_tokens': 6581784.0, 'mean_token_accuracy': 0.6938727833330631, 'epoch': 0.76}
 76%|███████▌  | 1100/1449 [6:51:42<2:05:50, 21.63s/it][INFO|trainer.py:3966] 2025-06-06 07:01:08,673 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100
[INFO|configuration_utils.py:423] 2025-06-06 07:01:08,679 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/config.json
[INFO|configuration_utils.py:908] 2025-06-06 07:01:08,681 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 07:01:17,158 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 07:01:17,161 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 07:01:17,163 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/special_tokens_map.json
[2025-06-06 07:01:17,379] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step1100 is about to be saved!
[2025-06-06 07:01:17,385] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/global_step1100/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 07:01:17,385] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/global_step1100/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 07:01:17,400] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/global_step1100/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 07:01:17,401] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/global_step1100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 07:01:39,802] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/global_step1100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 07:01:39,807] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1100/global_step1100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 07:01:40,609] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1100 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 07:01:51,605 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 07:01:51,607 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 76%|███████▌  | 1101/1449 [6:52:48<3:22:44, 34.96s/it]                                                       {'loss': 0.9927, 'grad_norm': 3.3367269039154053, 'learning_rate': 2.993802950269402e-07, 'num_tokens': 6587996.0, 'mean_token_accuracy': 0.7186580635607243, 'epoch': 0.76}
 76%|███████▌  | 1101/1449 [6:52:48<3:22:44, 34.96s/it] 76%|███████▌  | 1102/1449 [6:53:10<2:59:30, 31.04s/it]                                                       {'loss': 1.1668, 'grad_norm': 4.011541843414307, 'learning_rate': 2.9775302661130754e-07, 'num_tokens': 6593136.0, 'mean_token_accuracy': 0.6828577667474747, 'epoch': 0.76}
 76%|███████▌  | 1102/1449 [6:53:10<2:59:30, 31.04s/it] 76%|███████▌  | 1103/1449 [6:53:32<2:42:24, 28.16s/it]                                                       {'loss': 0.9796, 'grad_norm': 3.862393379211426, 'learning_rate': 2.961294187981168e-07, 'num_tokens': 6598932.0, 'mean_token_accuracy': 0.7292450517416, 'epoch': 0.76}
 76%|███████▌  | 1103/1449 [6:53:32<2:42:24, 28.16s/it] 76%|███████▌  | 1104/1449 [6:53:53<2:30:43, 26.21s/it]                                                       {'loss': 1.059, 'grad_norm': 3.138512134552002, 'learning_rate': 2.9450948005074694e-07, 'num_tokens': 6604989.0, 'mean_token_accuracy': 0.7047465480864048, 'epoch': 0.76}
 76%|███████▌  | 1104/1449 [6:53:53<2:30:43, 26.21s/it] 76%|███████▋  | 1105/1449 [6:54:14<2:21:31, 24.69s/it]                                                       {'loss': 1.0265, 'grad_norm': 3.5751349925994873, 'learning_rate': 2.9289321881345254e-07, 'num_tokens': 6610724.0, 'mean_token_accuracy': 0.704512432217598, 'epoch': 0.76}
 76%|███████▋  | 1105/1449 [6:54:14<2:21:31, 24.69s/it] 76%|███████▋  | 1106/1449 [6:54:36<2:16:19, 23.85s/it]                                                       {'loss': 0.9861, 'grad_norm': 3.0706233978271484, 'learning_rate': 2.912806435113174e-07, 'num_tokens': 6617990.0, 'mean_token_accuracy': 0.7275046482682228, 'epoch': 0.76}
 76%|███████▋  | 1106/1449 [6:54:36<2:16:19, 23.85s/it] 76%|███████▋  | 1107/1449 [6:54:58<2:11:59, 23.16s/it]                                                       {'loss': 0.9461, 'grad_norm': 3.5296483039855957, 'learning_rate': 2.8967176255021165e-07, 'num_tokens': 6623912.0, 'mean_token_accuracy': 0.7357225157320499, 'epoch': 0.76}
 76%|███████▋  | 1107/1449 [6:54:58<2:11:59, 23.16s/it] 76%|███████▋  | 1108/1449 [6:55:19<2:08:11, 22.56s/it]                                                       {'loss': 1.0201, 'grad_norm': 3.7287309169769287, 'learning_rate': 2.8806658431674877e-07, 'num_tokens': 6630022.0, 'mean_token_accuracy': 0.721151564270258, 'epoch': 0.76}
 76%|███████▋  | 1108/1449 [6:55:19<2:08:11, 22.56s/it] 77%|███████▋  | 1109/1449 [6:55:41<2:06:22, 22.30s/it]                                                       {'loss': 1.0496, 'grad_norm': 3.772019386291504, 'learning_rate': 2.8646511717824016e-07, 'num_tokens': 6635408.0, 'mean_token_accuracy': 0.7150240913033485, 'epoch': 0.76}
 77%|███████▋  | 1109/1449 [6:55:41<2:06:22, 22.30s/it] 77%|███████▋  | 1110/1449 [6:56:02<2:04:27, 22.03s/it]                                                       {'loss': 1.0773, 'grad_norm': 3.7928707599639893, 'learning_rate': 2.848673694826532e-07, 'num_tokens': 6641653.0, 'mean_token_accuracy': 0.7063159011304379, 'epoch': 0.77}
 77%|███████▋  | 1110/1449 [6:56:02<2:04:27, 22.03s/it] 77%|███████▋  | 1111/1449 [6:56:24<2:03:29, 21.92s/it]                                                       {'loss': 1.1472, 'grad_norm': 3.2478599548339844, 'learning_rate': 2.8327334955856597e-07, 'num_tokens': 6648040.0, 'mean_token_accuracy': 0.687385480850935, 'epoch': 0.77}
 77%|███████▋  | 1111/1449 [6:56:24<2:03:29, 21.92s/it] 77%|███████▋  | 1112/1449 [6:56:45<2:02:43, 21.85s/it]                                                       {'loss': 1.0378, 'grad_norm': 3.80407977104187, 'learning_rate': 2.816830657151258e-07, 'num_tokens': 6653200.0, 'mean_token_accuracy': 0.7116738632321358, 'epoch': 0.77}
 77%|███████▋  | 1112/1449 [6:56:45<2:02:43, 21.85s/it] 77%|███████▋  | 1113/1449 [6:57:07<2:02:11, 21.82s/it]                                                       {'loss': 1.0732, 'grad_norm': 3.6632003784179688, 'learning_rate': 2.800965262420043e-07, 'num_tokens': 6658582.0, 'mean_token_accuracy': 0.704355925321579, 'epoch': 0.77}
 77%|███████▋  | 1113/1449 [6:57:07<2:02:11, 21.82s/it] 77%|███████▋  | 1114/1449 [6:57:29<2:01:36, 21.78s/it]                                                       {'loss': 1.0248, 'grad_norm': 3.181382417678833, 'learning_rate': 2.7851373940935486e-07, 'num_tokens': 6664677.0, 'mean_token_accuracy': 0.7175870425999165, 'epoch': 0.77}
 77%|███████▋  | 1114/1449 [6:57:29<2:01:36, 21.78s/it] 77%|███████▋  | 1115/1449 [6:57:50<2:00:50, 21.71s/it]                                                       {'loss': 1.0291, 'grad_norm': 3.27895450592041, 'learning_rate': 2.769347134677694e-07, 'num_tokens': 6670866.0, 'mean_token_accuracy': 0.6975920125842094, 'epoch': 0.77}
 77%|███████▋  | 1115/1449 [6:57:50<2:00:50, 21.71s/it] 77%|███████▋  | 1116/1449 [6:58:12<2:00:53, 21.78s/it]                                                       {'loss': 0.9144, 'grad_norm': 3.221040964126587, 'learning_rate': 2.7535945664823626e-07, 'num_tokens': 6676626.0, 'mean_token_accuracy': 0.7288910336792469, 'epoch': 0.77}
 77%|███████▋  | 1116/1449 [6:58:12<2:00:53, 21.78s/it] 77%|███████▋  | 1117/1449 [6:58:34<1:59:44, 21.64s/it]                                                       {'loss': 0.9597, 'grad_norm': 3.24843692779541, 'learning_rate': 2.73787977162095e-07, 'num_tokens': 6683320.0, 'mean_token_accuracy': 0.7228980325162411, 'epoch': 0.77}
 77%|███████▋  | 1117/1449 [6:58:34<1:59:44, 21.64s/it] 77%|███████▋  | 1118/1449 [6:58:56<1:59:46, 21.71s/it]                                                       {'loss': 0.9544, 'grad_norm': 3.442568063735962, 'learning_rate': 2.722202832009969e-07, 'num_tokens': 6689499.0, 'mean_token_accuracy': 0.7308812774717808, 'epoch': 0.77}
 77%|███████▋  | 1118/1449 [6:58:56<1:59:46, 21.71s/it] 77%|███████▋  | 1119/1449 [6:59:17<1:59:20, 21.70s/it]                                                       {'loss': 0.8574, 'grad_norm': 3.308250904083252, 'learning_rate': 2.7065638293685864e-07, 'num_tokens': 6696088.0, 'mean_token_accuracy': 0.7580293081700802, 'epoch': 0.77}
 77%|███████▋  | 1119/1449 [6:59:17<1:59:20, 21.70s/it] 77%|███████▋  | 1120/1449 [6:59:39<1:58:48, 21.67s/it]                                                       {'loss': 1.0454, 'grad_norm': 3.1342086791992188, 'learning_rate': 2.690962845218231e-07, 'num_tokens': 6702353.0, 'mean_token_accuracy': 0.7044993788003922, 'epoch': 0.77}
 77%|███████▋  | 1120/1449 [6:59:39<1:58:48, 21.67s/it] 77%|███████▋  | 1121/1449 [7:00:01<1:58:49, 21.74s/it]                                                       {'loss': 1.134, 'grad_norm': 3.6326072216033936, 'learning_rate': 2.675399960882138e-07, 'num_tokens': 6707798.0, 'mean_token_accuracy': 0.6986605487763882, 'epoch': 0.77}
 77%|███████▋  | 1121/1449 [7:00:01<1:58:49, 21.74s/it] 77%|███████▋  | 1122/1449 [7:00:22<1:57:50, 21.62s/it]                                                       {'loss': 1.043, 'grad_norm': 4.0026936531066895, 'learning_rate': 2.6598752574849526e-07, 'num_tokens': 6712632.0, 'mean_token_accuracy': 0.712298896163702, 'epoch': 0.77}
 77%|███████▋  | 1122/1449 [7:00:22<1:57:50, 21.62s/it] 78%|███████▊  | 1123/1449 [7:00:44<1:57:55, 21.70s/it]                                                       {'loss': 1.075, 'grad_norm': 3.4098212718963623, 'learning_rate': 2.644388815952282e-07, 'num_tokens': 6718373.0, 'mean_token_accuracy': 0.7140896953642368, 'epoch': 0.77}
 78%|███████▊  | 1123/1449 [7:00:44<1:57:55, 21.70s/it] 78%|███████▊  | 1124/1449 [7:01:06<1:57:55, 21.77s/it]                                                       {'loss': 0.9998, 'grad_norm': 3.4128165245056152, 'learning_rate': 2.6289407170103e-07, 'num_tokens': 6724199.0, 'mean_token_accuracy': 0.7218017838895321, 'epoch': 0.78}
 78%|███████▊  | 1124/1449 [7:01:06<1:57:55, 21.77s/it] 78%|███████▊  | 1125/1449 [7:01:27<1:56:52, 21.64s/it]                                                       {'loss': 0.9539, 'grad_norm': 3.5688045024871826, 'learning_rate': 2.6135310411852975e-07, 'num_tokens': 6729848.0, 'mean_token_accuracy': 0.7373486272990704, 'epoch': 0.78}
 78%|███████▊  | 1125/1449 [7:01:27<1:56:52, 21.64s/it] 78%|███████▊  | 1126/1449 [7:01:49<1:56:56, 21.72s/it]                                                       {'loss': 1.235, 'grad_norm': 3.4641988277435303, 'learning_rate': 2.598159868803287e-07, 'num_tokens': 6735493.0, 'mean_token_accuracy': 0.6731383167207241, 'epoch': 0.78}
 78%|███████▊  | 1126/1449 [7:01:49<1:56:56, 21.72s/it] 78%|███████▊  | 1127/1449 [7:02:11<1:56:18, 21.67s/it]                                                       {'loss': 0.9421, 'grad_norm': 3.1901707649230957, 'learning_rate': 2.582827279989568e-07, 'num_tokens': 6741861.0, 'mean_token_accuracy': 0.7377448752522469, 'epoch': 0.78}
 78%|███████▊  | 1127/1449 [7:02:11<1:56:18, 21.67s/it] 78%|███████▊  | 1128/1449 [7:02:32<1:55:58, 21.68s/it]                                                       {'loss': 1.0149, 'grad_norm': 3.474710702896118, 'learning_rate': 2.567533354668322e-07, 'num_tokens': 6749261.0, 'mean_token_accuracy': 0.7245394214987755, 'epoch': 0.78}
 78%|███████▊  | 1128/1449 [7:02:32<1:55:58, 21.68s/it] 78%|███████▊  | 1129/1449 [7:02:54<1:55:53, 21.73s/it]                                                       {'loss': 1.0495, 'grad_norm': 3.5662641525268555, 'learning_rate': 2.552278172562181e-07, 'num_tokens': 6755171.0, 'mean_token_accuracy': 0.7119740732014179, 'epoch': 0.78}
 78%|███████▊  | 1129/1449 [7:02:54<1:55:53, 21.73s/it] 78%|███████▊  | 1130/1449 [7:03:16<1:55:12, 21.67s/it]                                                       {'loss': 1.0002, 'grad_norm': 3.237842082977295, 'learning_rate': 2.537061813191833e-07, 'num_tokens': 6761395.0, 'mean_token_accuracy': 0.7249966003000736, 'epoch': 0.78}
 78%|███████▊  | 1130/1449 [7:03:16<1:55:12, 21.67s/it] 78%|███████▊  | 1131/1449 [7:03:37<1:54:52, 21.67s/it]                                                       {'loss': 1.0273, 'grad_norm': 3.325212001800537, 'learning_rate': 2.5218843558755777e-07, 'num_tokens': 6767648.0, 'mean_token_accuracy': 0.7249980419874191, 'epoch': 0.78}
 78%|███████▊  | 1131/1449 [7:03:37<1:54:52, 21.67s/it] 78%|███████▊  | 1132/1449 [7:03:59<1:54:18, 21.64s/it]                                                       {'loss': 1.0537, 'grad_norm': 4.176450729370117, 'learning_rate': 2.5067458797289466e-07, 'num_tokens': 6773391.0, 'mean_token_accuracy': 0.7016584649682045, 'epoch': 0.78}
 78%|███████▊  | 1132/1449 [7:03:59<1:54:18, 21.64s/it] 78%|███████▊  | 1133/1449 [7:04:21<1:54:24, 21.72s/it]                                                       {'loss': 1.1585, 'grad_norm': 3.6970324516296387, 'learning_rate': 2.491646463664261e-07, 'num_tokens': 6779513.0, 'mean_token_accuracy': 0.6931562013924122, 'epoch': 0.78}
 78%|███████▊  | 1133/1449 [7:04:21<1:54:24, 21.72s/it] 78%|███████▊  | 1134/1449 [7:04:42<1:53:39, 21.65s/it]                                                       {'loss': 1.0528, 'grad_norm': 3.461273431777954, 'learning_rate': 2.4765861863902436e-07, 'num_tokens': 6785501.0, 'mean_token_accuracy': 0.7051453143358231, 'epoch': 0.78}
 78%|███████▊  | 1134/1449 [7:04:42<1:53:39, 21.65s/it] 78%|███████▊  | 1135/1449 [7:05:04<1:53:21, 21.66s/it]                                                       {'loss': 1.0266, 'grad_norm': 3.510941982269287, 'learning_rate': 2.46156512641159e-07, 'num_tokens': 6791765.0, 'mean_token_accuracy': 0.7136331759393215, 'epoch': 0.78}
 78%|███████▊  | 1135/1449 [7:05:04<1:53:21, 21.66s/it] 78%|███████▊  | 1136/1449 [7:05:26<1:53:27, 21.75s/it]                                                       {'loss': 1.1539, 'grad_norm': 3.80645751953125, 'learning_rate': 2.446583362028577e-07, 'num_tokens': 6797387.0, 'mean_token_accuracy': 0.6944713592529297, 'epoch': 0.78}
 78%|███████▊  | 1136/1449 [7:05:26<1:53:27, 21.75s/it] 78%|███████▊  | 1137/1449 [7:05:47<1:52:28, 21.63s/it]                                                       {'loss': 1.0744, 'grad_norm': 3.9281387329101562, 'learning_rate': 2.431640971336635e-07, 'num_tokens': 6802761.0, 'mean_token_accuracy': 0.7047094032168388, 'epoch': 0.78}
 78%|███████▊  | 1137/1449 [7:05:47<1:52:28, 21.63s/it] 79%|███████▊  | 1138/1449 [7:06:09<1:52:30, 21.70s/it]                                                       {'loss': 0.9845, 'grad_norm': 3.3016302585601807, 'learning_rate': 2.4167380322259613e-07, 'num_tokens': 6808893.0, 'mean_token_accuracy': 0.7270715273916721, 'epoch': 0.78}
 79%|███████▊  | 1138/1449 [7:06:09<1:52:30, 21.70s/it] 79%|███████▊  | 1139/1449 [7:06:31<1:51:30, 21.58s/it]                                                       {'loss': 1.0391, 'grad_norm': 4.1777777671813965, 'learning_rate': 2.401874622381097e-07, 'num_tokens': 6813698.0, 'mean_token_accuracy': 0.7048539631068707, 'epoch': 0.79}
 79%|███████▊  | 1139/1449 [7:06:31<1:51:30, 21.58s/it] 79%|███████▊  | 1140/1449 [7:06:52<1:51:37, 21.67s/it]                                                       {'loss': 1.0329, 'grad_norm': 3.831448793411255, 'learning_rate': 2.3870508192805307e-07, 'num_tokens': 6819411.0, 'mean_token_accuracy': 0.712205708026886, 'epoch': 0.79}
 79%|███████▊  | 1140/1449 [7:06:52<1:51:37, 21.67s/it] 79%|███████▊  | 1141/1449 [7:07:14<1:51:35, 21.74s/it]                                                       {'loss': 1.085, 'grad_norm': 3.5384135246276855, 'learning_rate': 2.3722667001962893e-07, 'num_tokens': 6825141.0, 'mean_token_accuracy': 0.6994973905384541, 'epoch': 0.79}
 79%|███████▊  | 1141/1449 [7:07:14<1:51:35, 21.74s/it] 79%|███████▉  | 1142/1449 [7:07:36<1:50:38, 21.62s/it]                                                       {'loss': 1.1355, 'grad_norm': 3.8100459575653076, 'learning_rate': 2.3575223421935497e-07, 'num_tokens': 6830280.0, 'mean_token_accuracy': 0.693670429289341, 'epoch': 0.79}
 79%|███████▉  | 1142/1449 [7:07:36<1:50:38, 21.62s/it] 79%|███████▉  | 1143/1449 [7:07:58<1:50:41, 21.71s/it]                                                       {'loss': 0.9478, 'grad_norm': 3.8257393836975098, 'learning_rate': 2.342817822130214e-07, 'num_tokens': 6836173.0, 'mean_token_accuracy': 0.7282937914133072, 'epoch': 0.79}
 79%|███████▉  | 1143/1449 [7:07:58<1:50:41, 21.71s/it] 79%|███████▉  | 1144/1449 [7:08:19<1:50:07, 21.66s/it]                                                       {'loss': 1.0118, 'grad_norm': 3.248439073562622, 'learning_rate': 2.3281532166565321e-07, 'num_tokens': 6842198.0, 'mean_token_accuracy': 0.7215881608426571, 'epoch': 0.79}
 79%|███████▉  | 1144/1449 [7:08:19<1:50:07, 21.66s/it] 79%|███████▉  | 1145/1449 [7:08:41<1:49:48, 21.67s/it]                                                       {'loss': 0.9649, 'grad_norm': 3.2287063598632812, 'learning_rate': 2.3135286022146782e-07, 'num_tokens': 6848529.0, 'mean_token_accuracy': 0.7210623994469643, 'epoch': 0.79}
 79%|███████▉  | 1145/1449 [7:08:41<1:49:48, 21.67s/it] 79%|███████▉  | 1146/1449 [7:09:03<1:49:51, 21.76s/it]                                                       {'loss': 1.0557, 'grad_norm': 3.668590545654297, 'learning_rate': 2.2989440550383798e-07, 'num_tokens': 6853805.0, 'mean_token_accuracy': 0.7035768777132034, 'epoch': 0.79}
 79%|███████▉  | 1146/1449 [7:09:03<1:49:51, 21.76s/it] 79%|███████▉  | 1147/1449 [7:09:24<1:49:14, 21.70s/it]                                                       {'loss': 1.0319, 'grad_norm': 3.437145471572876, 'learning_rate': 2.2843996511524932e-07, 'num_tokens': 6859808.0, 'mean_token_accuracy': 0.7184709683060646, 'epoch': 0.79}
 79%|███████▉  | 1147/1449 [7:09:24<1:49:14, 21.70s/it] 79%|███████▉  | 1148/1449 [7:09:46<1:48:51, 21.70s/it]                                                       {'loss': 0.9831, 'grad_norm': 3.6284494400024414, 'learning_rate': 2.26989546637263e-07, 'num_tokens': 6865329.0, 'mean_token_accuracy': 0.7191842123866081, 'epoch': 0.79}
 79%|███████▉  | 1148/1449 [7:09:46<1:48:51, 21.70s/it] 79%|███████▉  | 1149/1449 [7:10:08<1:48:18, 21.66s/it]                                                       {'loss': 0.9125, 'grad_norm': 3.0154483318328857, 'learning_rate': 2.2554315763047437e-07, 'num_tokens': 6872329.0, 'mean_token_accuracy': 0.7386224046349525, 'epoch': 0.79}
 79%|███████▉  | 1149/1449 [7:10:08<1:48:18, 21.66s/it] 79%|███████▉  | 1150/1449 [7:10:30<1:48:25, 21.76s/it]                                                       {'loss': 0.9923, 'grad_norm': 3.657074451446533, 'learning_rate': 2.2410080563447454e-07, 'num_tokens': 6878500.0, 'mean_token_accuracy': 0.7180511653423309, 'epoch': 0.79}
 79%|███████▉  | 1150/1449 [7:10:30<1:48:25, 21.76s/it][INFO|trainer.py:3966] 2025-06-06 07:19:56,134 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150
[INFO|configuration_utils.py:423] 2025-06-06 07:19:56,140 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/config.json
[INFO|configuration_utils.py:908] 2025-06-06 07:19:56,142 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 07:20:03,112 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 07:20:03,115 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 07:20:03,117 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/special_tokens_map.json
[2025-06-06 07:20:03,315] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step1150 is about to be saved!
[2025-06-06 07:20:03,321] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/global_step1150/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 07:20:03,321] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/global_step1150/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 07:20:03,336] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/global_step1150/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 07:20:03,337] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/global_step1150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 07:20:26,304] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/global_step1150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 07:20:26,309] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1150/global_step1150/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 07:20:26,797] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1150 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 07:20:38,362 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 07:20:38,364 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 79%|███████▉  | 1151/1449 [7:11:35<2:53:37, 34.96s/it]                                                       {'loss': 1.0633, 'grad_norm': 3.3319671154022217, 'learning_rate': 2.2266249816781146e-07, 'num_tokens': 6884778.0, 'mean_token_accuracy': 0.7245839424431324, 'epoch': 0.79}
 79%|███████▉  | 1151/1449 [7:11:35<2:53:37, 34.96s/it] 80%|███████▉  | 1152/1449 [7:11:57<2:33:53, 31.09s/it]                                                       {'loss': 1.0495, 'grad_norm': 3.816098928451538, 'learning_rate': 2.2122824272794938e-07, 'num_tokens': 6890115.0, 'mean_token_accuracy': 0.7055919654667377, 'epoch': 0.79}
 80%|███████▉  | 1152/1449 [7:11:57<2:33:53, 31.09s/it] 80%|███████▉  | 1153/1449 [7:12:19<2:19:29, 28.28s/it]                                                       {'loss': 0.9715, 'grad_norm': 3.6164612770080566, 'learning_rate': 2.1979804679123103e-07, 'num_tokens': 6895897.0, 'mean_token_accuracy': 0.7281471379101276, 'epoch': 0.8}
 80%|███████▉  | 1153/1449 [7:12:19<2:19:29, 28.28s/it] 80%|███████▉  | 1154/1449 [7:12:41<2:09:42, 26.38s/it]                                                       {'loss': 0.9844, 'grad_norm': 3.107800006866455, 'learning_rate': 2.183719178128378e-07, 'num_tokens': 6902898.0, 'mean_token_accuracy': 0.7167508006095886, 'epoch': 0.8}
 80%|███████▉  | 1154/1449 [7:12:41<2:09:42, 26.38s/it] 80%|███████▉  | 1155/1449 [7:13:03<2:02:17, 24.96s/it]                                                       {'loss': 1.0853, 'grad_norm': 3.437732219696045, 'learning_rate': 2.1694986322675202e-07, 'num_tokens': 6908790.0, 'mean_token_accuracy': 0.6941726058721542, 'epoch': 0.8}
 80%|███████▉  | 1155/1449 [7:13:03<2:02:17, 24.96s/it] 80%|███████▉  | 1156/1449 [7:13:25<1:57:19, 24.03s/it]                                                       {'loss': 1.061, 'grad_norm': 2.9100501537323, 'learning_rate': 2.1553189044571617e-07, 'num_tokens': 6915694.0, 'mean_token_accuracy': 0.7105935998260975, 'epoch': 0.8}
 80%|███████▉  | 1156/1449 [7:13:25<1:57:19, 24.03s/it] 80%|███████▉  | 1157/1449 [7:13:47<1:53:48, 23.39s/it]                                                       {'loss': 0.9187, 'grad_norm': 3.6421971321105957, 'learning_rate': 2.1411800686119707e-07, 'num_tokens': 6921808.0, 'mean_token_accuracy': 0.7356771379709244, 'epoch': 0.8}
 80%|███████▉  | 1157/1449 [7:13:47<1:53:48, 23.39s/it] 80%|███████▉  | 1158/1449 [7:14:08<1:50:47, 22.84s/it]                                                       {'loss': 1.0035, 'grad_norm': 3.178539514541626, 'learning_rate': 2.127082198433442e-07, 'num_tokens': 6927883.0, 'mean_token_accuracy': 0.7166535295546055, 'epoch': 0.8}
 80%|███████▉  | 1158/1449 [7:14:08<1:50:47, 22.84s/it] 80%|███████▉  | 1159/1449 [7:14:30<1:49:03, 22.57s/it]                                                       {'loss': 0.8917, 'grad_norm': 3.258143663406372, 'learning_rate': 2.1130253674095433e-07, 'num_tokens': 6933878.0, 'mean_token_accuracy': 0.7364517748355865, 'epoch': 0.8}
 80%|███████▉  | 1159/1449 [7:14:30<1:49:03, 22.57s/it] 80%|████████  | 1160/1449 [7:14:52<1:47:24, 22.30s/it]                                                       {'loss': 1.0608, 'grad_norm': 3.5818142890930176, 'learning_rate': 2.099009648814304e-07, 'num_tokens': 6939824.0, 'mean_token_accuracy': 0.7092889696359634, 'epoch': 0.8}
 80%|████████  | 1160/1449 [7:14:52<1:47:24, 22.30s/it] 80%|████████  | 1161/1449 [7:15:13<1:45:43, 22.03s/it]                                                       {'loss': 1.0402, 'grad_norm': 4.1295599937438965, 'learning_rate': 2.0850351157074597e-07, 'num_tokens': 6944976.0, 'mean_token_accuracy': 0.7205139771103859, 'epoch': 0.8}
 80%|████████  | 1161/1449 [7:15:13<1:45:43, 22.03s/it] 80%|████████  | 1162/1449 [7:15:35<1:44:47, 21.91s/it]                                                       {'loss': 1.0567, 'grad_norm': 4.2562384605407715, 'learning_rate': 2.0711018409340464e-07, 'num_tokens': 6951731.0, 'mean_token_accuracy': 0.7056049518287182, 'epoch': 0.8}
 80%|████████  | 1162/1449 [7:15:35<1:44:47, 21.91s/it] 80%|████████  | 1163/1449 [7:15:56<1:44:13, 21.87s/it]                                                       {'loss': 0.9474, 'grad_norm': 3.951552629470825, 'learning_rate': 2.0572098971240427e-07, 'num_tokens': 6957307.0, 'mean_token_accuracy': 0.7331150248646736, 'epoch': 0.8}
 80%|████████  | 1163/1449 [7:15:56<1:44:13, 21.87s/it] 80%|████████  | 1164/1449 [7:16:18<1:43:06, 21.71s/it]                                                       {'loss': 1.1049, 'grad_norm': 3.617940902709961, 'learning_rate': 2.0433593566919725e-07, 'num_tokens': 6962895.0, 'mean_token_accuracy': 0.6927089765667915, 'epoch': 0.8}
 80%|████████  | 1164/1449 [7:16:18<1:43:06, 21.71s/it] 80%|████████  | 1165/1449 [7:16:40<1:43:04, 21.78s/it]                                                       {'loss': 1.1368, 'grad_norm': 3.232948064804077, 'learning_rate': 2.029550291836547e-07, 'num_tokens': 6969325.0, 'mean_token_accuracy': 0.6878379322588444, 'epoch': 0.8}
 80%|████████  | 1165/1449 [7:16:40<1:43:04, 21.78s/it] 80%|████████  | 1166/1449 [7:17:01<1:41:53, 21.60s/it]                                                       {'loss': 1.0134, 'grad_norm': 3.301011323928833, 'learning_rate': 2.015782774540268e-07, 'num_tokens': 6975227.0, 'mean_token_accuracy': 0.7040181495249271, 'epoch': 0.8}
 80%|████████  | 1166/1449 [7:17:01<1:41:53, 21.60s/it] 81%|████████  | 1167/1449 [7:17:23<1:41:46, 21.66s/it]                                                       {'loss': 0.9449, 'grad_norm': 3.195342540740967, 'learning_rate': 2.002056876569066e-07, 'num_tokens': 6981563.0, 'mean_token_accuracy': 0.7259080745279789, 'epoch': 0.8}
 81%|████████  | 1167/1449 [7:17:23<1:41:46, 21.66s/it] 81%|████████  | 1168/1449 [7:17:44<1:41:11, 21.61s/it]                                                       {'loss': 1.0301, 'grad_norm': 3.491417407989502, 'learning_rate': 1.9883726694719193e-07, 'num_tokens': 6987230.0, 'mean_token_accuracy': 0.7161376625299454, 'epoch': 0.81}
 81%|████████  | 1168/1449 [7:17:44<1:41:11, 21.61s/it] 81%|████████  | 1169/1449 [7:18:06<1:40:27, 21.53s/it]                                                       {'loss': 0.9017, 'grad_norm': 3.424858331680298, 'learning_rate': 1.974730224580494e-07, 'num_tokens': 6992989.0, 'mean_token_accuracy': 0.7400531023740768, 'epoch': 0.81}
 81%|████████  | 1169/1449 [7:18:06<1:40:27, 21.53s/it] 81%|████████  | 1170/1449 [7:18:27<1:40:33, 21.63s/it]                                                       {'loss': 1.0119, 'grad_norm': 3.373347759246826, 'learning_rate': 1.9611296130087486e-07, 'num_tokens': 6998569.0, 'mean_token_accuracy': 0.7180709578096867, 'epoch': 0.81}
 81%|████████  | 1170/1449 [7:18:27<1:40:33, 21.63s/it] 81%|████████  | 1171/1449 [7:18:49<1:40:00, 21.59s/it]                                                       {'loss': 1.0317, 'grad_norm': 3.758251428604126, 'learning_rate': 1.9475709056525903e-07, 'num_tokens': 7004657.0, 'mean_token_accuracy': 0.7150553613901138, 'epoch': 0.81}
 81%|████████  | 1171/1449 [7:18:49<1:40:00, 21.59s/it] 81%|████████  | 1172/1449 [7:19:10<1:39:34, 21.57s/it]                                                       {'loss': 1.1124, 'grad_norm': 3.925889492034912, 'learning_rate': 1.934054173189481e-07, 'num_tokens': 7009805.0, 'mean_token_accuracy': 0.6871512420475483, 'epoch': 0.81}
 81%|████████  | 1172/1449 [7:19:10<1:39:34, 21.57s/it] 81%|████████  | 1173/1449 [7:19:32<1:39:05, 21.54s/it]                                                       {'loss': 1.0941, 'grad_norm': 3.7740657329559326, 'learning_rate': 1.920579486078091e-07, 'num_tokens': 7016027.0, 'mean_token_accuracy': 0.7064356319606304, 'epoch': 0.81}
 81%|████████  | 1173/1449 [7:19:32<1:39:05, 21.54s/it] 81%|████████  | 1174/1449 [7:19:54<1:39:12, 21.65s/it]                                                       {'loss': 0.9949, 'grad_norm': 3.6350998878479004, 'learning_rate': 1.9071469145579077e-07, 'num_tokens': 7021838.0, 'mean_token_accuracy': 0.7145257331430912, 'epoch': 0.81}
 81%|████████  | 1174/1449 [7:19:54<1:39:12, 21.65s/it] 81%|████████  | 1175/1449 [7:20:15<1:38:30, 21.57s/it]                                                       {'loss': 1.0224, 'grad_norm': 3.301264762878418, 'learning_rate': 1.8937565286488967e-07, 'num_tokens': 7028318.0, 'mean_token_accuracy': 0.7236490584909916, 'epoch': 0.81}
 81%|████████  | 1175/1449 [7:20:15<1:38:30, 21.57s/it] 81%|████████  | 1176/1449 [7:20:37<1:38:13, 21.59s/it]                                                       {'loss': 0.9709, 'grad_norm': 3.5744411945343018, 'learning_rate': 1.8804083981511098e-07, 'num_tokens': 7034530.0, 'mean_token_accuracy': 0.7324683405458927, 'epoch': 0.81}
 81%|████████  | 1176/1449 [7:20:37<1:38:13, 21.59s/it] 81%|████████  | 1177/1449 [7:20:58<1:37:34, 21.52s/it]                                                       {'loss': 1.0337, 'grad_norm': 3.637814521789551, 'learning_rate': 1.8671025926443463e-07, 'num_tokens': 7039424.0, 'mean_token_accuracy': 0.7029328681528568, 'epoch': 0.81}
 81%|████████  | 1177/1449 [7:20:58<1:37:34, 21.52s/it] 81%|████████▏ | 1178/1449 [7:21:20<1:37:07, 21.51s/it]                                                       {'loss': 1.133, 'grad_norm': 3.289513349533081, 'learning_rate': 1.8538391814877685e-07, 'num_tokens': 7045267.0, 'mean_token_accuracy': 0.6880826056003571, 'epoch': 0.81}
 81%|████████▏ | 1178/1449 [7:21:20<1:37:07, 21.51s/it] 81%|████████▏ | 1179/1449 [7:21:42<1:37:14, 21.61s/it]                                                       {'loss': 1.0145, 'grad_norm': 3.335256338119507, 'learning_rate': 1.840618233819552e-07, 'num_tokens': 7051028.0, 'mean_token_accuracy': 0.712557952851057, 'epoch': 0.81}
 81%|████████▏ | 1179/1449 [7:21:42<1:37:14, 21.61s/it] 81%|████████▏ | 1180/1449 [7:22:03<1:36:18, 21.48s/it]                                                       {'loss': 0.9909, 'grad_norm': 3.7528345584869385, 'learning_rate': 1.8274398185565232e-07, 'num_tokens': 7056925.0, 'mean_token_accuracy': 0.7323231659829617, 'epoch': 0.81}
 81%|████████▏ | 1180/1449 [7:22:03<1:36:18, 21.48s/it] 82%|████████▏ | 1181/1449 [7:22:25<1:36:27, 21.59s/it]                                                       {'loss': 1.0667, 'grad_norm': 3.459674596786499, 'learning_rate': 1.8143040043938053e-07, 'num_tokens': 7062985.0, 'mean_token_accuracy': 0.7090997062623501, 'epoch': 0.81}
 82%|████████▏ | 1181/1449 [7:22:25<1:36:27, 21.59s/it] 82%|████████▏ | 1182/1449 [7:22:46<1:36:08, 21.61s/it]                                                       {'loss': 1.0325, 'grad_norm': 3.38751220703125, 'learning_rate': 1.8012108598044452e-07, 'num_tokens': 7069151.0, 'mean_token_accuracy': 0.7162451595067978, 'epoch': 0.82}
 82%|████████▏ | 1182/1449 [7:22:46<1:36:08, 21.61s/it] 82%|████████▏ | 1183/1449 [7:23:08<1:35:28, 21.54s/it]                                                       {'loss': 0.9798, 'grad_norm': 3.4150631427764893, 'learning_rate': 1.788160453039075e-07, 'num_tokens': 7075250.0, 'mean_token_accuracy': 0.7229252718389034, 'epoch': 0.82}
 82%|████████▏ | 1183/1449 [7:23:08<1:35:28, 21.54s/it] 82%|████████▏ | 1184/1449 [7:23:29<1:35:13, 21.56s/it]                                                       {'loss': 0.9307, 'grad_norm': 3.6729331016540527, 'learning_rate': 1.7751528521255388e-07, 'num_tokens': 7081286.0, 'mean_token_accuracy': 0.7462062053382397, 'epoch': 0.82}
 82%|████████▏ | 1184/1449 [7:23:29<1:35:13, 21.56s/it] 82%|████████▏ | 1185/1449 [7:23:51<1:35:05, 21.61s/it]                                                       {'loss': 1.0218, 'grad_norm': 3.1605887413024902, 'learning_rate': 1.7621881248685567e-07, 'num_tokens': 7087051.0, 'mean_token_accuracy': 0.7154642455279827, 'epoch': 0.82}
 82%|████████▏ | 1185/1449 [7:23:51<1:35:05, 21.61s/it] 82%|████████▏ | 1186/1449 [7:24:12<1:34:23, 21.54s/it]                                                       {'loss': 1.1018, 'grad_norm': 3.825104236602783, 'learning_rate': 1.749266338849351e-07, 'num_tokens': 7093227.0, 'mean_token_accuracy': 0.7027775831520557, 'epoch': 0.82}
 82%|████████▏ | 1186/1449 [7:24:12<1:34:23, 21.54s/it] 82%|████████▏ | 1187/1449 [7:24:34<1:34:10, 21.57s/it]                                                       {'loss': 0.9411, 'grad_norm': 3.459807872772217, 'learning_rate': 1.7363875614253132e-07, 'num_tokens': 7099198.0, 'mean_token_accuracy': 0.7228950075805187, 'epoch': 0.82}
 82%|████████▏ | 1187/1449 [7:24:34<1:34:10, 21.57s/it] 82%|████████▏ | 1188/1449 [7:24:55<1:33:30, 21.50s/it]                                                       {'loss': 0.9784, 'grad_norm': 3.671335220336914, 'learning_rate': 1.723551859729636e-07, 'num_tokens': 7104756.0, 'mean_token_accuracy': 0.7224470563232899, 'epoch': 0.82}
 82%|████████▏ | 1188/1449 [7:24:55<1:33:30, 21.50s/it] 82%|████████▏ | 1189/1449 [7:25:17<1:33:30, 21.58s/it]                                                       {'loss': 0.9107, 'grad_norm': 3.237400531768799, 'learning_rate': 1.7107593006709798e-07, 'num_tokens': 7110521.0, 'mean_token_accuracy': 0.7295039109885693, 'epoch': 0.82}
 82%|████████▏ | 1189/1449 [7:25:17<1:33:30, 21.58s/it] 82%|████████▏ | 1190/1449 [7:25:39<1:33:23, 21.64s/it]                                                       {'loss': 1.0743, 'grad_norm': 3.4738235473632812, 'learning_rate': 1.698009950933108e-07, 'num_tokens': 7116984.0, 'mean_token_accuracy': 0.6992186494171619, 'epoch': 0.82}
 82%|████████▏ | 1190/1449 [7:25:39<1:33:23, 21.64s/it] 82%|████████▏ | 1191/1449 [7:26:00<1:32:49, 21.59s/it]                                                       {'loss': 1.0449, 'grad_norm': 3.5194432735443115, 'learning_rate': 1.6853038769745465e-07, 'num_tokens': 7122222.0, 'mean_token_accuracy': 0.7163890935480595, 'epoch': 0.82}
 82%|████████▏ | 1191/1449 [7:26:00<1:32:49, 21.59s/it] 82%|████████▏ | 1192/1449 [7:26:22<1:32:54, 21.69s/it]                                                       {'loss': 1.0719, 'grad_norm': 3.7740113735198975, 'learning_rate': 1.6726411450282475e-07, 'num_tokens': 7127616.0, 'mean_token_accuracy': 0.7033828012645245, 'epoch': 0.82}
 82%|████████▏ | 1192/1449 [7:26:22<1:32:54, 21.69s/it] 82%|████████▏ | 1193/1449 [7:26:44<1:32:23, 21.65s/it]                                                       {'loss': 1.0391, 'grad_norm': 3.366600751876831, 'learning_rate': 1.6600218211012218e-07, 'num_tokens': 7133100.0, 'mean_token_accuracy': 0.7089544869959354, 'epoch': 0.82}
 82%|████████▏ | 1193/1449 [7:26:44<1:32:23, 21.65s/it] 82%|████████▏ | 1194/1449 [7:27:05<1:31:59, 21.65s/it]                                                       {'loss': 0.9504, 'grad_norm': 3.157754421234131, 'learning_rate': 1.647445970974215e-07, 'num_tokens': 7139823.0, 'mean_token_accuracy': 0.7483937926590443, 'epoch': 0.82}
 82%|████████▏ | 1194/1449 [7:27:05<1:31:59, 21.65s/it] 82%|████████▏ | 1195/1449 [7:27:27<1:31:37, 21.64s/it]                                                       {'loss': 1.0512, 'grad_norm': 3.9558510780334473, 'learning_rate': 1.6349136602013524e-07, 'num_tokens': 7145017.0, 'mean_token_accuracy': 0.6971731223165989, 'epoch': 0.82}
 82%|████████▏ | 1195/1449 [7:27:27<1:31:37, 21.64s/it] 83%|████████▎ | 1196/1449 [7:27:49<1:31:31, 21.71s/it]                                                       {'loss': 1.0251, 'grad_norm': 3.6659750938415527, 'learning_rate': 1.6224249541098078e-07, 'num_tokens': 7150327.0, 'mean_token_accuracy': 0.7098018229007721, 'epoch': 0.82}
 83%|████████▎ | 1196/1449 [7:27:49<1:31:31, 21.71s/it] 83%|████████▎ | 1197/1449 [7:28:11<1:31:06, 21.69s/it]                                                       {'loss': 1.0684, 'grad_norm': 3.622478723526001, 'learning_rate': 1.6099799177994488e-07, 'num_tokens': 7156844.0, 'mean_token_accuracy': 0.7187282294034958, 'epoch': 0.83}
 83%|████████▎ | 1197/1449 [7:28:11<1:31:06, 21.69s/it] 83%|████████▎ | 1198/1449 [7:28:32<1:30:38, 21.67s/it]                                                       {'loss': 1.0305, 'grad_norm': 3.228832483291626, 'learning_rate': 1.5975786161425142e-07, 'num_tokens': 7163860.0, 'mean_token_accuracy': 0.7283270172774792, 'epoch': 0.83}
 83%|████████▎ | 1198/1449 [7:28:32<1:30:38, 21.67s/it] 83%|████████▎ | 1199/1449 [7:28:54<1:30:16, 21.66s/it]                                                       {'loss': 0.9897, 'grad_norm': 3.048248291015625, 'learning_rate': 1.5852211137832584e-07, 'num_tokens': 7170000.0, 'mean_token_accuracy': 0.7193158231675625, 'epoch': 0.83}
 83%|████████▎ | 1199/1449 [7:28:54<1:30:16, 21.66s/it] 83%|████████▎ | 1200/1449 [7:29:15<1:29:48, 21.64s/it]                                                       {'loss': 1.014, 'grad_norm': 3.4347095489501953, 'learning_rate': 1.5729074751376327e-07, 'num_tokens': 7176073.0, 'mean_token_accuracy': 0.7268422804772854, 'epoch': 0.83}
 83%|████████▎ | 1200/1449 [7:29:15<1:29:48, 21.64s/it][INFO|trainer.py:3966] 2025-06-06 07:38:41,843 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200
[INFO|configuration_utils.py:423] 2025-06-06 07:38:41,849 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/config.json
[INFO|configuration_utils.py:908] 2025-06-06 07:38:41,851 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 07:38:50,860 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 07:38:50,864 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 07:38:50,866 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/special_tokens_map.json
[2025-06-06 07:38:51,060] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step1200 is about to be saved!
[2025-06-06 07:38:51,066] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/global_step1200/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 07:38:51,066] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/global_step1200/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 07:38:51,081] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/global_step1200/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 07:38:51,082] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/global_step1200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 07:39:13,603] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/global_step1200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 07:39:13,609] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1200/global_step1200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 07:39:14,421] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1200 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 07:39:25,659 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 07:39:25,661 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 83%|████████▎ | 1201/1449 [7:30:23<2:26:32, 35.45s/it]                                                       {'loss': 1.0392, 'grad_norm': 3.4383137226104736, 'learning_rate': 1.5606377643929304e-07, 'num_tokens': 7181853.0, 'mean_token_accuracy': 0.7161438390612602, 'epoch': 0.83}
 83%|████████▎ | 1201/1449 [7:30:23<2:26:32, 35.45s/it] 83%|████████▎ | 1202/1449 [7:30:44<2:08:33, 31.23s/it]                                                       {'loss': 0.9683, 'grad_norm': 3.481567144393921, 'learning_rate': 1.5484120455074702e-07, 'num_tokens': 7187467.0, 'mean_token_accuracy': 0.7227905243635178, 'epoch': 0.83}
 83%|████████▎ | 1202/1449 [7:30:44<2:08:33, 31.23s/it] 83%|████████▎ | 1203/1449 [7:31:06<1:56:26, 28.40s/it]                                                       {'loss': 0.9811, 'grad_norm': 3.4175093173980713, 'learning_rate': 1.5362303822102462e-07, 'num_tokens': 7192976.0, 'mean_token_accuracy': 0.7285346426069736, 'epoch': 0.83}
 83%|████████▎ | 1203/1449 [7:31:06<1:56:26, 28.40s/it] 83%|████████▎ | 1204/1449 [7:31:28<1:47:23, 26.30s/it]                                                       {'loss': 1.0356, 'grad_norm': 3.4601364135742188, 'learning_rate': 1.5240928380006147e-07, 'num_tokens': 7198685.0, 'mean_token_accuracy': 0.7098584845662117, 'epoch': 0.83}
 83%|████████▎ | 1204/1449 [7:31:28<1:47:23, 26.30s/it] 83%|████████▎ | 1205/1449 [7:31:49<1:41:09, 24.88s/it]                                                       {'loss': 1.0756, 'grad_norm': 3.5336694717407227, 'learning_rate': 1.5119994761479427e-07, 'num_tokens': 7204477.0, 'mean_token_accuracy': 0.7090122923254967, 'epoch': 0.83}
 83%|████████▎ | 1205/1449 [7:31:49<1:41:09, 24.88s/it] 83%|████████▎ | 1206/1449 [7:32:11<1:36:33, 23.84s/it]                                                       {'loss': 1.098, 'grad_norm': 3.1413469314575195, 'learning_rate': 1.499950359691291e-07, 'num_tokens': 7211353.0, 'mean_token_accuracy': 0.7119271419942379, 'epoch': 0.83}
 83%|████████▎ | 1206/1449 [7:32:11<1:36:33, 23.84s/it] 83%|████████▎ | 1207/1449 [7:32:32<1:33:36, 23.21s/it]                                                       {'loss': 1.0746, 'grad_norm': 3.6853413581848145, 'learning_rate': 1.4879455514390815e-07, 'num_tokens': 7216834.0, 'mean_token_accuracy': 0.7009960189461708, 'epoch': 0.83}
 83%|████████▎ | 1207/1449 [7:32:32<1:33:36, 23.21s/it] 83%|████████▎ | 1208/1449 [7:32:54<1:30:51, 22.62s/it]                                                       {'loss': 1.0585, 'grad_norm': 3.673339605331421, 'learning_rate': 1.4759851139687752e-07, 'num_tokens': 7222431.0, 'mean_token_accuracy': 0.7095120586454868, 'epoch': 0.83}
 83%|████████▎ | 1208/1449 [7:32:54<1:30:51, 22.62s/it] 83%|████████▎ | 1209/1449 [7:33:15<1:29:25, 22.36s/it]                                                       {'loss': 0.9538, 'grad_norm': 2.8013665676116943, 'learning_rate': 1.4640691096265357e-07, 'num_tokens': 7229953.0, 'mean_token_accuracy': 0.734083566814661, 'epoch': 0.83}
 83%|████████▎ | 1209/1449 [7:33:15<1:29:25, 22.36s/it] 84%|████████▎ | 1210/1449 [7:33:37<1:27:55, 22.07s/it]                                                       {'loss': 1.0427, 'grad_norm': 3.2176907062530518, 'learning_rate': 1.4521976005269165e-07, 'num_tokens': 7236024.0, 'mean_token_accuracy': 0.7160523943603039, 'epoch': 0.83}
 84%|████████▎ | 1210/1449 [7:33:37<1:27:55, 22.07s/it] 84%|████████▎ | 1211/1449 [7:33:58<1:26:56, 21.92s/it]                                                       {'loss': 1.059, 'grad_norm': 3.8026676177978516, 'learning_rate': 1.4403706485525224e-07, 'num_tokens': 7241153.0, 'mean_token_accuracy': 0.7089121714234352, 'epoch': 0.84}
 84%|████████▎ | 1211/1449 [7:33:58<1:26:56, 21.92s/it] 84%|████████▎ | 1212/1449 [7:34:20<1:25:56, 21.76s/it]                                                       {'loss': 1.1132, 'grad_norm': 3.9271931648254395, 'learning_rate': 1.4285883153537047e-07, 'num_tokens': 7246493.0, 'mean_token_accuracy': 0.6844540350139141, 'epoch': 0.84}
 84%|████████▎ | 1212/1449 [7:34:20<1:25:56, 21.76s/it] 84%|████████▎ | 1213/1449 [7:34:41<1:25:35, 21.76s/it]                                                       {'loss': 1.0602, 'grad_norm': 3.7474162578582764, 'learning_rate': 1.41685066234822e-07, 'num_tokens': 7251911.0, 'mean_token_accuracy': 0.7150198332965374, 'epoch': 0.84}
 84%|████████▎ | 1213/1449 [7:34:41<1:25:35, 21.76s/it] 84%|████████▍ | 1214/1449 [7:35:03<1:24:35, 21.60s/it]                                                       {'loss': 0.8986, 'grad_norm': 3.931778907775879, 'learning_rate': 1.4051577507209335e-07, 'num_tokens': 7257583.0, 'mean_token_accuracy': 0.7434995621442795, 'epoch': 0.84}
 84%|████████▍ | 1214/1449 [7:35:03<1:24:35, 21.60s/it] 84%|████████▍ | 1215/1449 [7:35:24<1:24:21, 21.63s/it]                                                       {'loss': 0.9867, 'grad_norm': 3.3527607917785645, 'learning_rate': 1.3935096414234726e-07, 'num_tokens': 7263585.0, 'mean_token_accuracy': 0.7187023013830185, 'epoch': 0.84}
 84%|████████▍ | 1215/1449 [7:35:24<1:24:21, 21.63s/it] 84%|████████▍ | 1216/1449 [7:35:46<1:23:31, 21.51s/it]                                                       {'loss': 0.9352, 'grad_norm': 3.5792622566223145, 'learning_rate': 1.3819063951739362e-07, 'num_tokens': 7269397.0, 'mean_token_accuracy': 0.7405214346945286, 'epoch': 0.84}
 84%|████████▍ | 1216/1449 [7:35:46<1:23:31, 21.51s/it] 84%|████████▍ | 1217/1449 [7:36:07<1:23:13, 21.52s/it]                                                       {'loss': 1.06, 'grad_norm': 3.2440388202667236, 'learning_rate': 1.3703480724565575e-07, 'num_tokens': 7275308.0, 'mean_token_accuracy': 0.708086334168911, 'epoch': 0.84}
 84%|████████▍ | 1217/1449 [7:36:07<1:23:13, 21.52s/it] 84%|████████▍ | 1218/1449 [7:36:29<1:22:52, 21.53s/it]                                                       {'loss': 1.0278, 'grad_norm': 3.186276912689209, 'learning_rate': 1.358834733521399e-07, 'num_tokens': 7282611.0, 'mean_token_accuracy': 0.726093802601099, 'epoch': 0.84}
 84%|████████▍ | 1218/1449 [7:36:29<1:22:52, 21.53s/it] 84%|████████▍ | 1219/1449 [7:36:50<1:22:18, 21.47s/it]                                                       {'loss': 1.0058, 'grad_norm': 3.4357552528381348, 'learning_rate': 1.3473664383840367e-07, 'num_tokens': 7288637.0, 'mean_token_accuracy': 0.7239125072956085, 'epoch': 0.84}
 84%|████████▍ | 1219/1449 [7:36:50<1:22:18, 21.47s/it] 84%|████████▍ | 1220/1449 [7:37:12<1:22:00, 21.49s/it]                                                       {'loss': 1.0777, 'grad_norm': 3.670555591583252, 'learning_rate': 1.3359432468252484e-07, 'num_tokens': 7293964.0, 'mean_token_accuracy': 0.7034824304282665, 'epoch': 0.84}
 84%|████████▍ | 1220/1449 [7:37:12<1:22:00, 21.49s/it] 84%|████████▍ | 1221/1449 [7:37:33<1:21:42, 21.50s/it]                                                       {'loss': 1.0282, 'grad_norm': 3.620421886444092, 'learning_rate': 1.3245652183906964e-07, 'num_tokens': 7299511.0, 'mean_token_accuracy': 0.7135538272559643, 'epoch': 0.84}
 84%|████████▍ | 1221/1449 [7:37:33<1:21:42, 21.50s/it] 84%|████████▍ | 1222/1449 [7:37:54<1:21:12, 21.47s/it]                                                       {'loss': 1.0452, 'grad_norm': 3.9223673343658447, 'learning_rate': 1.3132324123906279e-07, 'num_tokens': 7304647.0, 'mean_token_accuracy': 0.7145624235272408, 'epoch': 0.84}
 84%|████████▍ | 1222/1449 [7:37:54<1:21:12, 21.47s/it] 84%|████████▍ | 1223/1449 [7:38:16<1:20:55, 21.48s/it]                                                       {'loss': 1.0102, 'grad_norm': 3.3263463973999023, 'learning_rate': 1.3019448878995497e-07, 'num_tokens': 7310882.0, 'mean_token_accuracy': 0.7159645259380341, 'epoch': 0.84}
 84%|████████▍ | 1223/1449 [7:38:16<1:20:55, 21.48s/it] 84%|████████▍ | 1224/1449 [7:38:38<1:20:39, 21.51s/it]                                                       {'loss': 0.9266, 'grad_norm': 3.4906606674194336, 'learning_rate': 1.2907027037559416e-07, 'num_tokens': 7316601.0, 'mean_token_accuracy': 0.7352164201438427, 'epoch': 0.84}
 84%|████████▍ | 1224/1449 [7:38:38<1:20:39, 21.51s/it] 85%|████████▍ | 1225/1449 [7:38:59<1:20:07, 21.46s/it]                                                       {'loss': 1.0483, 'grad_norm': 3.577014923095703, 'learning_rate': 1.279505918561923e-07, 'num_tokens': 7322398.0, 'mean_token_accuracy': 0.7091951109468937, 'epoch': 0.84}
 85%|████████▍ | 1225/1449 [7:38:59<1:20:07, 21.46s/it] 85%|████████▍ | 1226/1449 [7:39:20<1:19:42, 21.44s/it]                                                       {'loss': 1.0477, 'grad_norm': 3.3354804515838623, 'learning_rate': 1.2683545906829784e-07, 'num_tokens': 7328274.0, 'mean_token_accuracy': 0.7117670997977257, 'epoch': 0.85}
 85%|████████▍ | 1226/1449 [7:39:20<1:19:42, 21.44s/it] 85%|████████▍ | 1227/1449 [7:39:42<1:19:07, 21.39s/it]                                                       {'loss': 0.9988, 'grad_norm': 3.1559696197509766, 'learning_rate': 1.2572487782476225e-07, 'num_tokens': 7334325.0, 'mean_token_accuracy': 0.7316828519105911, 'epoch': 0.85}
 85%|████████▍ | 1227/1449 [7:39:42<1:19:07, 21.39s/it] 85%|████████▍ | 1228/1449 [7:40:03<1:18:36, 21.34s/it]                                                       {'loss': 1.1705, 'grad_norm': 3.6317379474639893, 'learning_rate': 1.246188539147124e-07, 'num_tokens': 7340938.0, 'mean_token_accuracy': 0.679115666076541, 'epoch': 0.85}
 85%|████████▍ | 1228/1449 [7:40:03<1:18:36, 21.34s/it] 85%|████████▍ | 1229/1449 [7:40:24<1:17:43, 21.20s/it]                                                       {'loss': 1.1416, 'grad_norm': 3.4780142307281494, 'learning_rate': 1.2351739310351794e-07, 'num_tokens': 7347115.0, 'mean_token_accuracy': 0.6944665126502514, 'epoch': 0.85}
 85%|████████▍ | 1229/1449 [7:40:24<1:17:43, 21.20s/it] 85%|████████▍ | 1230/1449 [7:40:45<1:17:19, 21.18s/it]                                                       {'loss': 0.9615, 'grad_norm': 3.4694833755493164, 'learning_rate': 1.224205011327637e-07, 'num_tokens': 7353618.0, 'mean_token_accuracy': 0.7339189648628235, 'epoch': 0.85}
 85%|████████▍ | 1230/1449 [7:40:45<1:17:19, 21.18s/it] 85%|████████▍ | 1231/1449 [7:41:06<1:16:33, 21.07s/it]                                                       {'loss': 0.9929, 'grad_norm': 3.4684746265411377, 'learning_rate': 1.2132818372021757e-07, 'num_tokens': 7359519.0, 'mean_token_accuracy': 0.723102331161499, 'epoch': 0.85}
 85%|████████▍ | 1231/1449 [7:41:06<1:16:33, 21.07s/it] 85%|████████▌ | 1232/1449 [7:41:27<1:16:32, 21.16s/it]                                                       {'loss': 0.9914, 'grad_norm': 3.6239876747131348, 'learning_rate': 1.2024044655980193e-07, 'num_tokens': 7365251.0, 'mean_token_accuracy': 0.7312242724001408, 'epoch': 0.85}
 85%|████████▌ | 1232/1449 [7:41:27<1:16:32, 21.16s/it] 85%|████████▌ | 1233/1449 [7:41:48<1:15:38, 21.01s/it]                                                       {'loss': 0.9729, 'grad_norm': 3.187614679336548, 'learning_rate': 1.1915729532156371e-07, 'num_tokens': 7371240.0, 'mean_token_accuracy': 0.7181330695748329, 'epoch': 0.85}
 85%|████████▌ | 1233/1449 [7:41:48<1:15:38, 21.01s/it] 85%|████████▌ | 1234/1449 [7:42:09<1:15:28, 21.06s/it]                                                       {'loss': 0.9717, 'grad_norm': 3.1858270168304443, 'learning_rate': 1.1807873565164505e-07, 'num_tokens': 7377355.0, 'mean_token_accuracy': 0.7287903130054474, 'epoch': 0.85}
 85%|████████▌ | 1234/1449 [7:42:09<1:15:28, 21.06s/it] 85%|████████▌ | 1235/1449 [7:42:30<1:15:03, 21.05s/it]                                                       {'loss': 0.9614, 'grad_norm': 3.3063483238220215, 'learning_rate': 1.1700477317225333e-07, 'num_tokens': 7383161.0, 'mean_token_accuracy': 0.7166424468159676, 'epoch': 0.85}
 85%|████████▌ | 1235/1449 [7:42:30<1:15:03, 21.05s/it] 85%|████████▌ | 1236/1449 [7:42:51<1:14:43, 21.05s/it]                                                       {'loss': 1.0776, 'grad_norm': 3.4335858821868896, 'learning_rate': 1.1593541348163183e-07, 'num_tokens': 7389538.0, 'mean_token_accuracy': 0.6962569206953049, 'epoch': 0.85}
 85%|████████▌ | 1236/1449 [7:42:51<1:14:43, 21.05s/it] 85%|████████▌ | 1237/1449 [7:43:12<1:14:02, 20.95s/it]                                                       {'loss': 1.0063, 'grad_norm': 2.839066505432129, 'learning_rate': 1.1487066215403184e-07, 'num_tokens': 7396164.0, 'mean_token_accuracy': 0.7247815728187561, 'epoch': 0.85}
 85%|████████▌ | 1237/1449 [7:43:12<1:14:02, 20.95s/it] 85%|████████▌ | 1238/1449 [7:43:33<1:13:57, 21.03s/it]                                                       {'loss': 0.9181, 'grad_norm': 3.3444223403930664, 'learning_rate': 1.1381052473968156e-07, 'num_tokens': 7402380.0, 'mean_token_accuracy': 0.7198631167411804, 'epoch': 0.85}
 85%|████████▌ | 1238/1449 [7:43:33<1:13:57, 21.03s/it] 86%|████████▌ | 1239/1449 [7:43:53<1:13:10, 20.91s/it]                                                       {'loss': 1.1009, 'grad_norm': 3.0362489223480225, 'learning_rate': 1.1275500676475924e-07, 'num_tokens': 7409332.0, 'mean_token_accuracy': 0.718143705278635, 'epoch': 0.85}
 86%|████████▌ | 1239/1449 [7:43:53<1:13:10, 20.91s/it] 86%|████████▌ | 1240/1449 [7:44:15<1:13:05, 20.98s/it]                                                       {'loss': 1.0053, 'grad_norm': 3.304997682571411, 'learning_rate': 1.1170411373136246e-07, 'num_tokens': 7415920.0, 'mean_token_accuracy': 0.723074484616518, 'epoch': 0.86}
 86%|████████▌ | 1240/1449 [7:44:15<1:13:05, 20.98s/it] 86%|████████▌ | 1241/1449 [7:44:35<1:12:20, 20.87s/it]                                                       {'loss': 1.0101, 'grad_norm': 3.379997968673706, 'learning_rate': 1.1065785111748117e-07, 'num_tokens': 7421779.0, 'mean_token_accuracy': 0.7152972780168056, 'epoch': 0.86}
 86%|████████▌ | 1241/1449 [7:44:35<1:12:20, 20.87s/it] 86%|████████▌ | 1242/1449 [7:44:56<1:12:14, 20.94s/it]                                                       {'loss': 0.9926, 'grad_norm': 3.6016316413879395, 'learning_rate': 1.096162243769676e-07, 'num_tokens': 7427322.0, 'mean_token_accuracy': 0.7287795133888721, 'epoch': 0.86}
 86%|████████▌ | 1242/1449 [7:44:56<1:12:14, 20.94s/it] 86%|████████▌ | 1243/1449 [7:45:18<1:12:29, 21.11s/it]                                                       {'loss': 0.9687, 'grad_norm': 3.7160682678222656, 'learning_rate': 1.0857923893950926e-07, 'num_tokens': 7433134.0, 'mean_token_accuracy': 0.729557953774929, 'epoch': 0.86}
 86%|████████▌ | 1243/1449 [7:45:18<1:12:29, 21.11s/it] 86%|████████▌ | 1244/1449 [7:45:40<1:12:43, 21.29s/it]                                                       {'loss': 1.0785, 'grad_norm': 3.6514060497283936, 'learning_rate': 1.0754690021059953e-07, 'num_tokens': 7438781.0, 'mean_token_accuracy': 0.7003625966608524, 'epoch': 0.86}
 86%|████████▌ | 1244/1449 [7:45:40<1:12:43, 21.29s/it] 86%|████████▌ | 1245/1449 [7:46:01<1:12:33, 21.34s/it]                                                       {'loss': 1.077, 'grad_norm': 3.580634355545044, 'learning_rate': 1.0651921357150995e-07, 'num_tokens': 7444706.0, 'mean_token_accuracy': 0.7016724348068237, 'epoch': 0.86}
 86%|████████▌ | 1245/1449 [7:46:01<1:12:33, 21.34s/it] 86%|████████▌ | 1246/1449 [7:46:23<1:12:44, 21.50s/it]                                                       {'loss': 1.0513, 'grad_norm': 3.2851312160491943, 'learning_rate': 1.0549618437926178e-07, 'num_tokens': 7451221.0, 'mean_token_accuracy': 0.6944031901657581, 'epoch': 0.86}
 86%|████████▌ | 1246/1449 [7:46:23<1:12:44, 21.50s/it] 86%|████████▌ | 1247/1449 [7:46:44<1:12:20, 21.49s/it]                                                       {'loss': 0.9699, 'grad_norm': 3.6578853130340576, 'learning_rate': 1.0447781796659938e-07, 'num_tokens': 7456997.0, 'mean_token_accuracy': 0.7161430008709431, 'epoch': 0.86}
 86%|████████▌ | 1247/1449 [7:46:44<1:12:20, 21.49s/it] 86%|████████▌ | 1248/1449 [7:47:06<1:12:23, 21.61s/it]                                                       {'loss': 1.2096, 'grad_norm': 3.8606741428375244, 'learning_rate': 1.0346411964196033e-07, 'num_tokens': 7462256.0, 'mean_token_accuracy': 0.6745087206363678, 'epoch': 0.86}
 86%|████████▌ | 1248/1449 [7:47:06<1:12:23, 21.61s/it] 86%|████████▌ | 1249/1449 [7:47:28<1:11:54, 21.57s/it]                                                       {'loss': 0.9841, 'grad_norm': 3.533334493637085, 'learning_rate': 1.024550946894499e-07, 'num_tokens': 7469150.0, 'mean_token_accuracy': 0.7184758298099041, 'epoch': 0.86}
 86%|████████▌ | 1249/1449 [7:47:28<1:11:54, 21.57s/it] 86%|████████▋ | 1250/1449 [7:47:49<1:11:27, 21.55s/it]                                                       {'loss': 1.0286, 'grad_norm': 3.5234644412994385, 'learning_rate': 1.0145074836881129e-07, 'num_tokens': 7474762.0, 'mean_token_accuracy': 0.7163993753492832, 'epoch': 0.86}
 86%|████████▋ | 1250/1449 [7:47:49<1:11:27, 21.55s/it][INFO|trainer.py:3966] 2025-06-06 07:57:15,439 >> Saving model checkpoint to /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250
[INFO|configuration_utils.py:423] 2025-06-06 07:57:15,444 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/config.json
[INFO|configuration_utils.py:908] 2025-06-06 07:57:15,447 >> Configuration saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/generation_config.json
[INFO|modeling_utils.py:3586] 2025-06-06 07:57:23,664 >> Model weights saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/model.safetensors
[INFO|tokenization_utils_base.py:2510] 2025-06-06 07:57:23,667 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 07:57:23,669 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/special_tokens_map.json
[2025-06-06 07:57:23,863] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step1250 is about to be saved!
[2025-06-06 07:57:23,870] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/global_step1250/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-06-06 07:57:23,870] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/global_step1250/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-06-06 07:57:23,885] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/global_step1250/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-06-06 07:57:23,886] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/global_step1250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-06-06 07:57:48,672] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/global_step1250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-06-06 07:57:48,677] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/checkpoint-1250/global_step1250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-06-06 07:57:49,196] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1250 is ready now!
[INFO|tokenization_utils_base.py:2510] 2025-06-06 07:58:01,918 >> tokenizer config file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-06-06 07:58:01,920 >> Special tokens file saved in /n/fs/similarity/open-r1/data/Qwen2.5-1.5B-Instruct-SFT-v4/special_tokens_map.json
 86%|████████▋ | 1251/1449 [7:48:59<1:58:39, 35.96s/it]                                                       {'loss': 0.9328, 'grad_norm': 3.437704563140869, 'learning_rate': 1.0045108591540074e-07, 'num_tokens': 7482114.0, 'mean_token_accuracy': 0.7341082468628883, 'epoch': 0.86}
 86%|████████▋ | 1251/1449 [7:48:59<1:58:39, 35.96s/it] 86%|████████▋ | 1252/1449 [7:49:21<1:44:15, 31.76s/it]                                                       {'loss': 0.9953, 'grad_norm': 3.0702967643737793, 'learning_rate': 9.945611254015762e-08, 'num_tokens': 7488676.0, 'mean_token_accuracy': 0.7210590057075024, 'epoch': 0.86}
 86%|████████▋ | 1252/1449 [7:49:21<1:44:15, 31.76s/it] 86%|████████▋ | 1253/1449 [7:49:42<1:33:36, 28.65s/it]                                                       {'loss': 1.0974, 'grad_norm': 3.4256129264831543, 'learning_rate': 9.84658334295796e-08, 'num_tokens': 7495278.0, 'mean_token_accuracy': 0.6991214156150818, 'epoch': 0.86}
 86%|████████▋ | 1253/1449 [7:49:42<1:33:36, 28.65s/it] 87%|████████▋ | 1254/1449 [7:50:04<1:26:28, 26.61s/it]                                                       {'loss': 1.0514, 'grad_norm': 3.3318982124328613, 'learning_rate': 9.748025374569369e-08, 'num_tokens': 7501089.0, 'mean_token_accuracy': 0.7122407704591751, 'epoch': 0.86}
 87%|████████▋ | 1254/1449 [7:50:04<1:26:28, 26.61s/it] 87%|████████▋ | 1255/1449 [7:50:26<1:21:14, 25.12s/it]                                                       {'loss': 0.9951, 'grad_norm': 4.385025978088379, 'learning_rate': 9.649937862603096e-08, 'num_tokens': 7507417.0, 'mean_token_accuracy': 0.7372328229248524, 'epoch': 0.87}
 87%|████████▋ | 1255/1449 [7:50:26<1:21:14, 25.12s/it] 87%|████████▋ | 1256/1449 [7:50:47<1:17:15, 24.02s/it]                                                       {'loss': 1.0323, 'grad_norm': 3.224999189376831, 'learning_rate': 9.552321318359835e-08, 'num_tokens': 7513670.0, 'mean_token_accuracy': 0.7161972112953663, 'epoch': 0.87}
 87%|████████▋ | 1256/1449 [7:50:47<1:17:15, 24.02s/it] 87%|████████▋ | 1257/1449 [7:51:09<1:14:45, 23.36s/it]                                                       {'loss': 1.0219, 'grad_norm': 3.712286949157715, 'learning_rate': 9.455176250685337e-08, 'num_tokens': 7519331.0, 'mean_token_accuracy': 0.7107348702847958, 'epoch': 0.87}
 87%|████████▋ | 1257/1449 [7:51:09<1:14:45, 23.36s/it] 87%|████████▋ | 1258/1449 [7:51:30<1:12:35, 22.80s/it]                                                       {'loss': 1.0743, 'grad_norm': 3.8573999404907227, 'learning_rate': 9.358503165967612e-08, 'num_tokens': 7524516.0, 'mean_token_accuracy': 0.7080501243472099, 'epoch': 0.87}
 87%|████████▋ | 1258/1449 [7:51:30<1:12:35, 22.80s/it] 87%|████████▋ | 1259/1449 [7:51:52<1:11:05, 22.45s/it]                                                       {'loss': 0.9652, 'grad_norm': 3.6888694763183594, 'learning_rate': 9.262302568134416e-08, 'num_tokens': 7530008.0, 'mean_token_accuracy': 0.7274485379457474, 'epoch': 0.87}
 87%|████████▋ | 1259/1449 [7:51:52<1:11:05, 22.45s/it] 87%|████████▋ | 1260/1449 [7:52:14<1:09:55, 22.20s/it]                                                       {'loss': 1.086, 'grad_norm': 3.0766289234161377, 'learning_rate': 9.16657495865053e-08, 'num_tokens': 7536275.0, 'mean_token_accuracy': 0.6960783377289772, 'epoch': 0.87}
 87%|████████▋ | 1260/1449 [7:52:14<1:09:55, 22.20s/it] 87%|████████▋ | 1261/1449 [7:52:35<1:08:51, 21.98s/it]                                                       {'loss': 1.0298, 'grad_norm': 3.56298828125, 'learning_rate': 9.071320836515262e-08, 'num_tokens': 7541946.0, 'mean_token_accuracy': 0.7111074700951576, 'epoch': 0.87}
 87%|████████▋ | 1261/1449 [7:52:35<1:08:51, 21.98s/it] 87%|████████▋ | 1262/1449 [7:52:57<1:08:18, 21.92s/it]                                                       {'loss': 0.9976, 'grad_norm': 3.3033132553100586, 'learning_rate': 8.976540698259672e-08, 'num_tokens': 7547879.0, 'mean_token_accuracy': 0.719409205019474, 'epoch': 0.87}
 87%|████████▋ | 1262/1449 [7:52:57<1:08:18, 21.92s/it] 87%|████████▋ | 1263/1449 [7:53:18<1:07:30, 21.78s/it]                                                       {'loss': 0.9279, 'grad_norm': 3.506817102432251, 'learning_rate': 8.882235037944185e-08, 'num_tokens': 7553822.0, 'mean_token_accuracy': 0.726750124245882, 'epoch': 0.87}
 87%|████████▋ | 1263/1449 [7:53:18<1:07:30, 21.78s/it] 87%|████████▋ | 1264/1449 [7:53:40<1:07:00, 21.73s/it]                                                       {'loss': 1.0484, 'grad_norm': 3.9211761951446533, 'learning_rate': 8.788404347155831e-08, 'num_tokens': 7560304.0, 'mean_token_accuracy': 0.7103204503655434, 'epoch': 0.87}
 87%|████████▋ | 1264/1449 [7:53:40<1:07:00, 21.73s/it] 87%|████████▋ | 1265/1449 [7:54:01<1:06:24, 21.65s/it]                                                       {'loss': 0.9885, 'grad_norm': 3.201314926147461, 'learning_rate': 8.695049115005837e-08, 'num_tokens': 7566566.0, 'mean_token_accuracy': 0.7318523339927197, 'epoch': 0.87}
 87%|████████▋ | 1265/1449 [7:54:01<1:06:24, 21.65s/it] 87%|████████▋ | 1266/1449 [7:54:23<1:06:09, 21.69s/it]                                                       {'loss': 1.0042, 'grad_norm': 3.8502776622772217, 'learning_rate': 8.602169828126948e-08, 'num_tokens': 7572090.0, 'mean_token_accuracy': 0.7183133326470852, 'epoch': 0.87}
 87%|████████▋ | 1266/1449 [7:54:23<1:06:09, 21.69s/it] 87%|████████▋ | 1267/1449 [7:54:45<1:05:44, 21.67s/it]                                                       {'loss': 0.9121, 'grad_norm': 3.1604857444763184, 'learning_rate': 8.509766970671006e-08, 'num_tokens': 7578905.0, 'mean_token_accuracy': 0.7373636141419411, 'epoch': 0.87}
 87%|████████▋ | 1267/1449 [7:54:45<1:05:44, 21.67s/it] 88%|████████▊ | 1268/1449 [7:55:06<1:05:07, 21.59s/it]                                                       {'loss': 1.0648, 'grad_norm': 3.5066301822662354, 'learning_rate': 8.417841024306294e-08, 'num_tokens': 7584194.0, 'mean_token_accuracy': 0.7036811597645283, 'epoch': 0.87}
 88%|████████▊ | 1268/1449 [7:55:06<1:05:07, 21.59s/it] 88%|████████▊ | 1269/1449 [7:55:28<1:04:56, 21.65s/it]                                                       {'loss': 1.0698, 'grad_norm': 3.2679495811462402, 'learning_rate': 8.326392468215204e-08, 'num_tokens': 7590084.0, 'mean_token_accuracy': 0.7101576216518879, 'epoch': 0.88}
 88%|████████▊ | 1269/1449 [7:55:28<1:04:56, 21.65s/it] 88%|████████▊ | 1270/1449 [7:55:49<1:04:14, 21.53s/it]                                                       {'loss': 1.0499, 'grad_norm': 3.9256064891815186, 'learning_rate': 8.235421779091534e-08, 'num_tokens': 7596050.0, 'mean_token_accuracy': 0.7071401216089725, 'epoch': 0.88}
 88%|████████▊ | 1270/1449 [7:55:49<1:04:14, 21.53s/it] 88%|████████▊ | 1271/1449 [7:56:11<1:04:06, 21.61s/it]                                                       {'loss': 1.0118, 'grad_norm': 3.7444405555725098, 'learning_rate': 8.14492943113817e-08, 'num_tokens': 7601645.0, 'mean_token_accuracy': 0.7168084718286991, 'epoch': 0.88}
 88%|████████▊ | 1271/1449 [7:56:11<1:04:06, 21.61s/it] 88%|████████▊ | 1272/1449 [7:56:33<1:03:51, 21.65s/it]                                                       {'loss': 1.1162, 'grad_norm': 3.077615261077881, 'learning_rate': 8.054915896064495e-08, 'num_tokens': 7608115.0, 'mean_token_accuracy': 0.6975254230201244, 'epoch': 0.88}
 88%|████████▊ | 1272/1449 [7:56:33<1:03:51, 21.65s/it] 88%|████████▊ | 1273/1449 [7:56:54<1:03:10, 21.54s/it]                                                       {'loss': 0.9772, 'grad_norm': 3.029841899871826, 'learning_rate': 7.965381643084068e-08, 'num_tokens': 7614663.0, 'mean_token_accuracy': 0.7198135778307915, 'epoch': 0.88}
 88%|████████▊ | 1273/1449 [7:56:54<1:03:10, 21.54s/it] 88%|████████▊ | 1274/1449 [7:57:16<1:03:30, 21.77s/it]                                                       {'loss': 0.9999, 'grad_norm': 3.5698933601379395, 'learning_rate': 7.876327138911998e-08, 'num_tokens': 7620618.0, 'mean_token_accuracy': 0.7253513261675835, 'epoch': 0.88}
 88%|████████▊ | 1274/1449 [7:57:16<1:03:30, 21.77s/it] 88%|████████▊ | 1275/1449 [7:57:38<1:03:16, 21.82s/it]                                                       {'loss': 1.0316, 'grad_norm': 3.909493923187256, 'learning_rate': 7.787752847762686e-08, 'num_tokens': 7625784.0, 'mean_token_accuracy': 0.7206633575260639, 'epoch': 0.88}
 88%|████████▊ | 1275/1449 [7:57:38<1:03:16, 21.82s/it] 88%|████████▊ | 1276/1449 [7:58:01<1:03:19, 21.96s/it]                                                       {'loss': 0.9901, 'grad_norm': 3.2863962650299072, 'learning_rate': 7.699659231347267e-08, 'num_tokens': 7632087.0, 'mean_token_accuracy': 0.7227970473468304, 'epoch': 0.88}
 88%|████████▊ | 1276/1449 [7:58:01<1:03:19, 21.96s/it] 88%|████████▊ | 1277/1449 [7:58:23<1:03:03, 22.00s/it]                                                       {'loss': 1.1812, 'grad_norm': 3.6296799182891846, 'learning_rate': 7.612046748871326e-08, 'num_tokens': 7637333.0, 'mean_token_accuracy': 0.6868943776935339, 'epoch': 0.88}
 88%|████████▊ | 1277/1449 [7:58:23<1:03:03, 22.00s/it] 88%|████████▊ | 1278/1449 [7:58:45<1:02:39, 21.99s/it]                                                       {'loss': 1.0796, 'grad_norm': 3.448625326156616, 'learning_rate': 7.524915857032389e-08, 'num_tokens': 7642862.0, 'mean_token_accuracy': 0.6995753683149815, 'epoch': 0.88}
 88%|████████▊ | 1278/1449 [7:58:45<1:02:39, 21.99s/it] 88%|████████▊ | 1279/1449 [7:59:07<1:02:31, 22.07s/it]                                                       {'loss': 1.0034, 'grad_norm': 4.095073223114014, 'learning_rate': 7.438267010017585e-08, 'num_tokens': 7648567.0, 'mean_token_accuracy': 0.7262492217123508, 'epoch': 0.88}
 88%|████████▊ | 1279/1449 [7:59:07<1:02:31, 22.07s/it] 88%|████████▊ | 1280/1449 [7:59:29<1:01:53, 21.98s/it]                                                       {'loss': 0.8879, 'grad_norm': 3.8884246349334717, 'learning_rate': 7.352100659501359e-08, 'num_tokens': 7653894.0, 'mean_token_accuracy': 0.7403264343738556, 'epoch': 0.88}
 88%|████████▊ | 1280/1449 [7:59:29<1:01:53, 21.98s/it]slurmstepd: error: *** JOB 24133227 ON node207 CANCELLED AT 2025-06-06T08:08:57 DUE TO TIME LIMIT ***
